{
  "hash": "0ba41a7ca4bce9f0c90dae723a8a2a79",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Workflow\"\nauthor: \"Prof. Sam Berchuck\"\ndate: \"2025-01-30\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    html-math-method: mathjax\nfilters:\n  - parse-latex\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Review of last lecture\n\nOn Tuesday, we learned about various ways to check MCMC convergence and model fit.\n\n-   Traceplots, effective sample size ($n_{eff}$), MC standard error, $\\hat{R}$, sampling issues\n\n-   Posterior predictive checks\n\n-   Model checks using `shinystan`\n\nToday, we will put these concepts within the larger framework of the Bayesian workflow.\n\n## Bayes theorem\n\n$$f(\\boldsymbol{\\theta} | \\mathbf{Y}) = \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta})f(\\boldsymbol{\\theta})}{f(\\mathbf{Y})}$$\n\n. . .\n\n\n- Rethinking Bayes theorem:\n\n$$f(\\boldsymbol{\\theta} | \\mathbf{Y}) \\propto f(\\mathbf{Y}, \\boldsymbol{\\theta}) = f(\\mathbf{Y} | \\boldsymbol{\\theta})f(\\boldsymbol{\\theta}) $$\n\n. . .\n\n- In Stan:\n\n$$\\log f(\\mathbf{Y} | \\boldsymbol{\\theta}) + \\log f(\\boldsymbol{\\theta})$$\n\n<!-- ## Bayesian statistics -->\n\n<!-- Advantages: -->\n\n<!-- - Natural approach to expressing uncertainty -->\n\n<!-- - Ability to incorporate prior information -->\n\n<!-- - Increased modeling flexibility -->\n\n<!-- - Full posterior distribution of parameters -->\n\n<!-- - Natural propagation of uncertainty -->\n\n<!-- Disadvantages: -->\n\n<!-- - Slow speed of model estimation -->\n\n## Bayesian workflow {.smaller}\n\n![](images/07/workflow.png){fig-alt=\"workflow\" fig-align=\"center\" height=\"6in\"}\n\n[Gelman A., Vehtari A., Simpson D., Margossian, C., Carpenter, B. and Yao, Y., Kennedy, L., Gabry, J., BÃ¼rkner P. C., & ModrÃ¡k M. (2020). Bayesian Workflow.](https://arxiv.org/abs/2011.01808)\n\n## Bayesian workflow\n\n![[Taken from Bayesian workflow by Francesca Capel](https://francescacapel.com/BayesianWorkflow/index.html)](images/07/workflow0.png){fig-alt=\"workflow0\" fig-align=\"center\" height=\"4.5in\"}\n\n- Today we will talk about a general strategy for taking a question and data to a robust conclusion.\n\n## A simplified workflow {.midi}\n\n1. *Setting up a full probability model:* a joint probability distribution for all observable and unobservable quantities in a problem. The model should be consistent with knowledge about the underlying scientific problem and the data collection process.\n\n2. *Conditioning on observed data:* calculating and interpreting the appropriate posterior distribution â€” the conditional probability distribution of the unobserved quantities of ultimate interest, given the observed data.\n\n3. *Evaluating the fit of the model and the implications of the resulting posterior distribution:* how well does the model fit the data, are the substantive conclusions reasonable, and how sensitive are the results to the modeling assumptions in step 1? In response, one can alter or expand the model and repeat the three steps.\n\n- From BDA3.\n\n## Bayesian workflow\n\n1. **Research question:** What are your dependent and indepednent variables? What associations are you interested in? EDA.\n\n. . .\n\n2. **Specify likelihood & priors:** Use knowledge of the problem to construct a generative model.\n\n. . .\n\n3. **Check the model with simulated data:** Generate data from the model and evaluate fit as a sanity check (prior predictive checks).\n\n. . .\n\n4. **Fit the model to real data:** Estimate parameters in the model using MCMC.\n\n## Bayesian workflow\n\n5. **Check diagnostics:** Use MCMC diagnostics to guarentee that the algorithm converged.\n\n. . .\n\n6. **Examine posterior fit:** Create posterior summaries that are relevant to the research question. \n\n. . .\n\n7. **Check predictions:** Examing posterior predictive checks.\n\n. . .\n\n8. **Compare models:** Iterate on model design and choose a model.\n\n## Motivating example: predicting weight from height\n\n**Research question:** We would like to understand the relationship between a person's height and weight. A few particular questions we have are:\n\n  1. How much does a person's weight increase when their height increases? \n  \n  2. How certain we can be about the magnitude of the increase?\n  \n  3. Can we predict a personâ€™s weight based on their height?\n\n**Data:** We will use the `bdims` dataset from the `openintro` package. This dataset contains body girth measurements and skeletal diameter measurements, as well as age, weight, height and gender.\n\n## Prepare data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openintro)\ndat <- data.frame(weight = bdims$wgt * 2.20462, # convert weight to lbs\n                  height = bdims$hgt * 0.393701, # convert height to inches\n                  sex = ifelse(bdims$sex == 1, \"Male\", \"Female\"))\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    weight   height  sex\n1 144.6231 68.50397 Male\n2 158.2917 69.01579 Male\n3 177.9128 76.18114 Male\n4 160.0554 73.42524 Male\n5 173.7241 73.70083 Male\n6 164.9056 71.45673 Male\n```\n\n\n:::\n:::\n\n\n\n## 1. **Research question:**\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=384}\n:::\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-3-2.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## 1. **Research question:**\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=480}\n:::\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-4-2.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n## 1. **Research question:**\n\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n## 2. **Specify likelihood & priors:**\n\n- Construct a data generating process. \n\n- We would like to model weight as a function of height using a linear regression model.\n\n$$weight_i = \\alpha + \\beta \\times height_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$$\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\ndata {\n  int<lower = 1> n;\n  vector[n] height;\n  vector[n] weight;\n}\n```\n:::\n\n\n\n## 2. **Specify likelihood & priors:**\n\n- Construct a data generating process. \n\n- We would like to model weight as a function of height using a linear regression model.\n\n$$weight_i = \\alpha + \\beta \\times height_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$$\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\nparameter {\n  real alpha;\n  real beta;\n  real<lower = 0> sigma;\n}\n```\n:::\n\n\n\n## 2. **Specify likelihood & priors:**\n\n- Construct a data generating process. \n\n- We would like to model weight as a function of height using a linear regression model.\n\n$$weight_i = \\alpha + \\beta \\times height_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$$\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\nmodel {\n  target += normal_lpdf(weight | alpha + beta * height, sigma);\n}\n```\n:::\n\n\n\n## 2. **Specify likelihood & priors:**\n\n$$weight_i = \\alpha + \\beta \\times height_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)$$\n\nThink about reasonable priors for your parameters:\n\n- $\\alpha$ is the intercept, or average weight for someone who is zero inches (not a particularly useful number on its own)\n\n- $\\beta$ measures the association between weight and height, in pounds/inch\n\n- $\\sigma$ is the measurement error for the population\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\nmodel {\n  target += normal_lpdf(weight | alpha + beta * height, sigma);\n  target += normal_lpdf(alpha | 0, 100);\n  target += normal_lpdf(beta | 0, 10);\n  target += normal_lpdf(sigma | 0, 5);\n}\n```\n:::\n\n\n\n## 2. **Specify likelihood & priors:**\n\n$$\\mathbb{E}[weight_i] = \\alpha + \\beta \\times (height_i - \\bar{x)},\\quad\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n height_i$$\n\nThink about reasonable priors for your parameters:\n\n- $\\alpha$ is the intercept, or average weight for someone who is an average height\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\nmodel {\n  target += normal_lpdf(weight | alpha + beta * height_c, sigma);\n  target += normal_lpdf(alpha | 150, 5);\n  target += normal_lpdf(beta | 0, 10);\n  target += normal_lpdf(sigma | 0, 5);\n}\n```\n:::\n\n\n\n## Quick aside\n\nWhat does it mean to use the prior `sigma ~ normal(0, 5)`? \n\n- When a parameter is truncated, for example `real<lower = 0> sigma`, priors can still be placed across the real line, $\\mathbb{R}$.\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\nparameters {\n  real<lower = 0> sigma;\n}\nmodel {\n  target += normal_lpdf(sigma | 0, 5);\n}\n```\n:::\n\n\n\n- This specification induces a prior on the truncated space $\\mathbb{R}^+$. \n\n- The induced prior for `sigma` is a [half-normal distribution](https://en.wikipedia.org/wiki/Half-normal_distribution).\n\n## Quick aside\n\n- The half-normal is a useful prior for nonnegative parameters that should not be too large and may be very close to zero. \n\n- Similar distributions for scale parameters are [half-t](https://en.wikipedia.org/wiki/Folded-t_and_half-t_distributions) and [half-Cauchy](https://distribution-explorer.github.io/continuous/halfcauchy.html) priors, these have heavier tales.\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n## 3. **Check the model with simulated data:**\n\nSanity check:\n\n  1. Draw parameter values from priors.\n\n  2. Generate data based on those parameter values.\n\n  3. Fit model to generated data.\n\n  4. Check fit is reasonable.\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\ngenerated quantities {\n  vector[n] weight;\n  real alpha = normal_rng(150, 5);\n  real beta = normal_rng(0, 10);\n  real sigma = fabs(normal_rng(0, 5));\n  for (i in 1:n) {\n    weight[i] = normal_rng(alpha + beta * height_c[i], sigma);\n  }\n}\n```\n:::\n\n\n\n## 3. **Check the model with simulated data:**\n\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\n\n## 4. **Fit the model to real data:**\n\n\n\n::: {.cell output.var='workflow'}\n\n```{.stan .cell-code}\n// saved in linear_regression_workflow.stan\ndata {\n  int<lower = 1> n; // number of observations\n  vector[n] weight; // outcome vector\n  vector[n] height_c; // covariate vector\n  int<lower = 1> n_pred; // number of new observations\n  vector[n_pred] height_c_pred; // vector for new observations\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower = 0> sigma;\n}\nmodel {\n  target += normal_lpdf(weight | alpha + height_c * beta, sigma); // likelihood\n  target += normal_lpdf(alpha | 150, 5);\n  target += normal_lpdf(beta | 0, 10);\n  target += normal_lpdf(sigma | 0, 5);\n}\ngenerated quantities {\n  vector[n] in_sample;\n  vector[n_pred] out_sample;\n  vector[n] log_lik;\n  for (i in 1:n) {\n    in_sample[i] = normal_rng(alpha + height_c[i] * beta, sigma);\n    log_lik[i] = normal_lpdf(weight[i] | alpha + height_c[i] * beta, sigma);\n  }\n  for (i in 1:n_pred) {\n    out_sample[i] = normal_rng(alpha + height_c_pred[i] * beta, sigma);\n  }\n}\n```\n:::\n\n\n\n## 4. **Fit the model to real data:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_data <- list(n = nrow(dat), \n                  height_c = (dat$height - mean(dat$height)), \n                  weight = dat$weight)\nregression_model <- stan_model(file = \"linear_regression_workflow.stan\")\nfit <- sampling(regression_model, data = stan_data)\nprint(fit)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n        mean se_mean   sd   2.5%    50%  97.5% n_eff Rhat\nalpha 152.35    0.01 0.88 150.63 152.35 154.08  3773    1\nbeta    5.69    0.00 0.25   5.21   5.69   6.18  4215    1\nsigma  20.25    0.01 0.60  19.13  20.23  21.50  3571    1\n\nSamples were drawn using NUTS(diag_e) at Wed Nov 27 14:08:19 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n```\n\n\n:::\n:::\n\n\n\n## 5. **Check diagnostics:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrstan::traceplot(fit, pars = c(\"alpha\", \"beta\", \"sigma\"))\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n## 5. **Check diagnostics:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesplot)\nmcmc_acf(fit, regex_pars = c(\"alpha\", \"beta\", \"sigma\"))\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n## 6.**Examine posterior fit:**\n\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\n\n## 6.**Examine posterior fit:**\n\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='center' width=576}\n:::\n:::\n\n\nRegression line corresponds to posterior mean and 95% credible interval for $\\mu = \\alpha + \\beta \\times height_i$.\n\n## 7.**Check predictions:**\n\n\n\n::: {.cell layout-nrow=\"1\" layout-align=\"center\"}\n\n```{.r .cell-code}\ny_pred <- rstan::extract(fit, pars = \"in_sample\")$in_sample\nppc_dens_overlay(dat$weight, y_pred[1:100, ])\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## 7. **Check predictions:**\n\n\n\n::: {.cell layout-nrow=\"2\" layout-ncol=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\nppc_stat(dat$weight, y_pred, stat = \"mean\") # from bayesplot\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='center' width=576}\n:::\n\n```{.r .cell-code}\nppc_stat(dat$weight, y_pred, stat = \"sd\")\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-23-2.png){fig-align='center' width=576}\n:::\n\n```{.r .cell-code}\nq025 <- function(y) quantile(y, 0.025)\nq975 <- function(y) quantile(y, 0.975)\nppc_stat(dat$weight, y_pred, stat = \"q025\")\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-23-3.png){fig-align='center' width=576}\n:::\n\n```{.r .cell-code}\nppc_stat(dat$weight, y_pred, stat = \"q975\")\n```\n\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-23-4.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n## 7. **Check predictions:**\n\n\n\n::: {.cell layout-ncol=\"1\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](07-workflow_files/figure-revealjs/unnamed-chunk-24-1.png){fig-align='center' width=576}\n:::\n:::\n\n\nRegression line corresponds to posterior predictive distribution mean and 95% credible interval, $f(weight_i' | weight_{1:n})$.\n\n## `shinystan`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(shinystan)\ny <- dat$weight # need to define outcome as a global variable to be accessible\nsso <- shinystan::launch_shinystan(fit)\n```\n:::\n\n\n\n## 8. **Compare models:**\n\n- Iterate on model design, choose a model.\n\n- We've talked about performing sensitivity analyses to choice of prior.\n\n- We have not introduced formal methods for model comparison.\n\n# Model comparison \n\n- Methods for model comparison for Bayesian models.\n\n  -   Watanabe-Akaike information criteria (WAIC)\n\n  -   Leave-one-out cross-validation (LOO-CV)\n\n## Model comparison\n\n- Model selection criteria are designed to help comparing several models.\n\n- An ideal criteria will not just based on their fit with training data, but on an estimation of their prediction accuracy with new data.\n\n- Criteria often reward models that offer a good compromise between simplicity and accuracy.\n\n- Examples: Likelihood ratio test, AIC\n\n## Likelihood ratio\n\n- The likelihood ratio method consists in assessing whether increasing the complexity of a model results in a significant improvement of likelihood which justifies this increased complexity.\n\n- It is a computationally inexpensive method, since it only relies on the value of the total likelihood function, but can only be used to compare nested models.\n\n- Not often used for Bayesian models.\n\n## Information criteria\n\n- Several information criteria have been proposed that do not require fitting the model several times.\n\n- Many are functions of the **deviance**, i.e., twice the negative log likelihood, $D(\\mathbf{Y}|\\boldsymbol{\\theta}) = âˆ’2 \\log f(\\mathbf{Y}|\\boldsymbol{\\theta}).$\n\n- Ideally, models will have small deviance.\n\n- However, if a model is too complex it will have small deviance but be unstable (over-fitting)\n\n- The Akaike information criteria has a complexity penalty $AIC = D(\\mathbf{Y}|\\hat{\\boldsymbol{\\theta}})+ 2p$,\nwhere $\\hat{\\boldsymbol{\\theta}}$ is the MLE.\n\n- Model with smaller AIC are preferred.\n\n## Bayesian information criteria (BIC)\n\n- The Bayesian information criteria is similar\n\n$$BIC = D(\\mathbf{Y}|\\hat{\\boldsymbol{\\theta}})+ \\log(n)p$$\n\n- This is motivated as an approximation to the log Bayes factor of the model compared to the null model.\n\n- However, this is only an asymptotic (large $n$) approximation.\n\n- With large $n$ the prior is irrelevant, and so this is not satisfying to a subjective Bayesian.\n\n## Deviance information criteria (DIC)\n\n- DIC is a popular Bayesian analog of AIC or BIC.\n\n- Unlike CV, DIC requires only one model fit.\n\n- However, proceed with caution.\n\n- DIC really only applies when the posterior is approximately normal, and will give misleading results when the posterior far from normality (e.g., bimodal).\n\n- DIC is also criticized for selecting overly-complex models.\n\n## Deviance information criteria (DIC)\n\n- Let $\\bar{D} = \\mathbb{E}[D(\\mathbf{Y}|\\boldsymbol{\\theta})|\\mathbf{Y}]$ be the posterior mean of the deviance.\n\n- Denote $\\hat{\\boldsymbol{\\theta}}$ as the posterior mean of $\\boldsymbol{\\theta}$.\n\n- The effective number of parameters is $p_D = \\bar{D} âˆ’ D(\\mathbf{Y}| \\hat{\\boldsymbol{\\theta}})$.\n\n- DIC can be written like AIC,\n\n$$DIC = \\bar{D} + p_D =D(\\mathbf{Y}| \\hat{\\boldsymbol{\\theta}}) + 2p_D$$\n\n- Models with small $\\bar{D}$ fit the data well.\n\n- Models with small $p_D$ are simple.\n\n- We select the model with smallest DIC.\n\n## Deviance information criteria (DIC)\n\n- The effective number of parameters is a useful measure of model complexity\n\n- Intuitively, if there are $p$ parameters and we have uninformative priors then $p_D \\approx p$\n\n- However, $p_D \\ll p$ if there are strong priors.\n\n- As with AIC or BIC, the actual value is meaningless, only differences are relevant.\n\n- DIC can only be used to compare models with the same likelihood.\n\n## Watanabe-Akaike information criteria (WAIC)\n\n- WAIC is an alternative to DIC\n\n- It is motivated as an approximation to leave-one-out CV\n\n- In the end WAIC has model-fit and model-complexity components\n\n- It is used the same as DIC with smaller WAIC preferred\n\n- In practice the two often give similar results, but WAIC is arguably more theoretically justified\n\n## Watanabe-Akaike information criteria (WAIC)\n\n- WAIC is written in terms of the posterior of the likelihood rather than parameters\n\n- Let $m_i$ be the posterior mean of $f(Y_i|\\boldsymbol{\\theta})$\nand $v_i$ be the posterior variance of $\\log f(Y_i|\\boldsymbol{\\theta})$\n\n- The effective model size is $p_W = \\sum_{i=1}^n v_i$\n\n- The criteria is\n\n$$WAIC = âˆ’2 \\sum_{i=1}^n \\log (m_i) + 2p_W$$\n\n## Cross-validation\n\n-   **Cross-validation** is a strategy for estimating a modelâ€™s predictive accuracy on another sample.\n\n-   Cross-validation methods capture out-of-sample prediction error by fitting the model to training data and evaluating this predictive accuracy on a holdout set. \n\n-   They can be computationally expensive but avoid the problem of overfitting.\n\n-   The sample data is divided into a number of chunks, called \"folds\" and the model is asked to predict each fold, after training on all the others. The number of folds is given by $k$.\n\n-   **Leave-one-out cross-validation (LOO-CV)** represents cross-validation at the extreme, when $k = n$.\n\n## Leave-one-out cross-validation\n\n-   It is computationally costly to compute LOO-CV, since it requires fitting the model $n$ times.\n\n-   Luckily, there exists an approximation to LOO-CV using Pareto smoothed importance-sampling by [Vehtari, Gelman, and Gabry (2017)](https://arxiv.org/abs/1507.04544).\n\n-   This can be computed easily using R.\n\n## Computing WAIC using Stan\n\nWe need to update the **generated quantities** code block.\n\n\n\n::: {.cell output.var='waic'}\n\n```{.stan .cell-code}\ngenerated quantities {\n  ...\n  vector[n] log_lik;\n  for (i in 1:n) log_lik[i] = normal_lpdf(Y[i] | X[i, ] * beta, sigma);\n}\n```\n:::\n\n\n\n## Let's refit the Stan model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Create stan data object\nstan_data <- list(n = n, p = p, Y = Y, X = X,\n                  beta0 = 0, sigma_beta = 10, a = 3,  b = 1,\n                  n_pred = n_pred, X_pred = X_pred)\n  \n###Compile model separately\nstan_model <- stan_model(file = \"linear_regression_ppd_log_lik.stan\")\n\n###Run model and save\nfit <- sampling(stan_model, data = stan_data, \n                chains = 4, iter = 1000)\nsaveRDS(fit, file = \"linear_regression_ppd_log_lik_fit.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## We can now compute the WAIC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(loo)\nlog_lik <- loo::extract_log_lik(fit, parameter_name = \"log_lik\", \n                           merge_chains = TRUE)\nwaic_fit <- loo::waic(log_lik)\nprint(waic_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 2000 by 100 log-likelihood matrix.\n\n          Estimate   SE\nelpd_waic   -188.4  7.4\np_waic         3.2  0.6\nwaic         376.9 14.7\n```\n\n\n:::\n:::\n\n\n\n\n## 8. Compare models\n\n- Suppose we would like to predict weight and we would like to compare our original model with a model that also includes sex. We can compare these models using WAIC.\n\n## Prepare for next class\n\n-   Work on [HW 01](https://biostat725-sp25.netlify.app/hw/hw-01) which is due before next class\n\n-   Complete reading to prepare for next Thursday's lecture\n\n-   Thursday's lecture: Bayesian Workflow\n",
    "supporting": [
      "07-workflow_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}