{
  "hash": "51a8b55967b62528c3be6e507a380c08",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Probabilistic Programming (Intro to Stan!)\"\nauthor: \"Prof. Sam Berchuck\"\ndate: \"2025-01-21\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    html-math-method: mathjax\nfilters:\n  - parse-latex\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Review of last lecture\n\nOn Thursday, we performed posterior inference for Bayesian linear regression using Gibbs and Metropolis sampling.\n\n-   We obtained correlated samples from the posterior using MCMC.\n\n-   Gibbs required a lot math!\n\n-   Metropolis required tuning!\n\nToday we will introduce Stan, a probabilistic programming language that uses Hamiltonian Monte Carlo to perform general Bayesian inference.\n\n## Learning objectives\n\nBy the end of this lecture you should:\n\n-   Know how to start coding up a model in Stan.\n\n-   Appreciate how easy Stan makes things for us compared to coding up the algorithm ourselves.\n\n-   Be able to fit a basic linear regression in Stan.\n\n## What is Stan and how do we use it?\n\n-   Stan is an intuitive yet sophisticated programming language that does the hard work for us.\n\n-   Programming language like R, Python, Matlab, C++...\n\n-   Works like most other languages: can use loops, conditional statements, and functions.\n\n-   Code up a model in Stan and then it implements HMC (actually something called NUTS) for us.\n\n## Why should we use Stan?\n\n-   Stan is the brainchild of Andrew Gelman at Colombia.\n\n-   Stan uses an extension of HMC called NUTS that automatically tunes. It is fast.\n\n-   Stan is simple to learn.\n\n-   Stan has excellent [documentation](https://mc-stan.org/docs/) (a manual full of extensive examples).\n\n-   **Most important:** Stan has a very active and helpful [user forum](https://discourse.mc-stan.org/) and development team; for example, typical question answered in less than a couple of hours.\n\n## How do we use it?\n\nCode up model in Stan code in a text editor and save as `.stan` file.\n\n-   Call Stan to run the model from:\n\n    -   R, python, the command line, Matlab, Stata, Julia\n\n-   Use one of the above to analyse the data (of course you can export to another one).\n\n## A straightforward example {.midi}\n\nSuppose:\n\n-   We record the height, $Y_i$, of 10 people.\n\n-   We want a model to explain the variation, and choose a normal likelihood: $$Y_i \\sim N(\\mu, \\sigma^2)$$\n\n-   We choose the following (independent) priors on each parameter:\n\n    -   $\\mu \\sim N(0, 1)$\n    -   $\\sigma^2 \\sim IG(1, 1)$\n\n-   **Question:** how do we code this up in Stan?\n\n## An example Stan program\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\ndata {\n  real Y[10]; // height for 10 people\n}\nparameters {\n  real mu;\n  real<lower = 0> sigma2;\n}\nmodel {\n  Y ~ normal(mu, sqrt(sigma2)); // likelihood\n  mu ~ normal(0, 1); // prior for mu\n  sigma2 ~ inv_gamma(1, 1); // prior for sigma\n}\n```\n:::\n\n\n\n## An example Stan program: data block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\ndata {\n  real Y[10]; // height for 10 people\n}\n```\n:::\n\n\n\n-   Declare all data that you will pass to Stan to estimate your model.\n\n-   Terminate all statements with a semi-colon `;`.\n\n-   Use `##` or `//` for comments.\n\n## An example Stan program: data block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\ndata {\n  real Y[10]; // height for 10 people\n}\n```\n:::\n\n\n\n-   We need to tell Stan the type of data variable. For example:\n\n    -   `real` for continuous data.\n\n    -   `int` for discrete data.\n\n    -   Arrays: above we specified `Y` as an array of continuous data of length 10.\n\n## An example Stan program: data block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\ndata {\n  real Y[10]; // height for 10 people\n}\n```\n:::\n\n\n\nCan place limits on data, for example:\n\n-   `real<lower = 0, upper = 1> X;`\n\n-   `real<lower = 0> Z;`\n\nVectors and matrices; only contain reals and can be used for matrix operations.\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nreal Y[10]; // array representation\nvector[10] Y; // vector representation\n```\n:::\n\n\n\n## An example Stan program: parameter block {.midi}\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nparameters {\n  real mu;\n  real<lower = 0> sigma2;\n}\n```\n:::\n\n\n\n-   Declare all parameters that you use in your model.\n\n-   Place limits on variables, for example:\n\n    -   `real<lower = 0> sigma2`\n\nA multitude of parameter types including some of the aforementioned:\n\n-   `real` for continuous parameters.\n\n-   Arrays of types, for example `real beta[10]`\n\n## An example Stan program: parameter block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nparameters {\n  real mu;\n  real<lower = 0> sigma2;\n}\n```\n:::\n\n\n\n-   `vector` or `matrix`, specified by:\n\n    -   `vector[5] beta`\n\n    -   `matrix[5, 3] gamma`\n\n-   `simplex` for a parameter vector that must sum to 1.\n\n-   More exotic types like `corr_matrix`, or `ordered`.\n\n## An example Stan program: parameter block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nparameters {\n  real mu;\n  real<lower = 0> sigma2;\n}\n```\n:::\n\n\n\n**Important:** Stan is not developed yet to work with discrete parameters. Options for discrete parameters in Stan:\n\n-   Marginalize out the parameter. For example, suppose we have $f(\\boldsymbol{\\beta}, \\theta)$, where $\\boldsymbol{\\beta}$ is continuous and $\\theta$ is discrete:\n\n\\begin{center}$f(\\boldsymbol{\\beta}) = \\sum_{i = 1}^K f(\\boldsymbol{\\beta}, \\theta_i)$\\end{center}\n\n-   Some models can be reformulated without discrete parameters.\n\n## An example Stan program: model block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nmodel {\n  Y ~ normal(mu, sqrt(sigma2)); // likelihood\n  mu ~ normal(0, 1); // prior for mu\n  sigma2 ~ inv_gamma(1, 1); // prior for sigma2\n}\n```\n:::\n\n\n\n-   Used to define:\n\n    -   Likelihood.\n\n    -   Priors on parameters.\n\nIf donâ€™t specify priors on parameters Stan assumes you are using flat priors (which can be improper).\n\n## An example Stan program: model block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nmodel {\n  Y ~ normal(mu, sqrt(sigma2)); // likelihood\n  mu ~ normal(0, 1); // prior for mu\n  sigma2 ~ inv_gamma(1, 1); // prior for sigma2\n}\n```\n:::\n\n\n\nHuge range of probability distributions covered, across a range of parameterizations. For example:\n\n-   **Discrete:** Bernoulli, binomial, Poisson, beta-binomial, negative-binomial, categorical, multinomial.\n\n-   **Continuous unbounded:** normal, skew-normal, student-t, Cauchy, logistic.\n\n## An example Stan program: model block\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nmodel {\n  Y ~ normal(mu, sqrt(sigma2)); // likelihood\n  mu ~ normal(0, 1); // prior for mu\n  sigma2 ~ inv_gamma(1, 1); // prior for sigma2\n}\n```\n:::\n\n\n\n-   **Continuous bounded:** uniform, beta, log-normal, exponential, gamma, chi-squared, inverse-chi-squared, Weibull, Wiener diffusion, Pareto.\n\n-   **Multivariate continuous:** normal, student-t, Gaussian process.\n\n-   **Exotics:** Dirichlet, LKJ correlation distribution, Wishart and its inverse, Von-Mises.\n\n## Running Stan\n\nWrite model in a text editing program and save as a `.stan` file.\n\n-   To create a `.stan` file from RStudio, `File -> New File -> Stan File`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Load packages\nlibrary(rstan)\n\n###Generate fake data\nY <- rnorm(10, mean = 0, sd = 1)\n\n###Compile and run model, and save in fit\nfit <- stan(file = 'straightforward.stan', data = list(Y = Y), \n            iter = 1000, chains = 4, seed = 1)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## Running Stan on example model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Compile and run model, and save in fit\nfit <- stan(file = 'straightforward.stan', data = list(Y = Y), \n            iter = 1000, chains = 4, seed = 1)\n```\n:::\n\n\n\nThe above R code runs NUTS for our model with the following options:\n\n-   $S=1,000$ MCMC samples of which 500 are discarded as warm-up.\n\n-   Across 4 chains.\n\n-   Using a random number seed of 1 (good to ensure you can reproduce results).\n\n## Example model: results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Print summary statistics\nprint(fit, probs = c(0.25, 0.5, 0.75))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for Stan model: anon_model.\n4 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=2000.\n\n        mean se_mean   sd   25%   50%   75% n_eff Rhat\nmu     -0.45    0.01 0.32 -0.66 -0.46 -0.26  1361    1\nsigma2  1.23    0.02 0.62  0.81  1.09  1.48   865    1\nlp__   -6.80    0.04 1.03 -7.21 -6.49 -6.06   808    1\n\nSamples were drawn using NUTS(diag_e) at Tue Jan 21 14:36:33 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n```\n\n\n:::\n:::\n\n\n\n## Example model: results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Extract posterior samples\npars <- extract(fit)\nclass(pars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"list\"\n```\n\n\n:::\n\n```{.r .cell-code}\nnames(pars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"mu\"     \"sigma2\" \"lp__\"  \n```\n\n\n:::\n\n```{.r .cell-code}\n###Extract samples for particular parameters\npars <- extract(fit, pars = \"mu\")\nclass(pars$mu)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"array\"\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(pars$mu)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2000\n```\n\n\n:::\n:::\n\n\n\n## Visualize posterior\n\n\n\n::: {.cell layout-nrow=\"1\" layout-align=\"center\"}\n\n```{.r .cell-code}\n###Extract samples for particular parameters\nlibrary(ggplot2)\ndata.frame(mu = pars$mu) |>\n  ggplot(aes(x = mu)) +\n  geom_histogram() +\n  labs(x = expression(mu), y = \"Count\", \n       subtitle = bquote(\"Posterior distribution for \" ~ mu))\n```\n\n::: {.cell-output-display}\n![](04-stan_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## Quick note: what does $\\sim$ mean? {.midi}\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nmodel {\n  Y ~ normal(mu, sigma); // likelihood\n  mu ~ normal(0, 1); // prior for mu\n  sigma ~ inv_gamma(1, 1); // prior for sigma\n}\n```\n:::\n\n\n\n-   $\\sim$ doesn't mean *sampling*, although often times it can be thought of as sampling\n\n-   MCMC/HMC makes use of the log-posterior\n\n$$\\log f(\\boldsymbol{\\theta} | \\mathbf{Y}) \\propto \\log f(\\boldsymbol{\\theta}) + \\sum_{i=1}^n \\log f({Y}_i | \\boldsymbol{\\theta})$$\n\n-   As such $\\sim$ really means *increment log probability*\n\n-   All we have to do in Stan is specify the log-posterior!\n\n## Alternate way of specifying Stan models {.midi}\n\n\n\n::: {.cell output.var='straightforward'}\n\n```{.stan .cell-code}\nmodel {\n  target += normal_lpdf(Y | mu, sqrt(sigma2)); // likelihood\n  target += normal_lpdf(mu | 0, 1); // prior for mu\n  target += inv_gamma_lpdf(sigma2 | 1, 1); // prior for sigma\n}\n```\n:::\n\n\n\n-   `target` is a not a variable, but a special object that represents incremental log probability.\n\n-   `target` is initialized to zero.\n\n-   `normal_lpdf` is the log of the normal density of `y` given location `mu` and scale `sigma`:\n\n-   [Stan documentation for normal distribution](https://mc-stan.org/docs/functions-reference/unbounded_continuous_distributions.html#normal-distribution)\n\n\n\n::: {.cell output.var='std_normal'}\n\n```{.stan .cell-code}\ntarget += std_normal_lpdf(mu) // prior for mu using standard normal\n```\n:::\n\n\n\n## Linear regression using Stan: data and parameter chunks\n\n\n\n::: {.cell output.var='linear_regression'}\n\n```{.stan .cell-code}\ndata {\n  int<lower = 1> n; // number of observations\n  int<lower = 1> p; // number of covariates\n  vector[n] Y; // outcome vector\n  matrix[n, p + 1] X; // covariate vector\n  real beta0; // location hyperparameter for beta\n  real<lower = 0> sigma_beta; // scale hyperparameter for beta\n  real<lower = 0> a; // shape hyperparameter for sigma2\n  real<lower = 0> b; // scale hyperparameter for sigma2\n}\nparameters {\n  vector[p + 1] beta;\n  real<lower = 0> sigma2;\n}\n```\n:::\n\n\n\n## Linear regression using Stan: model chunk\n\n\n\n::: {.cell output.var='linear_regression'}\n\n```{.stan .cell-code}\nmodel {\n  for (i in 1:n) {\n    target += normal_lpdf(Y[i] | X[i, ] * beta, sqrt(sigma2)); // likelihood\n  }\n  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta\n  target += inv_gamma_lpdf(sigma2 | a, b); // prior for sigma2\n}\n```\n:::\n\n\n\n## Linear regression using Stan: vectorization\n\nIt is always a good idea to vectorize Stan code for faster and more efficient inference\n\n\n\n::: {.cell output.var='linear_regression'}\n\n```{.stan .cell-code}\nmodel {\n  target += normal_lpdf(Y | X * beta, sqrt(sigma2)); // likelihood\n  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta\n  target += inv_gamma_lpdf(sigma2 | a, b); // prior for sigma2\n}\n```\n:::\n\n\n\n## Linear regression using Stan\n\n\n\n::: {.cell output.var='linear_regression'}\n\n```{.stan .cell-code}\n// saved in linear_regression.stan\ndata {\n  int<lower = 1> n; // number of observations\n  int<lower = 1> p; // number of covariates\n  vector[n] Y; // outcome vector\n  matrix[n, p + 1] X; // covariate vector\n  real beta0; // location hyperparameter for beta\n  real<lower = 0> sigma_beta; // scale hyperparameter for beta\n  real<lower = 0> a; // shape hyperparameter for sigma2\n  real<lower = 0> b; // scale hyperparameter for sigma2\n}\nparameters {\n  vector[p + 1] beta;\n  real<lower = 0> sigma2;\n}\nmodel {\n  target += normal_lpdf(Y | X * beta, sqrt(sigma2)); // likelihood\n  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta\n  target += inv_gamma_lpdf(sigma2 | a, b); // prior for sigma2\n}\n```\n:::\n\n\n\n## Let's simulate some data again\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###True parameters\nsigma <- 1.5 # true measurement error\nbeta <- matrix(c(-1.5, 3), ncol = 1) # true beta\n\n###Simulation settings\nn <- 100 # number of observations\np <- length(beta) - 1 # number of covariates\n\n###Simulate data\nset.seed(54) # set seed\nX <- cbind(1, matrix(rnorm(n * p), ncol = p))\nY <- as.numeric(X %*% beta + rnorm(n, 0, sigma))\n```\n:::\n\n\n\n## Fit linear regression using Stan\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Load packages\nlibrary(rstan)\n\n###Create stan data object\nstan_data <- list(n = n,\n                  p = p,\n                  Y = Y,\n                  X = X,\n                  beta0 = 0,\n                  sigma_beta = 10,\n                  a = 3, \n                  b = 1)\n  \n###Compile model separately\nstan_model <- stan_model(file = \"linear_regression.stan\")\n\n###Run model and save\nfit <- sampling(stan_model, data = stan_data, \n                chains = 4, iter = 1000)\nsaveRDS(fit, file = \"linear_regression_fit.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## Example model: results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Print summary statistics\nprint(fit, probs = c(0.25, 0.5, 0.75))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for Stan model: anon_model.\n4 chains, each with iter=1000; warmup=500; thin=1; \npost-warmup draws per chain=500, total post-warmup draws=2000.\n\n           mean se_mean   sd     25%     50%     75% n_eff Rhat\nbeta[1]   -1.48    0.00 0.15   -1.58   -1.48   -1.37  1951    1\nbeta[2]    3.30    0.00 0.15    3.20    3.30    3.40  1674    1\nsigma2     2.35    0.01 0.33    2.12    2.32    2.55  1679    1\nlp__    -196.98    0.04 1.29 -197.58 -196.63 -196.04   899    1\n\nSamples were drawn using NUTS(diag_e) at Tue Jan 21 14:38:36 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n```\n\n\n:::\n:::\n\n\n\n## Stan plots: point estimate and intervals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_plot(fit, pars = c(\"beta\", \"sigma2\"), include_warmup = FALSE,\n          point_est = \"median\", ci_level = 0.8, outer_level = 0.95)\n```\n\n::: {.cell-output-display}\n![](04-stan_files/figure-revealjs/unnamed-chunk-30-1.png){width=960}\n:::\n:::\n\n\n\n## Stan plots: histogram\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_hist(fit)\n```\n\n::: {.cell-output-display}\n![](04-stan_files/figure-revealjs/unnamed-chunk-31-1.png){width=960}\n:::\n:::\n\n\n\n## Stan plots: density\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstan_dens(fit)\n```\n\n::: {.cell-output-display}\n![](04-stan_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n\n## Stan: a few of the loops and conditions\n\nStan has pretty much the full range of language constructs to allow pretty much any model to be coded.\n\n`for (i in 1:10) {something;}`\\\n\\\n\n`while (i > 1) {something;}`\\\n\\\n\n`if (i > 1) {something 1;}`\\\n`else if (i == 0) {something2;}`\\\n`else {something 3;}`\n\n## Stan speed concerns\n\nWhile Stan is fast it pays to know the importance of each code block for efficiency.\n\n-   **data:** called once at beginning of execution.\n\n-   **transformed data:** called once at beginning of execution.\n\n-   **parameters:** every log probability evaluation!\n\n-   **transformed parameters:** every log probability evaluation!\n\n-   **model:** every log probability evaluation!\n\n-   **generated quantities:** once per sample.\n\n-   **functions:** how many times it is called depends on the function's nature.\n\n## Stan in parallel\n\nIn R can run chains in parallel easily using:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstan)\noptions(mc.cores = 8)\n```\n:::\n\n\n\n## Stan summary\n\n-   Stan works by default with a HMC-like algorithm called NUTS.\n\n-   The Stan language is similar in nature to other common languages with loops, conditional statements and user-definable functions (didnâ€™t cover here).\n\n-   Stan makes life easier for us than coding up the MCMC algorithms ourselves.\n\n## R packages that interface with Stan {.midi}\n\n-   `rstan`, `brms`, `cmdstanr`, `rstanarm`\n\n-   `rstan` and `cmdstanr` you write the Stan code, which gives you the most options.\n\n    -   `rstan` has a more intuitive user interface.\n\n    -   `cmdstanr` is more memory efficient and a lightweight interface to Stan.\n\n-   `rstanarm` and `brms` you don't need to write the Stan code yourself, which makes it easier to use Stan, but is limiting.\n\n    -   `rstanarm`'s biggest advantage is that the models are pre-compiled, but this is also it's biggest limitation.\n\n    -   `brms` writes Stan code on the fly, so has many more models, some that are pretty advanced.\n\n## Prepare for next class\n\n-   Work on [HW 01](https://biostat725-sp25.netlify.app/hw/hw-01) which is due January 30\n\n-   Complete reading to prepare for next Thursday's lecture\n\n-   Thursday's lecture: Priors, Posteriors, and PPDs!\n",
    "supporting": [
      "04-stan_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}