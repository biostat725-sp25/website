{
  "hash": "abc88d9be92d5b8912a7744e46de4cba",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Markov chain Monte Carlo\"\nauthor: \"Prof. Sam Berchuck\"\ndate: \"2025-01-16\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    html-math-method: mathjax\nfilters:\n  - parse-latex\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Review of last lecture\n\n-   On Tuesday, we performed posterior inference for a Beta-Binomial model using Monte Carlo estimation.\n\n-   Today we will discuss Bayesian estimation of linear regression:\n\n$$\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2 \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n).$$\n\n-   There is no closed form posterior, so we cannot directly use Monte Carlo sampling.\n\n-   We need Markov chain Monte Carlo (MCMC)!\n\n-   Our goal is to gain intuition behind MCMC, the workhorse behind Stan.\n\n# Bayesian Linear Regression\n\n## Defining the model\n\nSuppose we have an observation $Y_i$ for subject $i$ ($i=1,\\ldots,n$), that is modeled as follows,\n\n\\begin{align*}\nY_i &= \\beta_0 + x_{i1} \\beta_1 + \\cdots + x_{ip} \\beta_p + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2)\\\\\n&= \\mathbf{x}_i \\boldsymbol{\\beta} + \\epsilon_i.\n\\end{align*}\n\n-   $\\mathbf{x}_i = (1, x_{i1},\\ldots,x_{ip})$ is a $(p+1)$-dimensional row vector of covariates (and intercept).\n-   $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1,\\ldots,\\beta_p)^\\top$ is a $(p+1)$-dimensional column vector of population regression parameters.\n-   $\\epsilon_i$ is a Gaussian measurement error term with variance $\\sigma^2$.\n\n## Defining the likelihood\n\nThe individual likelihood contribution for subject $i$ is given by, $$Y_i|\\boldsymbol{\\beta},\\sigma^2 \\sim N(\\mathbf{x}_i \\boldsymbol{\\beta}, \\sigma^2) \\Leftrightarrow f(Y_i|\\boldsymbol{\\beta},\\sigma^2) = N(\\mathbf{x}_i \\boldsymbol{\\beta}, \\sigma^2),$$ and the full data likelihood (or observed data likelihood) is given by, $$f(\\mathbf{Y} | \\boldsymbol{\\beta},\\sigma^2) = \\prod_{i=1}^n f(Y_i|\\boldsymbol{\\beta},\\sigma^2),$$ where $\\mathbf{Y} = (Y_1,\\ldots,Y_n)$.\n\n## Matrix likelihood specification\n\nWe can also write the likelihood directly, $$\\mathbf{Y} | \\boldsymbol{\\beta},\\sigma^2 \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n),$$ where $\\mathbf{X}$ is an $n \\times (p + 1)$ dimensional matrix with row $\\mathbf{x}_i$ and $\\mathbf{I}_n$ is an $n$-dimensional identity matrix. Thus, the mean of the observed data is modeled as a linear function of the parameters,\n\n$$\n\\mathbb{E}[ \\mathbf{Y} | \\boldsymbol{\\beta},\\sigma^2 ]  =\n  \\begin{bmatrix}\n    1 & x_{12} & \\ldots & x_{1p} \\\\\n    1 & x_{22} & \\ldots & x_{2p} \\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    1 & x_{n2} & \\ldots & x_{np}\n  \\end{bmatrix}\n    \\begin{bmatrix}\n    \\beta_0\\\\\n    \\beta_1\\\\\n    \\vdots\\\\\n    \\beta_p\n  \\end{bmatrix} = \\mathbf{X} \\boldsymbol{\\beta}.\n$$\n\n## Linear regression estimation\n\n-   Ordinary least squares (OLS)\n\n<center>$\\hat{\\boldsymbol{\\beta}}_{\\text{OLS}} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}} || \\mathbf{Y} - \\mathbf{X}\\boldsymbol{\\beta}||^2$</center>\n\n-   Maximum likelihood estimation (MLE)\n\n<center>$\\hat{\\boldsymbol{\\beta}}_{\\text{MLE}} = \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmax}} f(\\mathbf{Y} | \\boldsymbol{\\beta})$</center>\n\n-   $\\hat{\\boldsymbol{\\beta}}_{\\text{OLS}} = \\hat{\\boldsymbol{\\beta}}_{\\text{MLE}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1}\\mathbf{X}^\\top \\mathbf{Y}$\n\n## Posterior for linear regression\n\n\\begin{align*}\nf(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}) &= \\frac{f(\\mathbf{Y}, \\boldsymbol{\\beta}, \\sigma^2)}{f(\\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)}{f(\\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)}{\\int f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)d\\boldsymbol{\\beta}d\\sigma^2}.\n\\end{align*}\n\nNo closed form exists for the posterior. $$f(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)$$\n\n# Gibbs Sampling\n\n## Motivation for Gibbs sampling\n\n-   Suppose we were given $\\sigma^{2(1)}$, a single sample from the marginal posterior distribution $f\\left(\\sigma^2|\\mathbf{Y}\\right)$ (from where, who knows?)\n\n-   Use the sample to generate $\\boldsymbol{\\beta}^{(1)}$ from $f\\left(\\boldsymbol{\\beta}|\\mathbf{Y},\\sigma^{2(1)}\\right)$\n\n-   $\\left(\\boldsymbol{\\beta}^{(1)},\\sigma^{2(1)}\\right)$ is a sample from $f\\left(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}\\right)$\n\n-   $\\boldsymbol{\\beta}^{(1)}$ is a sample from $f\\left(\\boldsymbol{\\beta} | \\mathbf{Y}\\right)$\n\n. . .\n\n::: callout-important\n## Recall\n\n$f\\left(\\boldsymbol{\\beta}, \\sigma^{2}|\\mathbf{Y}\\right) = f\\left(\\boldsymbol{\\beta} | \\sigma^{2},\\mathbf{Y}\\right)f\\left(\\sigma^{2}|\\mathbf{Y}\\right)$\n:::\n\n## Gibbs sampler for linear regression\n\nSuppose we can sample from the following two distribution,\n\n1.  $f(\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^2) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta})$\n\n2.  $f(\\sigma^2 | \\mathbf{Y}, \\boldsymbol{\\beta}) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\sigma^2)$\n\nThese are called **full conditional distributions**.\n\nSet initial values for $\\boldsymbol{\\theta}^{(0)} = (\\boldsymbol{\\beta}^{(0)}, \\sigma^{2(0)})$. Then, given a current state of parameters $\\boldsymbol{\\theta}^{(s)}$, we can generate a new state as follows:\n\n1.  Sample $\\boldsymbol{\\beta}^{(s + 1)} \\sim f(\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^{2(s)})$\n\n2.  Sample $\\sigma^{2(s + 1)} \\sim f(\\sigma^2 | \\mathbf{Y}, \\boldsymbol{\\beta}^{(s + 1)})$\n\n3.  Let $\\boldsymbol{\\theta}^{(s+1)} = (\\boldsymbol{\\beta}^{(s + 1)}, \\sigma^{2(s + 1)})$\n\n## Why does this work?\n\n-   $\\boldsymbol{\\theta}^{(0)}$ isnâ€™t a sample from the posterior, it is an arbitrarily chosen initial value\n\n-   $\\boldsymbol{\\theta}^{(1)}$ likely isnâ€™t from the posterior either. Its distribution depends on $\\boldsymbol{\\theta}^{(0)}$\n\n-   $\\boldsymbol{\\theta}^{(2)}$ likely isnâ€™t from the posterior either. Its distribution depends on $\\boldsymbol{\\theta}^{(0)}$ and $\\boldsymbol{\\theta}^{(1)}$\n\n-   **Theorem:** For any initial values, the chain will eventually converge to the posterior\n\n-   **Theorem:** If $\\boldsymbol{\\theta}^{(s)}$ is a sample from the posterior, then $\\boldsymbol{\\theta}^{(s+1)}$ is too\n\n## Gibbs sampler\n\n-   Under mild regulatory conditions that are generally satisfied for most statistical models, one can show that the iteration $\\boldsymbol{\\theta}^{(s)}$ converges in distribution to a draw from the true joint posterior distribution\n\n-   So for $s$ sufficiently large (say, bigger than $s_0$), $\\left\\{\\boldsymbol{\\theta}^{(s)}, s=s_0+1,\\ldots,S\\right\\}$ is a **correlated** sample from the true joint posterior (and $\\boldsymbol{\\beta}^{(s)}$ and $\\sigma^{2(s)}$ are samples from the marginals)\n\n-   Similar to Monte Carlo approximation, we can use these samples to estimate posterior quantities of interest\n\n## Gibbs sampler\n\n-   $\\boldsymbol{\\theta}^{(t)}$ depends on $\\boldsymbol{\\theta}^{(0)},\\ldots,\\boldsymbol{\\theta}^{(t-1)}$ only through $\\boldsymbol{\\theta}^{(t-1)}$\n\n-   $\\boldsymbol{\\theta}^{(t)}$ is conditionally independent of $\\boldsymbol{\\theta}^{(0)},\\ldots,\\boldsymbol{\\theta}^{(t-2)}$ given $\\boldsymbol{\\theta}^{(t-1)}$\n\n    $\\implies$ Markov property, so the sequence is called a Markov chain\n\n-   We use the samples similar to MC approximation; therefore, Gibbs sampling is a form of Markov chain Monte Carlo (MCMC)\n\n-   We will cover diagnostics for MCMC in another lecture!\n\n## Gibbs sampler for linear regression\n\n-   We need to compute the full conditionals. Before doing this, we require prior distributions.\n\n-   Let's assume that the prior for $\\boldsymbol{\\beta}$ is Gassian,\n\n$$f(\\boldsymbol{\\beta}) = N(\\boldsymbol{\\beta}_0,\\sigma_{\\beta}^2 \\mathbf{I}_{p+1}).$$\n\n-   $\\boldsymbol{\\beta}_0$ is the prior mean (i.e., our a-priori guess for the likely value of $\\boldsymbol{\\beta}$)\n-   $\\sigma_{\\beta}^2$ is the prior variance (i.e., encodes our certainty for our a-priori guess)\n\n## Full conditional for $\\boldsymbol{\\beta}$ {.small}\n\n\\begin{align*}\nf(\\boldsymbol{\\beta},\\sigma^2 | \\mathbf{Y}) &\\propto f(\\mathbf{Y} | \\boldsymbol{\\beta},\\sigma^2) f(\\boldsymbol{\\beta})\\\\\n&\\propto \\exp\\left\\{-\\frac{1}{2}\\left[\\frac{\\left(\\mathbf{Y} - \\mathbf{X}\\boldsymbol{\\beta}\\right)^\\top\\left(\\mathbf{Y} - \\mathbf{X}\\boldsymbol{\\beta}\\right)}{\\sigma^2}\\right]\\right\\}\\\\\n&\\quad \\times \\exp\\left\\{-\\frac{1}{2}\\left[\\frac{\\left(\\boldsymbol{\\beta} - \\boldsymbol{\\beta}_0\\right)^\\top\\left(\\boldsymbol{\\beta}_0 - \\boldsymbol{\\beta}_0\\right)}{\\sigma_{\\beta}^2}\\right]\\right\\}\\\\\n&\\propto \\exp\\left\\{-\\frac{1}{2}\\left[\\boldsymbol{\\beta}^\\top\\left(\\frac{\\mathbf{X}^\\top \\mathbf{X}}{\\sigma^2} + \\frac{\\mathbf{I}_n}{\\sigma_{\\beta}^2} \\right)\\boldsymbol{\\beta} - 2\\boldsymbol{\\beta}^\\top\\left(\\frac{\\mathbf{X}^\\top\\mathbf{Y}}{\\sigma^2} + \\frac{\\boldsymbol{\\beta}_0}{\\sigma_{\\beta}^2}\\right)\\right]\\right\\}\\\\\n&\\propto \\exp\\left\\{-\\frac{1}{2}\\left[\\boldsymbol{\\beta}^\\top\\mathbf{A}\\boldsymbol{\\beta} - 2\\boldsymbol{\\beta}^\\top\\mathbf{a}\\right]\\right\\}\n\\end{align*}\n\nThis is the kernel of a multivariate normal for $\\boldsymbol{\\beta}$, with $\\mathbf{A} = \\boldsymbol{\\Sigma}^{-1}$ and $\\mathbf{a} = \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}$. It's easy to see then that, $f(\\boldsymbol{\\beta} | \\mathbf{Y}) = N(\\mathbf{A}^{-1}\\mathbf{a},\\mathbf{A}^{-1}).$\n\n::: callout-note\n## Recall the kernel for the multivariate normal: $\\exp\\left\\{-\\frac{1}{2}\\left[\\mathbf{Y}^\\top \\boldsymbol{\\Sigma}^{-1}\\mathbf{Y} - 2\\mathbf{Y}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}\\right]\\right\\}$\n:::\n\n## Full conditional for $\\boldsymbol{\\beta}$ {.midi}\n\nThe full conditional can be found in closed-form and is Gaussian with the following moments: \\begin{align*}\n\\mathbb{V}(\\boldsymbol{\\beta} | \\mathbf{Y},\\sigma^2) &= \\left(\\frac{\\mathbf{I}_{p+1}}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{X}}{\\sigma^2}\\right)^{-1}\\\\\n\\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y},\\sigma^2] &= \\left(\\frac{\\mathbf{I}_{p+1}}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{X}}{\\sigma^2}\\right)^{-1}\\left(\\frac{\\boldsymbol{\\beta}_0}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{Y}}{\\sigma^2}\\right)\n\\end{align*}\n\n. . .\n\n-   $\\sigma_{\\beta}^2 \\rightarrow \\infty: \\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y},\\sigma^2] = (\\mathbf{X}^\\top \\mathbf{X})^{-1}\\mathbf{X}^\\top \\mathbf{Y} = \\hat{\\boldsymbol{\\beta}}_{\\text{OLS}} = \\hat{\\boldsymbol{\\beta}}_{\\text{MLE}}$\n\n. . .\n\n-   $\\sigma^2 \\rightarrow \\infty: \\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y},\\sigma^2] = \\boldsymbol{\\beta}_0$\n\n## Full conditional for $\\sigma^2$\n\nFull conditional for $\\sigma^2$, assuming $f(\\sigma^2) \\sim IG(a, b)$:\n\n$$\\sigma^2 |  \\mathbf{Y} , \\boldsymbol{\\beta} \\sim IG\\left(a + \\frac{n}{2},b+\\frac{\\left(\\mathbf{Y}-\\mathbf{X}\\boldsymbol{\\beta}\\right)^\\top\\left(\\mathbf{Y}-\\mathbf{X}\\boldsymbol{\\beta}\\right)}{2}\\right)$$\n\n-   Why inverse-Gamma ($IG$) distribution for $\\sigma^2$?\n\n## Sampling from the posterior\n\nLet's simulate some data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###True parameters\nsigma <- 1.5 # true measurement error\nbeta <- matrix(c(-1.5, 3), ncol = 1) # true beta\n\n###Simulation settings\nn <- 100 # number of observations\np <- length(beta) - 1 # number of covariates\n\n###Simulate data\nset.seed(54) # set seed\nX <- cbind(1, matrix(rnorm(n * p), ncol = p))\nY <- as.numeric(X %*% beta + rnorm(n, 0, sigma))\n```\n:::\n\n\n\n## Visualize simulated data\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=384}\n:::\n\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-3-2.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## Inspecting the prior\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###Define hyperparameters\nbeta0 <- matrix(0, nrow = p + 1, ncol = 1)\nsigma_beta <- 10\na <- 3\nb <- 1\n```\n:::\n\n::: {.cell layout-ncol=\"3\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=384}\n:::\n\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-5-2.png){fig-align='center' width=384}\n:::\n\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-5-3.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n## Perform Gibbs sampling\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- exp(rnorm(1)) # initial value\nsamples <- NULL\nfor (s in 1:5000) {\n  ###Sample from full conditional for beta\n  var_beta <- chol2inv(chol(t(X) %*% X / sigma2 + diag(p + 1) / sigma_beta^2))\n  mean_beta <- var_beta %*% (beta0 / sigma_beta^2 + t(X) %*% Y / sigma2)\n  beta <- as.numeric(rmvnorm(1, mean_beta, var_beta))\n  \n  ###Sample from full conditional for sigma2\n  quadratic <- as.numeric(t(Y - X %*% beta) %*% (Y - X %*% beta))\n  sigma2 <- 1 / rgamma(1, shape = a + n / 2, rate = b + quadratic / 2)\n  \n  ###Save samples after a burn-in\n  samples <- rbind(samples, c(beta, sigma2))\n}\n```\n:::\n\n\n\n## Inspect results\n\n\n\n::: {.cell layout-nrow=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=960}\n:::\n\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-7-2.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Summary of Gibbs sampling\n\n-   Gibbs sampling is great when we are able to sample from the full conditional distributions.\n\n-   It has been the main inference machine for Bayesian inference since the early 1990s.\n\n-   Computing full conditionals and coding up a Gibbs sampler can be mathematically and computationally rigorous.\n\n-   New classes of MCMC are becoming more common to make Bayesian inference less rigorous.\n\n# Metropolis sampling\n\n## Intuition behind Metropolis sampling {.midi}\n\nSuppose we have a working collection $\\{\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(s)}\\}$ to which we would like to add a new value $\\boldsymbol{\\theta}^{(s+1)}$. Let's consider adding a value $\\boldsymbol{\\theta}^*$ which is nearby $\\boldsymbol{\\theta}^{(s)}$. Should we include $\\boldsymbol{\\theta}^*$ in the set or not?\n\n-   If $f(\\boldsymbol{\\theta}^* | \\mathbf{Y}) > f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ then we want more $\\boldsymbol{\\theta}^*$'s in the set than $\\boldsymbol{\\theta}^{(s)}$'s.\n\n    -   Since $\\boldsymbol{\\theta}^{(s)}$ is already in the set, then it seems we should include $\\boldsymbol{\\theta}^*$ as well.\n\n-   On the other hand, if $f(\\boldsymbol{\\theta}^* | \\mathbf{Y}) < f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ then it seems we should not necessarily include $\\boldsymbol{\\theta}^*$.\n\n-   So, perhaps our decision to include $\\boldsymbol{\\theta}^*$ or not should be based on a comparison of $f(\\boldsymbol{\\theta}^* | \\mathbf{Y})$ to $f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$.\n\n## Metropolis acceptance ratio\n\n-   Fortunately, the comparison of $f(\\boldsymbol{\\theta}^* | \\mathbf{Y})$ to $f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ can be made even if we cannot compute $f(\\boldsymbol{\\theta} | \\mathbf{Y})$.\n\n\\begin{align*}\nr &= \\frac{f(\\boldsymbol{\\theta}^* | \\mathbf{Y})}{f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y})}\\frac{f(\\mathbf{Y})}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}\n\\end{align*}\n\nHaving computed $r$, how should we proceed?\n\n## Metropolis intuition {.midi}\n\nMetropolis ratio: $r = \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}$\n\nIf $r > 1:$\n\n-   *Intuition:* Since $\\boldsymbol{\\theta}^{(s)}$ is already in our set, we should include $\\boldsymbol{\\theta}^*$ as it has a higher probability than $\\boldsymbol{\\theta}^{(s)}$\n\n-   *Procedure:* Accept $\\boldsymbol{\\theta}^*$ into our set (i.e., set $\\boldsymbol{\\theta}^{(s + 1)} = \\boldsymbol{\\theta}^*$)\n\nIf $r < 1:$\n\n-   *Intuition:* The relative frequency of $\\boldsymbol{\\theta}$-values in our set equal to $\\boldsymbol{\\theta}^*$ compared to those equal to $\\boldsymbol{\\theta}^{(s)}$ should be $r$. This means that for every instance of $\\boldsymbol{\\theta}^{(s)}$, we should have only a \"fraction\" of an instance of a $\\boldsymbol{\\theta}^*$ value.\n\n-   *Procedure:* Set $\\boldsymbol{\\theta}^{(s + 1)}$ equal to either $\\boldsymbol{\\theta}^*$ or $\\boldsymbol{\\theta}^{(s)}$, with probability $r$ and $1 âˆ’ r$ respectively.\n\n## Metropolis update\n\nGiven $\\boldsymbol{\\theta}^{(s)}$, the Metropolis algorithm generates a value $\\boldsymbol{\\theta}^{(s + 1)}$ as follows:\n\n1.  Sample $\\boldsymbol{\\theta}^*$ from a proposal distribution, $\\boldsymbol{\\theta}^* âˆ¼ J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$\n\n2.  Compute the acceptance ratio $r$\n\n3.  Let \\begin{equation}\n     \\boldsymbol{\\theta}^{(s + 1)} = \n    \\left\\{\n      \\begin{array}{ll}\n     \\boldsymbol{\\theta}^* & \\text{with probability }\\min(r, 1) \\\\\n     \\boldsymbol{\\theta}^{(s)} & \\text{with probability }1 -\\min(r, 1)\n      \\end{array}\n    \\right.\n    \\end{equation}\n\n## Metropolis proposal distribution\n\n-   The proposal distribution is symmetric (i.e., $J(\\boldsymbol{\\theta}_a | \\boldsymbol{\\theta}_b) = J(\\boldsymbol{\\theta}_b | \\boldsymbol{\\theta}_a)$\n\n-   Usually $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$ is very simple, with samples from $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$ being near $\\boldsymbol{\\theta}$ with high probability.\n\n-   The most common proposal is a normal distribution\n\n    -   $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)}) = N(\\boldsymbol{\\theta}^{(s)}, \\boldsymbol{\\Delta})$\n\n-   The value of the parameter $\\boldsymbol{\\Delta}$ is generally chosen to make the approximation algorithm run efficiently\n\n## Metropolis and Gibbs combined\n\n-   The Gibbs and Metropolis samplers are actually both algorithms within a larger class of Metropolis-Hastings algorithms\n\n-   When performing MCMC, one can actually choose to update a parameter using either a Gibbs or Metropolis update\n\n-   Let's see this in action using our linear regression example\n\n## Linear regression using Metropolis/Gibbs\n\n-   In this example, we will use a Metropolis update for $\\sigma^2$, however we will actually focus on $\\log\\sigma^2$.\n\n    -   Metropolis requires a symmetric proposal, so it is often easier to transform parameters to be on the real line and use a normal proposal.\n\n-   We will use the following proposal, $\\log\\sigma^{2*} \\sim N\\left(\\log\\sigma^{2(s)}, \\delta\\right)$, where $\\delta = 1$.\n\n-   We will place the prior: $\\log\\sigma^2 \\sim N(0,1)$.\n\n## Linear regression using Metropolis/Gibbs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- exp(rnorm(1))\nsamples <- NULL\ndelta <- 1\nfor (s in 1:10000) {\n  ###Sample from full conditional for beta\n  var_beta <- chol2inv(chol(t(X) %*% X / sigma2 + diag(p + 1) / sigma_beta^2))\n  mean_beta <- var_beta %*% (beta0 / sigma_beta^2 + t(X) %*% Y / sigma2)\n  beta <- as.numeric(rmvnorm(1, mean_beta, var_beta))\n\n  ###Metropolis update for sigma2\n  # Sample a proposal value\n  log_sigma2_proposal <- rnorm(1, log(sigma2), delta)\n  # Compute the ratio r on the log scale for numeric stability\n  # Also, I've decided to update log(sigma2) instead of sigma2, so I can use a normal proposal distribution\n  # I've placed a normal prior on log(sigma2)\n  likelihood_proposal <- sum(dnorm(Y, X %*% beta, sqrt(exp(log_sigma2_proposal)), log = TRUE))\n  likelihood_current <- sum(dnorm(Y, X %*% beta, sqrt(sigma2), log = TRUE))\n  prior_proposal <- dnorm(log_sigma2_proposal, 0, 1, log = TRUE)\n  prior_current <- dnorm(log(sigma2), 0, 1, log = TRUE)\n  log_r <- (likelihood_proposal + prior_proposal) - (likelihood_current + prior_current)\n  # Update beta using Metropolis ratio\n  if (log(runif(1)) < log_r) sigma2 <- exp(log_sigma2_proposal)\n\n  ###Save samples after a burn-in\n  if (s > 5000) samples <- rbind(samples, c(beta, sigma2))\n}\n```\n:::\n\n\n\n## Inspect results\n\n\n\n::: {.cell layout-nrow=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=960}\n:::\n\n::: {.cell-output-display}\n![](03-mcmc_files/figure-revealjs/unnamed-chunk-9-2.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Summary of Metropolis algorithm\n\n-   More flexible than Gibbs sampling, because we are no longer required to compute the full conditional distribution analytically.\n\n-   Posterior samples can be obtained, however the algorithm must be properly tuned (i.e., choosing $\\delta$) and the samples may take longer to converge.\n\n-   Furthermore, choosing a proper proposal distribution can be difficult in practice.\n\n-   In more recent years, Hamiltonian Monte Carlo has emerged as an new MCMC approach that alleviates the aforementioned issues.\n\n## Metropolis-Hastings (MH) algorithm\n\nThe proposal distribution is no longer assumed to be symmetric, so the acceptance ratio is, \\begin{align*}\nr &= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\beta}^*, \\sigma^{2(s)}) f(\\boldsymbol{\\beta}^*)}{f(\\mathbf{Y} | \\boldsymbol{\\beta}^{(s)},\\sigma^{2(s)})f(\\boldsymbol{\\beta}^{(s)})} \\frac{J(\\boldsymbol{\\beta}^{(s)} | \\boldsymbol{\\beta}^*)}{J(\\boldsymbol{\\beta}^* | \\boldsymbol{\\beta}^{(s)})}.\n\\end{align*}\n\nBoth Metropolis and Gibbs can easily be seen as subcases of Metropolis Hastings.\n\n-   Metropolis assumes a symmetric proposal, so the proposal terms cancel.\n\n-   Gibbs assumes that $J(\\boldsymbol{\\beta}^{(s)} | \\boldsymbol{\\beta}^*) = f(\\boldsymbol{\\beta}^* | \\mathbf{Y}, \\sigma^{2(s)})$, which implies that $r=1$.\n\n## Hamiltonian Monte Carlo (HMC) intuition {.midi}\n\n-   HMC is a new MCMC approach that has been shown to work better than the usual MH algorithm.\n\n-   It is based on the idea of Hamiltonian dynamics (a physical concept)\n\n::: callout-important\n## Rollercoaster Metaphor\n\nImagine you're on a roller coaster at an amusement park. As the roller coaster moves along the track, it goes up and down hills. When the roller coaster is at the top of a hill, it has a lot of potential energy (like stored energy). When it goes down the hill, that potential energy turns into kinetic energy (energy of motion), making the roller coaster go faster. Hamiltonian dynamics is like a set of rules that tells us how the roller coaster's energy changes as it moves along the track.\n:::\n\n## HMC intuition\n\n-   Hamiltonian dynamics is used to generate a proposal from a better proposal distribution, $J(\\boldsymbol{\\beta}^{(s)} | \\boldsymbol{\\beta}^*)$, and modifies the acceptance part so the it has a higher acceptance rate.\n\n-   Just like the roller coaster follows the track smoothly, Hamiltonian Monte Carlo (HMC) helps us explore different possibilities smoothly and efficiently. This way, we can make more efficient samples from the posterior, just like how the roller coaster moves quickly and smoothly along its track.\n\n-   HMC requires evaluations of $\\log f(\\boldsymbol{\\theta} | \\mathbf{Y})$ and $\\nabla_{\\boldsymbol{\\theta}} \\log f(\\boldsymbol{\\theta} | \\mathbf{Y})$,\n\n$$\\log f(\\boldsymbol{\\theta} | \\mathbf{Y}) \\propto \\log f(\\mathbf{Y} | \\boldsymbol{\\theta}) + \\log f(\\boldsymbol{\\theta})$$\n\n## Prepare for next class\n\n-   Begin [HW 01](https://biostat725-sp25.netlify.app/hw/hw-01) which is due January 30\n\n-   Be sure to turn in your AE by Sunday evening\n\n-   Complete reading to prepare for next Tuesday's lecture\n\n-   Tuesday's lecture: Probabilistic Programming (Intro to Stan!)\n",
    "supporting": [
      "03-mcmc_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}