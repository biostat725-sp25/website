{
  "hash": "b22a00b788e0452b29c5ac0ba08e8b7f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Linear Regression\"\nauthor: \"Prof. Sam Berchuck\"\ndate: \"2025-01-16\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    html-math-method: mathjax\nfilters:\n  - parse-latex\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n## Review of last lecture\n\nOn Tuesday, we performed posterior inference for Bayesian linear regression, but we assumed the measurement error ($\\sigma$) was known!\n\n-   We did this so we could sample from a closed form posterior.\n\n-   Monte Carlo approximation.\n\nWe will consider the same model, $$\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2 \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n)$$\n\n-   In today's lecture we will estimate both $\\boldsymbol{\\beta}$ and $\\sigma^2$. This will require a new algorithm called **Gibbs sampling**.\n\n# Gibbs Sampling\n\n## Posterior for linear regression\n\n\\begin{align*}\nf(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}) &= \\frac{f(\\mathbf{Y}, \\boldsymbol{\\beta}, \\sigma^2)}{f(\\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)}{f(\\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)}{\\int f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)d\\boldsymbol{\\beta}d\\sigma^2}.\n\\end{align*}\n\nNo closed form exists for the posterior. $$f(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta}, \\sigma^2)$$\n\n## Motivation for Gibbs sampling\n\n-   Suppose we were given $\\sigma^{2(1)}$, a single sample from the marginal posterior distribution $f\\left(\\sigma^2|\\mathbf{Y}\\right)$ (from where, who knows?)\n\n-   Use the sample to generate $\\boldsymbol{\\beta}^{(1)}$ from $f\\left(\\boldsymbol{\\beta}|\\mathbf{Y},\\sigma^{2(1)}\\right)$\n\n-   $\\left(\\boldsymbol{\\beta}^{(1)},\\sigma^{2(1)}\\right)$ is a sample from $f\\left(\\boldsymbol{\\beta}, \\sigma^2 | \\mathbf{Y}\\right)$\n\n-   $\\boldsymbol{\\beta}^{(1)}$ is a sample from $f\\left(\\boldsymbol{\\beta} | \\mathbf{Y}\\right)$\n\n. . . \n\n::: callout-important\n## Recall\n\n$f\\left(\\boldsymbol{\\beta}, \\sigma^{2}|\\mathbf{Y}\\right) = f\\left(\\boldsymbol{\\beta} | \\sigma^{2},\\mathbf{Y}\\right)f\\left(\\sigma^{2}|\\mathbf{Y}\\right)$\n:::\n\n## Gibbs sampler for linear regression\n\nSuppose we can sample from the following two distribution,\n\n1.  $f(\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^2) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\boldsymbol{\\beta})$\n\n2.  $f(\\sigma^2 | \\mathbf{Y}, \\boldsymbol{\\beta}) \\propto f(\\mathbf{Y} | \\boldsymbol{\\beta}, \\sigma^2) f(\\sigma^2)$\n\nThese are called **full conditional distributions**.\n\nSet initial values for $\\boldsymbol{\\theta}^{(0)} = (\\boldsymbol{\\beta}^{(0)}, \\sigma^{2(0)})$. Then, given a current state of parameters $\\boldsymbol{\\theta}^{(s)}$, we can generate a new state as follows:\n\n1.  Sample $\\boldsymbol{\\beta}^{(s + 1)} \\sim f(\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^{2(s)})$\n\n2.  Sample $\\sigma^{2(s + 1)} \\sim f(\\sigma^2 | \\mathbf{Y}, \\boldsymbol{\\beta}^{(s + 1)})$\n\n3.  Let $\\boldsymbol{\\theta}^{(s+1)} = (\\boldsymbol{\\beta}^{(s + 1)}, \\sigma^{2(s + 1)})$\n\n## Why does this work?\n\n-   $\\boldsymbol{\\theta}^{(0)}$ isnâ€™t a sample from the posterior, it is an arbitrarily chosen initial value\n\n-   $\\boldsymbol{\\theta}^{(1)}$ likely isnâ€™t from the posterior either. Its distribution depends on $\\boldsymbol{\\theta}^{(0)}$\n\n-   $\\boldsymbol{\\theta}^{(2)}$ likely isnâ€™t from the posterior either. Its distribution depends on $\\boldsymbol{\\theta}^{(0)}$ and $\\boldsymbol{\\theta}^{(1)}$\n\n-   **Theorem:** For any initial values, the chain will eventually converge to the posterior\n\n-   **Theorem:** If $\\boldsymbol{\\theta}^{(s)}$ is a sample from the posterior, then $\\boldsymbol{\\theta}^{(s+1)}$ is too\n\n## Gibbs sampler\n\n-   Under mild regulatory conditions that are generally satisfied for most statistical models, one can show that the iteration $\\boldsymbol{\\theta}^{(s)}$ converges in distribution to a draw from the true joint posterior distribution\n\n-   So for $s$ sufficiently large (say, bigger than $s_0$), $\\left\\{\\boldsymbol{\\theta}^{(s)}, s=s_0+1,\\ldots,S\\right\\}$ is a **correlated** sample from the true joint posterior (and $\\boldsymbol{\\beta}^{(s)}$ and $\\sigma^{2(s)}$ are samples from the marginals)\n\n-   Similar to Monte Carlo approximation, we can use these samples to estimate posterior quantities of interest\n\n## Gibbs sampler\n\n-   $\\boldsymbol{\\theta}^{(t)}$ depends on $\\boldsymbol{\\theta}^{(0)},\\ldots,\\boldsymbol{\\theta}^{(t-1)}$ only through $\\boldsymbol{\\theta}^{(t-1)}$\n\n-   $\\boldsymbol{\\theta}^{(t)}$ is conditionally independent of $\\boldsymbol{\\theta}^{(0)},\\ldots,\\boldsymbol{\\theta}^{(t-2)}$ given $\\boldsymbol{\\theta}^{(t-1)}$\n\n    $\\implies$ Markov property, so the sequence is called a Markov chain\n\n-   We use the samples similar to MC approximation; therefore, Gibbs sampling is a form of Markov chain Monte Carlo (MCMC)\n\n-   We will cover diagnostics for MCMC in another lecture!\n\n## Gibbs sampler for linear regression\n\n-   Computing the full conditionals.\n\n    1.  We already have the full conditional for $\\boldsymbol{\\beta}$:\n\n    $\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^2 \\sim N \\left(\\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y}], \\mathbb{V}(\\boldsymbol{\\beta} | \\mathbf{Y})\\right)$\n\n\\begin{align*}\n\\mathbb{V}(\\boldsymbol{\\beta} | \\mathbf{Y}) &= \\left(\\frac{\\mathbf{I}_{p+1}}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{X}}{\\sigma^2}\\right)^{-1}\\\\\n\\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y}] &= \\left(\\frac{\\mathbf{I}_{p+1}}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{X}}{\\sigma^2}\\right)^{-1}\\left(\\frac{\\boldsymbol{\\beta}_0}{\\sigma_{\\beta}^2} + \\frac{\\mathbf{X}^\\top \\mathbf{Y}}{\\sigma^2}\\right)\n\\end{align*}\n\n## Gibbs sampler for linear regression\n\n-   Computing the full conditionals.\n\n    1.  $\\boldsymbol{\\beta} | \\mathbf{Y}, \\sigma^2 \\sim N \\left(\\mathbb{E}[\\boldsymbol{\\beta} | \\mathbf{Y}], \\mathbb{V}(\\boldsymbol{\\beta} | \\mathbf{Y})\\right)$\n\n    2.  Full conditional for $\\sigma^2$, assuming $f(\\sigma^2) \\sim IG(a, b)$:\n\n    $$\\sigma^2 |  \\mathbf{Y} , \\boldsymbol{\\beta} \\sim IG\\left(a + \\frac{n}{2},b+\\frac{\\left(\\mathbf{Y}-\\mathbf{X}\\boldsymbol{\\beta}\\right)^\\top\\left(\\mathbf{Y}-\\mathbf{X}\\boldsymbol{\\beta}\\right)}{2}\\right)$$\n\n    -   Why inverse-Gamma ($IG$) distribution for $\\sigma^2$?\n\n## How can we use the posterior?\n\nLet's simulate some data again:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n###True parameters\nsigma <- 1.5 # true measurement error\nbeta <- matrix(c(-1.5, 3), ncol = 1) # true beta\n\n###Simulation settings\nn <- 100 # number of observations\np <- length(beta) - 1 # number of covariates\n\n###Simulate data\nset.seed(54) # set seed\nX <- cbind(1, matrix(rnorm(n * p), ncol = p))\nY <- as.numeric(X %*% beta + rnorm(n, 0, sigma))\n\n###Define hyperparameteters\nbeta0 <- matrix(0, nrow = p + 1, ncol = 1)\nsigma_beta <- 10\na <- 3\nb <- 1\n```\n:::\n\n\n\n## Perform Gibbs sampling\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- exp(rnorm(1)) # initial value\nsamples <- NULL\nfor (s in 1:5000) {\n  ###Sample from full conditional for beta\n  var_beta <- chol2inv(chol(t(X) %*% X / sigma2 + diag(p + 1) / sigma_beta^2))\n  mean_beta <- var_beta %*% (beta0 / sigma_beta^2 + t(X) %*% Y / sigma2)\n  beta <- as.numeric(rmvnorm(1, mean_beta, var_beta))\n  \n  ###Sample from full conditional for sigma2\n  quadratic <- as.numeric(t(Y - X %*% beta) %*% (Y - X %*% beta))\n  sigma2 <- 1 / rgamma(1, shape = a + n / 2, rate = b + quadratic / 2)\n  \n  ###Save samples after a burn-in\n  samples <- rbind(samples, c(beta, sigma2))\n}\n```\n:::\n\n\n\n## Inspect results\n\n\n\n::: {.cell layout-nrow=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-linear-regression_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=960}\n:::\n\n::: {.cell-output-display}\n![](03-linear-regression_files/figure-revealjs/unnamed-chunk-4-2.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Parameter estimation vs. posterior approximation\n\n-   Model specification: Choice of likelihood and introduction of model parameters\n\n-   Prior specification\n\n-   Calculation of the posterior\n\n-   Summarizing the posterior using MC or MCMC methods:\n\n    -   These are not models!\n\n    -   They do not generate more information than is in $\\mathbf{Y}$ or $f\\left(\\boldsymbol{\\theta}\\right)$\n\n    -   They are simply ways of looking at $f\\left(\\boldsymbol{\\theta}|\\mathbf{Y}\\right)$\n\n## Additional topic: Metropolis sampling\n\n-   Before we start using Stan for probabilistic programming, we need to understand the MCMC algorithm that is the engine for Stan's inference, Hamiltonian Monte Carlo.\n\n-   To get us one step closer we will quickly review the concept of Metropolis sampling, another MCMC variant\n\n## Intuition behind Metropolis samping\n\nSuppose we have a working collection $\\{\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(s)}\\}$ to which we would like to add a new value $\\boldsymbol{\\theta}^{(s+1)}$. Let's consider adding a value $\\boldsymbol{\\theta}^*$ which is nearby $\\boldsymbol{\\theta}^{(s)}$. Should we include $\\boldsymbol{\\theta}^*$ in the set or not?\n\n-   If $f(\\boldsymbol{\\theta}^* | \\mathbf{Y}) > f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ then we want more $\\boldsymbol{\\theta}^*$'s in the set than $\\boldsymbol{\\theta}^{(s)}$'s.\n\n    -   Since $\\boldsymbol{\\theta}^{(s)}$ is already in the set, then it seems we should include $\\boldsymbol{\\theta}^*$ as well.\n\n-   On the other hand, if $f(\\boldsymbol{\\theta}^* | \\mathbf{Y}) < f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ then it seems we should not necessarily include $\\boldsymbol{\\theta}^*$.\n\n-   So, perhaps our decision to include $\\boldsymbol{\\theta}^*$ or not should be based on a comparison of $f(\\boldsymbol{\\theta}^* | \\mathbf{Y})$ to $f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$.\n\n## Metropolis acceptance ratio\n\n-   Fortunately, the comparison of $f(\\boldsymbol{\\theta}^* | \\mathbf{Y})$ to $f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})$ can be made even if we cannot compute $f(\\boldsymbol{\\theta} | \\mathbf{Y})$.\n\n\\begin{align*}\nr &= \\frac{f(\\boldsymbol{\\theta}^* | \\mathbf{Y})}{f(\\boldsymbol{\\theta}^{(s)} | \\mathbf{Y})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y})}\\frac{f(\\mathbf{Y})}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}\\\\\n&= \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}\n\\end{align*}\n\nHaving computed $r$, how should we proceed?\n\n## Metropolis intuition {.midi}\n\nMetropolis ratio: $r = \\frac{f(\\mathbf{Y} | \\boldsymbol{\\theta}^*)f(\\boldsymbol{\\theta}^*)}{f(\\mathbf{Y} | \\boldsymbol{\\theta}^{(s)})f(\\boldsymbol{\\theta}^{(s)})}$\n\nIf $r > 1:$\n\n-   *Intuition:* Since $\\boldsymbol{\\theta}^{(s)}$ is already in our set, we should include $\\boldsymbol{\\theta}^*$ as it has a higher probability than $\\boldsymbol{\\theta}^{(s)}$\n\n-   *Procedure:* Accept $\\boldsymbol{\\theta}^*$ into our set (i.e., set $\\boldsymbol{\\theta}^{(s + 1)} = \\boldsymbol{\\theta}^*$)\n\nIf $r < 1:$\n\n-   *Intuition:* The relative frequency of $\\boldsymbol{\\theta}$-values in our set equal to $\\boldsymbol{\\theta}^*$ compared to those equal to $\\boldsymbol{\\theta}^{(s)}$ should be $r$. This means that for every instance of $\\boldsymbol{\\theta}^{(s)}$, we should have only a \"fraction\" of an instance of a $\\boldsymbol{\\theta}^*$ value.\n\n-   *Procedure:* Set $\\boldsymbol{\\theta}^{(s + 1)}$ equal to either $\\boldsymbol{\\theta}^*$ or $\\boldsymbol{\\theta}^{(s)}$, with probability $r$ and $1 âˆ’ r$ respectively.\n\n## Metropolis update\n\nGiven $\\boldsymbol{\\theta}^{(s)}$, the Metropolis algorithm generates a value $\\boldsymbol{\\theta}^{(s + 1)}$ as follows:\n\n1.  Sample $\\boldsymbol{\\theta}^*$ from a proposal distribution, $\\boldsymbol{\\theta}^* âˆ¼ J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$\n\n2.  Compute the acceptance ratio $r$\n\n3.  Let \\begin{equation}\n     \\boldsymbol{\\theta}^{(s + 1)} = \n    \\left\\{\n      \\begin{array}{ll}\n     \\boldsymbol{\\theta}^* & \\text{with probability }\\min(r, 1) \\\\\n     \\boldsymbol{\\theta}^{(s)} & \\text{with probability }1 -\\min(r, 1)\n      \\end{array}\n    \\right.\n    \\end{equation}\n\n## Metropolis proposal distribution\n\n-   The proposal distribution is symmetric (i.e., $J(\\boldsymbol{\\theta}_a | \\boldsymbol{\\theta}_b) = J(\\boldsymbol{\\theta}_b | \\boldsymbol{\\theta}_a)$\n\n-   Usually $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$ is very simple, with samples from $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)})$ being near $\\boldsymbol{\\theta}$ with high probability.\n\n-   The most common proposal is a normal distribution\n\n    -   $J(\\boldsymbol{\\theta} | \\boldsymbol{\\theta}^{(s)}) = N(\\boldsymbol{\\theta}^{(s)}, \\boldsymbol{\\Delta})$\n\n-   The value of the parameter $\\boldsymbol{\\Delta}$ is generally chosen to make the approximation algorithm run efficiently\n\n## Metropolis and Gibbs combined\n\n-   The Gibbs and Metropolis samplers are actually both algorithms within a larger class of Metropolis-Hastings algorithms\n\n-   When performing MCMC, one can actually choose to update a parameter using either a Gibbs or Metropolis update\n\n-   Let's see this in action using our linear regression example\n\n## Linear regression using Metropolis/Gibbs\n\n- In this example, we will use a Metropolis update for $\\sigma^2$, however we will actually focus on $\\log\\sigma^2$. \n\n  - Metropolis requires a symmetric proposal, so it is often easier to transform parameters to be on the real line and use a normal proposal.\n  \n- We will use the following proposal, $\\log\\sigma^{2*} \\sim N\\left(\\log\\sigma^{2(s)}, \\delta\\right)$, where $\\delta = 1$.\n\n- We will place $\\log\\sigma^2 \\sim N(0,1)$.\n\n## Linear regression using Metropolis/Gibbs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- exp(rnorm(1))\nsamples <- NULL\ndelta <- 1\nfor (s in 1:10000) {\n  ###Sample from full conditional for beta\n  var_beta <- chol2inv(chol(t(X) %*% X / sigma2 + diag(p + 1) / sigma_beta^2))\n  mean_beta <- var_beta %*% (beta0 / sigma_beta^2 + t(X) %*% Y / sigma2)\n  beta <- as.numeric(rmvnorm(1, mean_beta, var_beta))\n\n  ###Metropolis update for sigma2\n  # Sample a proposal value\n  log_sigma2_proposal <- rnorm(1, log(sigma2), delta)\n  # Compute the ratio r on the log scale for numeric stability\n  # Also, I've decided to update log(sigma2) instead of sigma2, so I can use a normal proposal distribution\n  # I've placed a normal prior on log(sigma2)\n  likelihood_proposal <- sum(dnorm(Y, X %*% beta, sqrt(exp(log_sigma2_proposal)), log = TRUE))\n  likelihood_current <- sum(dnorm(Y, X %*% beta, sqrt(sigma2), log = TRUE))\n  prior_proposal <- dnorm(log_sigma2_proposal, 0, 1, log = TRUE)\n  prior_current <- dnorm(log(sigma2), 0, 1, log = TRUE)\n  log_r <- (likelihood_proposal + prior_proposal) - (likelihood_current + prior_current)\n  # Update beta using Metropolis ratio\n  if (log(runif(1)) < log_r) sigma2 <- exp(log_sigma2_proposal)\n\n  ###Save samples after a burn-in\n  if (s > 5000) samples <- rbind(samples, c(beta, sigma2))\n}\n```\n:::\n\n\n\n## Inspect results\n\n\n\n::: {.cell layout-nrow=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-linear-regression_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=960}\n:::\n\n::: {.cell-output-display}\n![](03-linear-regression_files/figure-revealjs/unnamed-chunk-6-2.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Looking towards Stan\n\n-   We can use Monte Carlo approximation, when the posterior is available in closed form.\n\n-   We can use Gibbs sampling when the full conditional distributions are available in closed form.\n\n-   We can always use Metropolis (or its more general form Metropolis Hastings) regardless of the form of the posterior, we only need to be able to compute $f(\\mathbf{Y} | \\boldsymbol{\\theta})f(\\boldsymbol{\\theta})$\n\n    -   This amounts to specifying a likelihood and a prior (which is the fun modeling part!)\n\n    -   Metropolis can be difficult to tune (i.e., finding $\\boldsymbol{\\Delta}$)\n\n## Looking towards Stan\n\n\n-   Stan uses an algorithm called Hamiltonian Monte Carlo, which is a form of MCMC that uses a Metropolis update\n\n-   Stan does all of the MCMC tuning, allowing us to only focus on the modeling!\n\n-   This means that our job moving forward will be to focus on specifying the\n\n    1. likelihood: $f(\\mathbf{Y} | \\boldsymbol{\\theta})$\n  \n    2. prior: $f(\\boldsymbol{\\theta})$",
    "supporting": [
      "03-linear-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}