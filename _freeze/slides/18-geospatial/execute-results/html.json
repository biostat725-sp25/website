{
  "hash": "cc9e8a7092d0acefaa5e695705adcc5e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Geospatial Modeling\"\nauthor: \"Prof. Sam Berchuck\"\ndate: \"2025-03-20\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    html-math-method: mathjax\nfilters:\n  - parse-latex\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Review of last lecture\n\n-   During our last lecture, we learned about Gaussian processes. \n\n-   We learned how to apply Gaussian processes to longitudinal (or time-series) data. \n\n-   The longitudinal setting is one-dimensional (i.e., time). Today we will learn about applying Gaussian processes in two-dimensions (i.e. space).\n\n\n## Three Types of Spatial Data:\n\n- Geostatistical Point Referenced Data\n\n- Lattice Data (Areal Data)\n\n- Spatial Point Process Data\n\n  - All of these data settings can be extended to space-time\n  \n## Geostatistical Point Referenced Data\n\n- Point observations of a continuously varying quantity over a region\n \n  - Daily Concentrations of Ozone Over NC\n  \n![](./images/18/daily_ozone_intro.png){fig-align=\"center\" height=\"400\"}\n\n\n## Geostatistical Point Referenced Data\n\n- Daily Concentrations of PM2.5 Over the US\n\n![](./images/18/pm_us.png){fig-align=\"center\" height=\"450\"}\n\n\n## Lattice Data (Areal Data)\n\n- Data observed at the level of an areal unit\n  \n  - County Level Sudden Infant Death Syndrome Counts\n\n![](./images/18/lattice_data.png){fig-align=\"center\" height=\"450\"}\n\t\n\n\n## Lattice Data (Areal Data)\n\n- Birmingham Tract Level Poverty Levels\n\n![](./images/18/Birmingham_Poverty.png){fig-align=\"center\" height=\"500\"}\n\n## Spatial Point Process Data\n\n- Analyzing the clustering of random locations\n \n  - Locations of a certain tree type in a forest\n  \n  - Epicenter of earthquakes\n\n- Sometimes difficult to differentiate from point referenced geostatistical data (visually)\n\n## Spatial Point Process Data\n\n- Minneapolis Convenience Store Locations\n\n![](./images/18/Minneapolis_Convenience_withStores.png){fig-align=\"center\" height=\"500\"}\n\t\n## Spatial Data Analysis: When?\n\n- Anytime you have spatial information collected with your data.\n\n- Increasing availability of some level of spatial information:\n\n  - Latitude/longitude.\n  \n  - County, state, etc.\n  \n  - Imaging data.\n\n## Spatial Data Analysis: Why?\n\n  - Correct statistical inference (conditional independence may not be a valid assumption!).\n\t\n\t- Specific goals will depend on the type of spatial data you have and the objective of your analysis.\n\n  - Producing maps with valid inference.\n\n## Spatial Data Analysis: How?\n\n- Bayesian Hierarchical Modeling:\n\t\t\n  - Flexible framework to handle multiple levels of uncertainty.\n  - Markov chain Monte Carlo (MCMC) offers computationally convenient solution to make inference.\n  \n- Frequentist methods also available through the EM algorithm.\n\t\n  - Original frequentist methods ignore some of the uncertainty in estimating these spatial models.\n  \n## Goals of a Point-referenced Analysis\n\n- Estimation and explanation: \n \n  - Typical regression parameter estimation.\n\t\n\t- How does temperature change across the domain (large-scale)?\n\n- Prediction at unobserved locations:\n \n  - Original development of spatial methods.\n  \n  - Kriging named after D.G. Krige (mining applications).\n\n- Design issues:\n\n  - Where to put a new air pollution monitor to optimize future prediction criteria?\n\n## Goals of a Point-referenced Analysis\n\n- Estimation and Explanation\n\n![](./images/18/Temp.png){fig-align=\"center\" height=\"500\"}\n\n## Goals of a Point-referenced Analysis\n\n- Spatial Prediction \n\n![Observed Data](./images/18/geo_data_intro-eps-converted-to.png){fig-align=\"center\" height=\"450\"}\n\n## Goals of a Point-referenced Analysis\n\n- Spatial Prediction \n \n ![Prediction](./images/18/kriging_est_intro.png){fig-align=\"center\" height=\"450\"}\n\n## Goals of a Point-referenced Analysis\n\n- Spatial Prediction \n \n ![Standard Errors](./images/18/kriging_sd_intro-eps-converted-to.png){fig-align=\"center\" height=\"450\"}\n\n## Point-referenced Modeling\n\n- Observations closer in space tend to be more similar.\n\n  - Common regression models assume independence among observations.\n\t\n    - Not a valid assumption here, especially at short distances.\n\n- Multivariate normal distribution with valid spatial covariance function used in Bayesian modeling.\n\n  - Spatial covariance describes how observations are correlated based on their proximity to each other.\n\n\t- Advanced models built on similar ideas.\n\n  - Latent processes often used.\n\n## Point-referenced Modeling\n\n$$  Y_{ij} = \\alpha + \\mathbf{x}_{ij} \\boldsymbol{\\beta} + \\theta_i + \\epsilon_{ij}, \\quad \\epsilon_{ij} \\stackrel{iid}{\\sim} N(0,\\sigma^2).$$\n\n**Data Objects:**\n\n- $i \\in \\{1,\\dots,n\\}$ indexes unique locations.\n\n- $j \\in \\{1,\\dots,n_i\\}$ indexes individuals at each location.\n\n- $Y_{ij}$ denotes the observation of individual $j$ at location $i$.\n\n- $\\mathbf{x}_{ij} \\in \\mathbb{R}^p$, where $p$ is the number of predictors (exclusing intercept).\n\n## Point-referenced Modeling\n\n$$Y_{ij} = \\alpha + \\mathbf{x}_{ij} \\boldsymbol{\\beta} + \\theta_i + \\epsilon_{ij}, \\quad \\epsilon_{ij} \\stackrel{iid}{\\sim} N(0,\\sigma^2).$$\n\n**Population Parameters:**\n\n- $\\alpha \\in \\mathbb{R}$ is the intercept.\n\n- $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ is the regression coefficients.\n\n- $\\sigma^2 \\in \\mathbb{R}^+$ is the overall residual error (nugget).\n\n## Point-referenced Modeling\n\n$$Y_{ij} = \\alpha + \\mathbf{x}_{ij} \\boldsymbol{\\beta} + \\theta_i + \\epsilon_{ij}, \\quad \\epsilon_{ij} \\stackrel{iid}{\\sim} N(0,\\sigma^2).$$\n\n**Location-specific Parameters:**\n\n- $\\theta_i$ denotes the spatial intercept at location $\\mathbf{u}_i$.\n\n- $\\mathbf{u}_i \\in \\mathbb{R}^d$ denotes the spatial location of location $i$. For example, $\\mathbf{u}_i = (\\text{latitude}_i, \\text{longitude}_i)$, so that $d = 2$.\n\nIn a spatial context, we often use the following notation:\n\n$$Y_j(\\mathbf{u}_i) = \\alpha + \\mathbf{x}_j(\\mathbf{u}_i)\\boldsymbol{\\beta} + \\theta(\\mathbf{u}_i) + \\epsilon_i(\\mathbf{u}_i).$$\n\n## Location-specific Notation\n\n$$\\mathbf{Y}(\\mathbf{u}_i) = \\alpha \\mathbf{1}_{n_i} + \\mathbf{X}(\\mathbf{u}_i) \\boldsymbol{\\beta} + \\theta(\\mathbf{u}_i)\\mathbf{1}_{n_i} + \\boldsymbol{\\epsilon}(\\mathbf{u}_i)$$\n\n- $\\mathbf{Y}(\\mathbf{u}_i) = (Y_1(\\mathbf{u}_i),\\ldots,Y_{n_i}(\\mathbf{u}_i))^\\top$\n\n- $\\mathbf{X}(\\mathbf{u}_i)$ is an $n_i \\times p$ dimensional matrix with rows $\\mathbf{x}_j(\\mathbf{u}_i)$.\n\n- $\\boldsymbol{\\epsilon}(\\mathbf{u}_i) = (\\epsilon_i(\\mathbf{u}_i),\\ldots,\\epsilon_{n_i}(\\mathbf{u}_i))^\\top$, where $\\epsilon_j(\\mathbf{u}_i) \\stackrel{iid}{\\sim} N(0,\\sigma^2)$.\n\nNote: This notation is the same as the linear mixed model we have talked about in previous lectures.\n\n## Full data notation\n\n$$\\mathbf{Y} = \\alpha \\mathbf{1}_{N} + \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{\\theta} + \\boldsymbol{\\epsilon}$$\n\n- $\\mathbf{Y} = (\\mathbf{Y}(\\mathbf{u}_1)^\\top,\\ldots,\\mathbf{Y}(\\mathbf{u}_{n})^\\top)^\\top \\in \\mathbb{R}^N$, with $N = \\sum_{i=1}^n n_i$.\n\n- $\\mathbf{X} \\in \\mathbb{R}^{N \\times p}$ that stacks $\\mathbf{X}(\\mathbf{u}_i)$.\n\n- $\\boldsymbol{\\theta} = (\\theta(\\mathbf{u}_1),\\ldots,\\theta(\\mathbf{u}_n))^\\top \\in \\mathbb{R}^n$.\n\n- $\\mathbf{Z}$ is $N \\times n$ dimensional binary matrix. Each row contains a single 1 in column $i$ that corresponds to the location of $Y_j(\\mathbf{u}_i)$.\n\nThis notation is useful because it allows us to examine the vector of location-specific parameters, $\\boldsymbol{\\theta}$. Spatial dependency will be introduced through $\\boldsymbol{\\theta}$.\n\n## Accounting for spatial correlation\n\n- We want to model the spatial variation in $\\boldsymbol{\\theta}$ using a **prior** that reflects the spatial correlation between locations.\n\n- One powerful way to incorporate spatial correlations is through Gaussian processes (GPs).\n\n- Consider $\\{\\theta(\\mathbf{u}) \\in \\mathcal D\\}$, where $\\mathcal D$ is a fixed subset of $d$-dimensional Euclidean space ($d=1$ is time-series, $d=2,3$ is spatial).\n  \n- The process is said to be Gaussian if, for any $n\\geq 1$ and observed locations $\\{\\mathbf{u}_1,\\ldots,\\mathbf{u}_n\\}$, $\\boldsymbol{\\theta} = (\\theta(\\mathbf{u}_1),\\ldots,\\theta(\\mathbf{u}_n))^\\top$ has a multivariate normal distribution.\n\n## Properties of Gaussian Processes\n\nWe define a GP as $\\theta(\\mathbf{u}) \\sim GP(\\mu(\\cdot), C(\\cdot, \\cdot))$, where $\\mu(\\cdot)$ is the mean process and $C(\\cdot, \\cdot)$ is a covariance function.\n\n- Mean function: $\\mathbb{E}[\\theta(\\mathbf{u})] = \\mu(\\mathbf{u}) = 0$.\n\n- Covariance function: $\\mathbb{C}(\\theta(\\mathbf{u}_i),\\theta(\\mathbf{u}_{i'})) = C(\\mathbf{u}_i, \\mathbf{u}_{i'})$.\n\n**Properties of covariance functions:**\n\n- **Stationary**: $\\mathbb{C}(\\theta(\\mathbf{u}),\\theta(\\mathbf{u} + \\mathbf{h})) = C(\\mathbf{h})$, where $\\mathbf{h} \\in \\mathbf{R}^d$. \n\n- **Isotropic**: $\\mathbb{C}(\\theta(\\mathbf{u}),\\theta(\\mathbf{u} + \\mathbf{h})) = C(||\\mathbf{h}||)$, where $||\\cdot\\||$ is a distance length. \n\n## Choosing a covariance function {.midi}\n\nThe MatÃ©rn covariance function has a general form and is often the default choice for spatial data (squared exponential is often too smooth!). MatÃ©rn is a function of a smoothness parameter $\\nu > 0$ and a length scale, which we will define as $\\rho$.\n\n- $\\nu = 1/2$: exponential covariance function, `gp_exponential_cov`.\n\n- $\\nu = 3/2$: MatÃ©rn 3/2 covariance function, `gp_matern32_cov`.\n\n$$C(||\\mathbf{h}||) = \\tau^2 \\left(1 + \\frac{\\sqrt{3} ||\\mathbf{h}||}{\\rho}\\right) \\exp\\left(-\\frac{\\sqrt{3} ||\\mathbf{h}||}{\\rho}\\right)$$\n\n- $\\nu = 5/2$: MatÃ©rn 5/2 covariance function, `gp_matern52_cov`.\n\n## Point-referenced spatial model\n\n\\begin{align*}\n\\mathbf{Y} | \\alpha, \\boldsymbol{\\beta}, \\boldsymbol{\\theta},\\sigma &\\sim N_N(\\alpha \\mathbf{1}_{N} + \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\boldsymbol{\\theta},\\sigma^2 \\mathbf{I}_N)\\\\\n\\boldsymbol{\\theta} &\\sim N_{n}(\\mathbf{0}_n, \\mathbf{C})\\\\\n\\boldsymbol{\\Omega} &\\sim f(\\boldsymbol{\\Omega}),\n\\end{align*}\n\nwhere $\\boldsymbol{\\Omega} = (\\alpha,\\boldsymbol{\\beta},\\sigma,\\tau,\\rho)$ and \n\n$$\\mathbf{C} = \\begin{bmatrix}\nC(0) & C(||\\mathbf{u}_1 - \\mathbf{u}_2||) & \\cdots & C(||\\mathbf{u}_1 - \\mathbf{u}_{n_i}||)\\\\\nC(||\\mathbf{u}_1 - \\mathbf{u}_2||) & C(0) & \\cdots & C(||\\mathbf{u}_2 - \\mathbf{u}_{n_i}||)\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nC(||\\mathbf{u}_{1} - \\mathbf{u}_{n_i}||) & C(||\\mathbf{u}_2 - \\mathbf{u}_{n_i}||) & \\cdots & C(0)\\\\\n\\end{bmatrix}.$$\n\n## Point-referenced spatial model\n\nLike previous lecture, we can also specify a marginal model which is useful if we are only intereted in population parameters, speed is of concern, or the conditional specification has poor convergence.\n\n\\begin{align*}\n\\mathbf{Y} | \\boldsymbol{\\Omega}  &\\sim N_N(\\alpha \\mathbf{1}_{N} + \\mathbf{X} \\boldsymbol{\\beta},\\sigma^2 \\mathbf{I}_N + \\mathbf{Z} \\mathbf{C} \\mathbf{Z}^\\top)\\\\\n\\boldsymbol{\\Omega} &\\sim f(\\boldsymbol{\\Omega})\n\\end{align*}\n\n## Posterior predictive distribution {.midi}\n\nDefine $\\mathbf{Y}^* = (Y(\\mathbf{u}_{n+1}),\\ldots, Y(\\mathbf{u}_{n+q+1}))^\\top$ as observations at $q$ new locations. We ignore the subscript $j$. The new location-specific parameters are $\\boldsymbol{\\theta} = (\\theta(\\mathbf{u}_{n+1}),\\ldots,\\mathbf{u}_{n+q+1})^\\top$.\n\n\\begin{align*}\nf(\\mathbf{Y}^* | \\mathbf{Y}) &= \\int f(\\mathbf{Y}^*, \\boldsymbol{\\theta}^*, \\boldsymbol{\\theta}, \\boldsymbol{\\Omega} | \\mathbf{Y}) d\\boldsymbol{\\theta}^* d\\boldsymbol{\\theta} d\\boldsymbol{\\Omega}\\\\\n&= \\int \\underbrace{f(\\mathbf{Y}^* | \\boldsymbol{\\theta}^*, \\boldsymbol{\\Omega})}_{(1)} \\underbrace{f(\\boldsymbol{\\theta}^* | \\boldsymbol{\\theta}, \\boldsymbol{\\Omega})}_{(2)} \\underbrace{f(\\boldsymbol{\\Omega} | \\mathbf{Y})}_{(3)} d\\boldsymbol{\\theta}^* d\\boldsymbol{\\theta} d\\boldsymbol{\\Omega}\\\\\n\\end{align*}\n\n(1) Likelihood: $f(\\mathbf{Y}^* | \\boldsymbol{\\theta}^*, \\boldsymbol{\\Omega}) = \\prod_{i=n+1}^{n+q+1} f(Y(\\mathbf{u}_i) | \\alpha, \\boldsymbol{\\beta}, \\theta(\\mathbf{u}_i),\\sigma)$\n\n(2) Kriging: $f(\\boldsymbol{\\theta}^* | \\boldsymbol{\\theta}, \\boldsymbol{\\Omega})$\n\n(3) Posterior distribution: $f(\\boldsymbol{\\Omega} | \\mathbf{Y})$\n\n## Kriging Distribution {.smaller}\n\nTo compute $f(\\boldsymbol{\\theta}^* | \\boldsymbol{\\theta}, \\boldsymbol{\\Omega})$ we must specify the joint distribtuion:\n\n$$f\\left(\\begin{bmatrix}\n    \\boldsymbol{\\theta}\\\\\n    \\boldsymbol{\\theta}^*\n  \\end{bmatrix} \\Bigg| \\boldsymbol{\\Omega}\\right) = N\\left(\\begin{bmatrix}\n    \\mathbf{0}_n \\\\\n    \\mathbf{0}_{q}\n  \\end{bmatrix}, \\begin{bmatrix}\n    \\mathbf{C} & \\mathbf{C}_{+}\\\\\n    \\mathbf{C}_{+}^\\top & \\mathbf{C}^*\n  \\end{bmatrix}\\right),$$\n\nwhere $\\mathbf{C}$ is the covariance of $\\boldsymbol{\\theta}$,\n\n$$\\mathbf{C^*} = \\begin{bmatrix}\nC(0) & C(||\\mathbf{u}_{n+1} - \\mathbf{u}_{n+2}||) & \\cdots & C(||\\mathbf{u}_{n+1} - \\mathbf{u}_{n + q + 1}||)\\\\\nC(||\\mathbf{u}_{n+1} - \\mathbf{u}_{n+2}||) & C(0) & \\cdots & C(||\\mathbf{u}_{n_2} - \\mathbf{u}_{n + q + 1}||)\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nC(||\\mathbf{u}_{n + 1} - \\mathbf{u}_{n + q + 1}||) & C(||\\mathbf{u}_{n + 2} - \\mathbf{u}_{n + q + 1}||) & \\cdots & C(0)\\\\\n\\end{bmatrix} \\in \\mathbb{R}^{q \\times q},$$\n\n$$\\mathbf{C_+} = \\begin{bmatrix}\nC(||\\mathbf{u}_{1} - \\mathbf{u}_{n+1}||) & C(||\\mathbf{u}_{1} - \\mathbf{u}_{n+2}||) & \\cdots & C(||\\mathbf{u}_{1} - \\mathbf{u}_{n + q + 1}||)\\\\\nC(||\\mathbf{u}_{2} - \\mathbf{u}_{n+1}||) & C(||\\mathbf{u}_{2} - \\mathbf{u}_{n+2}||) & \\cdots & C(||\\mathbf{u}_{n} - \\mathbf{u}_{n + q + 1}||)\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\nC(||\\mathbf{u}_{n} - \\mathbf{u}_{n + 1}||) & C(||\\mathbf{u}_{n} - \\mathbf{u}_{n+2}||) & \\cdots & C(||\\mathbf{u}_{n} - \\mathbf{u}_{n+q+1}||)\\\\\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times q}.$$\n\n## Kriging Distribution {.smaller}\n\nWe can then use the [conditional specification of a multivariate normal](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions) to find, $f(\\boldsymbol{\\theta}^* | \\boldsymbol{\\theta}, \\boldsymbol{\\Omega}) = N(\\mathbb{E}_{\\boldsymbol{\\theta}^*},\\mathbb{V}_{\\boldsymbol{\\theta}^*})$, where\n\n\\begin{align*}\n\\mathbb{E}_{\\boldsymbol{\\theta}^*} &= \\mathbf{C}_+^\\top \\mathbf{C}^{-1} \\boldsymbol{\\theta}\\\\\n\\mathbb{V}_{\\boldsymbol{\\theta}^*} &= \\mathbf{C}^* - \\mathbf{C}_+^\\top \\mathbf{C}^{-1} \\mathbf{C}_+.\n\\end{align*}\n\nComputationally it is efficient to compute $\\mathbf{L} = \\text{chol}(\\mathbf{C})$, such that $\\mathbf{C} = \\mathbf{L}\\mathbf{L}^\\top$ and write:\n\n\\begin{align*}\n\\mathbb{E}_{\\boldsymbol{\\theta}^*} &= \\mathbf{C}_+^\\top \\left(\\mathbf{L}\\mathbf{L}^\\top\\right)^{-1} \\boldsymbol{\\theta}\\\\\n&= \\mathbf{C}_+^\\top \\left(\\mathbf{L}^{-1}\\right)^\\top\\mathbf{L}^{-1} \\boldsymbol{\\theta}\\\\\n&= \\left(\\mathbf{L}^{-1} \\mathbf{C}_+\\right)^\\top\\mathbf{L}^{-1} \\boldsymbol{\\theta}.\n\\end{align*}\n\nEfficient [Stan function](https://mc-stan.org/docs/functions-reference/matrix_operations.html#linear-algebra-functions-and-solvers): `mdivide_left_tri_low(A, b) = inverse(tri(A)) * b`.\n\n\\begin{align*}\n\\mathbb{V}_{\\boldsymbol{\\theta}^*} &=\\mathbf{C}^* - \\left(\\mathbf{L}^{-1} \\mathbf{C}_+\\right)^\\top \\mathbf{L}^{-1} \\mathbf{C}_+.\n\\end{align*}\n\n## Motivating Dataset {.midi}\n\nWe will look at a sample of women aged 15-49 sampled from the 2013-14 Democratic Republic of Congo (DRC) Demographic and Health Survey. \n\n- There are ~8600 women who are nested in ~500 survey clusters. \n\n- Variables are:\n\n  - `loc_id`: location id (i.e. survey cluster).\n\n  - `hemoglobin`: hemoglobin level (g/dL).\n\n  - `anemia`: anemia classifications.\n  \n  - `age`: age in years.\n\n  - `urban`: urban vs. rural.\n\n  - `LATNUM`: latitude.\n\n  - `LONGNUM`: longitude.\n\n## Motivating Dataset {.midi}\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  loc_id hemoglobin     anemia age urban   LATNUM  LONGNUM mean_hemoglobin\n1      1       12.5 not anemic  28 rural 0.220128 21.79508        11.81053\n2      1       12.6 not anemic  42 rural 0.220128 21.79508        11.81053\n3      1       13.3 not anemic  15 rural 0.220128 21.79508        11.81053\n4      1       12.9 not anemic  28 rural 0.220128 21.79508        11.81053\n5      1       10.4       mild  32 rural 0.220128 21.79508        11.81053\n6      1       12.2 not anemic  42 rural 0.220128 21.79508        11.81053\n  community_size mean_age\n1             19       19\n2             19       19\n3             19       19\n4             19       19\n5             19       19\n6             19       19\n```\n\n\n:::\n:::\n\n\n\n::: callout-important\n## Modeling Goals:\n\n  - Learn the associations between age and urbanality and hemoglobin, accounting for unmeasured spatial confounders.\n  \n  - Create a predicted map of hemoglobin across the spatial surface, with uncertainty quantification.\n  \n:::\n\n## Visualize data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n## Looking at community sizes\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n## Today we will focus on one state\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=768}\n:::\n\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-5-2.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n## Modeling {.midi}\n\nWe specify the following model: \n\n\\begin{align*}\nY_j(\\mathbf{u}_i) &= \\alpha + \\mathbf{x}_j(\\mathbf{u}_i) \\boldsymbol{\\beta} + \\theta(\\mathbf{u}_i) + \\epsilon_j(\\mathbf{u}_i), \\quad \\epsilon_j(\\mathbf{u}_i) \\stackrel{iid}{\\sim} N(0,\\sigma^2)\\\\\n\\boldsymbol{\\theta} | \\tau,\\rho &\\sim N(\\mathbf{0}_n,\\mathbf{C})\\\\\n\\alpha^* &\\sim N(0,4^2)\\\\\n\\beta_j | \\sigma_{\\beta} &\\sim N(0,\\sigma_{\\beta}^2), \\quad j = 1,\\ldots,p\\\\\n\\sigma &\\sim \\text{Half-Normal}(0, 2^2)\\\\\n\\tau &\\sim \\text{Half-Normal}(0, 4^2)\\\\\n\\rho &\\sim \\text{Inv-Gamma}(5, 5)\\\\\n\\sigma_{\\beta} &\\sim \\text{Half-Normal}(0, 2^2)\n\\end{align*}\n\nWhere $N = 490$, $n = 29$, $\\mathbf{x}_j(\\mathbf{u}_i) = (\\text{age}_{ij}/10, \\text{urban}_i)$, and $\\mathbf{C}$ is the MatÃ©rn 3/2.\n\n## Define the prediction grid\n\nFor prediction I created a $20 \\times 20$ grid, making sure the points are in the surface.\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=480}\n:::\n\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-6-2.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n## Stan code\n\n\n\n::: {.cell output.var='whole_model'}\n\n```{.stan .cell-code}\nfunctions {\n\tmatrix L_matern32(array[] vector x, real tau, real rho, real delta) { \n\t\tmatrix[size(x), size(x)] cov;\n\t\tcov = add_diag(gp_matern32_cov(x, tau, rho), delta);\n\t\treturn cholesky_decompose(cov);\n\t}\n  vector theta_new_rng(array[] vector x, array[] vector x_new, real tau, \n                        real rho, vector z_obs, real delta) {\n    int n = size(x);\n  \tint q = size(x_new);\n    vector[q] theta_new;\n\t  { // everything declared inside of {} will only exist in that local environment\n      matrix[n, n] LC = L_matern32(x, tau, rho, delta);\n      vector[n] theta_obs = LC * z_obs;\n      matrix[n, q] Cplus = gp_matern32_cov(x, x_new, tau, rho);\n      matrix[n, q] LCinv_Cplus = mdivide_left_tri_low(LC, Cplus);\n      vector[n] LCinv_theta_obs = mdivide_left_tri_low(LC, theta_obs);\n      vector[q] theta_new_mu = LCinv_Cplus' * LCinv_theta_obs;\n      matrix[q, q] C_star = add_diag(gp_matern32_cov(x_new, tau, rho), delta);\n      matrix[q, q] theta_new_cov = C_star - LCinv_Cplus' * LCinv_Cplus;\n      theta_new = multi_normal_rng(theta_new_mu, theta_new_cov);\n\t}\n\treturn theta_new;\n\t}\n\tmatrix cov2cor(matrix V) { \n\t  int p = rows(V); \n\t  vector[p] Is = inv_sqrt(diagonal(V)); \n\t  return quad_form_diag(V, Is); \n\t }\n}\ndata {\n  int<lower = 1> N;                        // number of observed data points\n  int<lower = 1> p;                        // number of fixed covariates\n  int<lower = 1> n;                        // number of unique locations\n  int<lower = 1> d;                        // dimension of the spatial location\n  int<lower = 1> q;                    // total number of points for prediction\n  vector[N] Y;                             // observed data\n  matrix[N, p] X;                          // design matrix - fixed effects\n  array[N] int<lower = 1, upper = n> Ids;  // location mapping indices\n  array[n] vector[d] u;                    // locations for observed data\n  array[q] vector[d] u_new;          // locations for prediction\n  matrix[q, p] X_new;                 // design matrix for the new locations\n}\ntransformed data {\n  real delta = 1e-9;\n  matrix[N, p] X_centered;\n  row_vector[p] X_bar;\n  for (i in 1:p) {\n    X_bar[i] = mean(X[, i]);\n    X_centered[, i] = X[, i] - X_bar[i];\n  }\n}\nparameters {\n  // likelihood parameters\n  real alpha_star;         // centered intercept\n  vector[p] beta;          // population coefficients\n  real<lower = 0> sigma;   // nugget error term\n  // GP parameters\n  real<lower = 0> tau;     // GP scale for intercept\n  real<lower = 0> rho;     // GP length for intercept\n  vector[n] z;             // standard normal\n  // hyperparameters\n  real<lower = 0> sigma_beta;     // variance for coefficients\n}\ntransformed parameters {\n    // compute spatial intercept\n  matrix[n,n] LC = L_matern32(u, tau, rho, delta);\n  vector[n] theta = LC * z; // spatial intercept\n}\nmodel {\n  // likelihood\n  target += normal_lupdf(Y | alpha_star + X_centered * beta + theta[Ids], sigma);\n  // likelihood parameters\n  target += normal_lupdf(alpha_star | 0, 4);\n  target += normal_lupdf(beta | 0, sigma_beta);\n  target += normal_lupdf(sigma | 0, 2);\n  // GP parameters\n  target += normal_lupdf(tau | 0, 4);\n  target += inv_gamma_lupdf(rho | 5, 5);\n  target += normal_lupdf(z | 0, 1);  \n  // hyperparameters\n  target += normal_lupdf(sigma_beta | 0, 2);\n}\ngenerated quantities {\n  // intercepts\n  real alpha = alpha_star - X_bar * beta;\n  vector[n] alphas = alpha_star + theta;\n  // covariance\n  corr_matrix[n] Phi = cov2cor(add_diag(gp_matern32_cov(u, tau, rho), delta));\n  // posterior predictive distribution for the observed locations\n  array[N] real Y_pred = normal_rng(alpha + X * beta + theta[Ids], sigma);\n  // posterior predictive distribution across a new grid of locations\n  vector[q] theta_new = theta_new_rng(u, u_new, tau, rho, z, delta);\n  array[q] real Y_new = normal_rng(alpha + X_new * beta + theta_new, sigma);\n  // log-likelihood for loo\n  array[N] real log_lik;\n  for (i in 1:N) log_lik[i] = normal_lpdf(Y[i] | alpha + X[i, ] * beta + theta[Ids[i]], sigma);\n}\n```\n:::\n\n\n\n## Function to compute $\\mathbf{L}$\n\n\n\n::: {.cell output.var='L'}\n\n```{.stan .cell-code}\nfunctions {\n\tmatrix L_matern32(array[] vector x, real tau, real rho, real delta) { \n\t\tmatrix[size(x), size(x)] cov;\n\t\tcov = add_diag(gp_matern32_cov(x, tau, rho), delta);\n\t\treturn cholesky_decompose(cov);\n\t}\n\t...\n}\n```\n:::\n\n\n\n## Function to predict $\\boldsymbol{\\theta}^*$\n\n\n\n::: {.cell output.var='L'}\n\n```{.stan .cell-code}\nfunctions {\n  vector theta_new_rng(array[] vector x, array[] vector x_new, real tau, \n                        real rho, vector z_obs, real delta) {\n    int n = size(x);\n  \tint q = size(x_new);\n    vector[q] theta_new;\n\t  { // everything declared inside of {} will only exist in that local environment\n      matrix[n, n] LC = L_matern32(x, tau, rho, delta);\n      vector[n] theta_obs = LC * z_obs;\n      matrix[n, q] Cplus = gp_matern32_cov(x, x_new, tau, rho);\n      matrix[n, q] LCinv_Cplus = mdivide_left_tri_low(LC, Cplus);\n      vector[n] LCinv_theta_obs = mdivide_left_tri_low(LC, theta_obs);\n      vector[q] theta_new_mu = LCinv_Cplus' * LCinv_theta_obs;\n      matrix[q, q] C_star = add_diag(gp_matern32_cov(x_new, tau, rho), delta);\n      matrix[q, q] theta_new_cov = C_star - LCinv_Cplus' * LCinv_Cplus;\n      theta_new = multi_normal_rng(theta_new_mu, theta_new_cov);\n\t}\n\treturn theta_new;\n\t}\n\t...\n}\n```\n:::\n\n\n\n## Posterior summaries\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nInference for Stan model: anon_model.\n4 chains, each with iter=4000; warmup=2000; thin=1; \npost-warmup draws per chain=2000, total post-warmup draws=8000.\n\n            mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\nalpha      11.44    0.07 2.04  5.29 11.10 12.08 12.61 13.41   937 1.01\nbeta[1]     0.00    0.00 0.07 -0.15 -0.04  0.00  0.04  0.14  6759 1.00\nbeta[2]     0.01    0.00 0.19 -0.39 -0.06  0.00  0.08  0.41  3647 1.00\nsigma       1.76    0.00 0.06  1.64  1.72  1.76  1.80  1.88  3787 1.00\ntau         1.72    0.04 1.26  0.43  0.90  1.35  2.10  5.20   937 1.00\nrho         0.90    0.01 0.58  0.35  0.54  0.73  1.05  2.42  1837 1.00\nsigma_beta  0.31    0.01 0.44  0.01  0.06  0.15  0.36  1.57  3734 1.00\n\nSamples were drawn using NUTS(diag_e) at Fri Mar 14 09:53:01 2025.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n```\n\n\n:::\n:::\n\n\n\n## Traceplots\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n## Traceplots\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=1056}\n:::\n:::\n\n\n\n## Traceplots\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=1056}\n:::\n:::\n\n\n\n## Posterior predictive check\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n\n## Posterior correlation matrix\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n## Correlation as a function of distance\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n## Posterior predictive distribution\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=528}\n:::\n\n::: {.cell-output-display}\n![](18-geospatial_files/figure-revealjs/unnamed-chunk-17-2.png){fig-align='center' width=528}\n:::\n:::\n\n\n\n## Trying to understand these trends\n\n ![](./images/18/sud-kivu1.png){fig-align=\"center\" height=\"550\"}\n\n## Trying to understand these trends\n\n ![](./images/18/sud-kivu2.png){fig-align=\"center\" height=\"550\"}\n\n## Prepare for next class\n\n-   Work on HW 04, which is due before class on Tuesday.\n\n-   Complete reading to prepare for next Tuesday's lecture\n\n-   Tuesday's lecture: Disease mapping\n",
    "supporting": [
      "18-geospatial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}