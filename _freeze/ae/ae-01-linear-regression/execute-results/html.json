{
  "hash": "f9b5370a693768e1a874340bba2d8e96",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AE 01: Posterior estimation using sampling \"\nsubtitle: \"Houses in Duke Forest\"\ndate: \"Jan 16, 2025\"\n---\n\n\n\n::: callout-important\n## Due date\n\nApplication exercises (AEs) are submitted by pushing your work to the relevant GitHub repo. AEs from Tuesday lectures should be submitted by Friday by 11:59pm ET, and AEs from Thursday lectures should be submitted by Sunday at 11:59pm ET. Because AEs are intended for in-class activities, there are no extensions given on AEs.\n\nThis AE is due on **Friday, January 18 at 11:59pm.** To be considered on time, the following must be done by the due date:\n\n-   Final `.qmd` and `.pdf` files pushed to your GitHub repo\n-   **Note:** For homeworks and exams, you will also be required to submit your final `.pdf` file submitted on Gradescope\n:::\n\n# Introduction\n\nThis AE will go through much of the same workflow we've demonstrated in class. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n## Learning goals\n\nBy the end of the AE, you will...\n\n-   Be familiar with the workflow using RStudio and GitHub\n-   Gain practice writing a reproducible report using Quarto\n-   Practice version control using GitHub\n-   Be able to produce visualizations and summary statistics to describe distributions\n-   Be able to fit, interpret, and evaluate Bayesian linear regression models\n\n# Getting Started\n\n## Clone the repo & start new RStudio project\n\n-   Go to the course organization at [github.com/biostat725-sp25](https://github.com/biostat725-sp25) organization on GitHub.\n-   Click on the repo with the prefix **ae-01-**. It contains the starter documents you need to complete the AE.\n-   Click on the green **CODE** button, select **Use SSH** (this might already be selected by default, and if it is, you'll see the text **Clone with SSH**). Click on the clipboard icon to copy the repo URL.\n    -   See the [HW 00 instructions](https://biostat725-sp25.netlify.app/hw/hw-00#connect-rstudio-and-github) if you have not set up the SSH key or configured git.\n-   In RStudio, go to *File* $\\rightarrow$ *New Project* $\\rightarrow$ *Version Control* $\\rightarrow$ *Git*.\n-   Copy and paste the URL of your assignment repo into the dialog box *Repository URL*. Again, please make sure to have *SSH* highlighted under *Clone* when you copy the address.\n-   Click *Create Project*, and the files from your GitHub repo will be displayed in the *Files* pane in RStudio.\n-   Click `ae-01-linear-regression.qmd` to open the template Quarto file. This is where you will write up your code and narrative for the AE.\n\n## R and R Studio\n\nBelow are the components of the RStudio IDE.\n\n![](images/rstudio-panes.png){fig-alt=\"Screenshot of RStudio IDE\" fig-align=\"center\"}\n\nBelow are the components of an Quarto (`.qmd`) file.\n\n![](images/quarto.png){fig-alt=\"Screenshot of Quarto document and rendered PDF.\" fig-align=\"center\"}\n\n### YAML\n\nThe top portion of your Quarto file (between the three dashed lines) is called **YAML**. It stands for \"YAML Ain't Markup Language\". It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n::: callout-important\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n:::\n\n### Committing changes\n\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\n\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on **Diff**. This shows you the *diff*erence between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\nIf you're happy with these changes, we'll prepare the changes to be pushed to your remote repository. First, **stage** your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, \"updated author name\") in the **Commit message** box. Finally, click **Commit**. Note that every commit needs to have a commit message associated with it.\n\nYou don't have to commit after every change, as this would get quite tedious. You should commit states that are *meaningful to you* for inspection, comparison, or restoration.\n\nIn the first few assignments we may tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\n\nNow let's make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you're good to go!\n\n### Push changes\n\nNow that you have made an update and committed this change, it's time to push these changes to your repo on GitHub.\n\nIn order to push your changes to GitHub, you must have **staged** your **commit** to be pushed. click on **Push**.\n\n<!-- ::: callout-important -->\n<!-- Go to the [course GitHub organization](https://github.com/biostat725-sp25) and locate your `ae-01` repo to get started. -->\n\n<!-- Render, commit, and push your responses to GitHub by the end of class to submit your AE. -->\n<!-- ::: -->\n\n# R packages\n\nWe will begin by loading R packages that we will use in this AE.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # data wrangling and visualization\nlibrary(tidymodels)   # broom and yardstick package\nlibrary(openintro)    # duke_forest dataset\nlibrary(knitr)        # format output\nlibrary(scales)       # format plot axes\nlibrary(skimr)        # quickly calculate summary statistics\nlibrary(mvtnorm)      # multivariate normal rng\n```\n:::\n\n\n\n# Data\n\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the `duke_forest` data set in the **openintro** R package.\n\nWe will focus on two variables:\n\n-   `area`: Total area of the home in square feet (sqft)\n\n-   `price`: Sale price in US Dollars (USD)\n\nThe goal of this analysis is to use the area to understand variability in the price of homes in Duke Forest.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(duke_forest)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 98\nColumns: 13\n$ address    <chr> \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      <dbl> 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        <dbl> 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       <dbl> 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       <dbl> 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       <chr> \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built <dbl> 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    <chr> \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    <fct> central, central, central, central, central, central, centr…\n$ parking    <chr> \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        <dbl> 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        <chr> \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…\n```\n\n\n:::\n:::\n\n\n\n# Exploratory data analysis\n\nLet's begin by examining the univariate distributions of the price and area. The code to visualize and calculate summary statistics for `price` is below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = duke_forest, aes(x = price)) + \n  geom_histogram() +\n  labs(x = \"Price in US dollars\", \n       title = \"Price of houses in Duke Forest\") + \n  scale_x_continuous(labels = label_dollar(scale_cut = cut_long_scale()))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ae-01-linear-regression_files/figure-html/price-viz-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nduke_forest |>\n  summarise(min = min(price), q1 = quantile(price, 0.25), \n            median = median(price), q3 = quantile(price, 0.75), \n            max = max(price), mean = mean(price), sd = sd(price)) |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|   min|     q1| median|     q3|     max|     mean|       sd|\n|-----:|------:|------:|------:|-------:|--------:|--------:|\n| 95000| 450625| 540000| 643750| 1520000| 559898.7| 225448.1|\n\n\n:::\n:::\n\n\n\n# Posterior estimation\n\nYou want to fit a model of the form\n\n$$\nprice_i = \\beta_0 + \\beta_1 ~ area_i + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2).\n$$ \n\nWe can obtain samples from the posterior distribution for the regression parameters using the specification from the slides. We define the data objects needed for posterior estimation. Note that the distribution of the outcome has a massive range, so we scale the outcome and predictor to have mean zero and standard deviation one. This will help stabilize inference in the Gibbs sampler. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- cbind(1, scale(duke_forest$area))\nY <- scale(duke_forest$price)\np <- 1\nn <- length(Y)\n```\n:::\n\n\n\nWe will then define hyperparameters for the priors. Since, the data has been centered and scaled we can place priors that place most of the prior mass near zero.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma_beta2 <- 10\nbeta0 <- rep(0, p + 1)\na <- 3\nb <- 1\n```\n:::\n\n\n\nWe can now obtain samples from the posterior using Gibbs sampling. Let's set $S=5,000$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma2 <- exp(rnorm(1)) # initial value\nsamples <- NULL\nfor (s in 1:5000) {\n  ###Sample from full conditional for beta\n  var_beta <- chol2inv(chol(t(X) %*% X / sigma2 + diag(p + 1) / sigma_beta2))\n  mean_beta <- var_beta %*% (beta0 / sigma_beta2 + t(X) %*% Y / sigma2)\n  beta <- as.numeric(rmvnorm(1, mean_beta, var_beta))\n  \n  ###Sample from full conditional for sigma2\n  quadratic <- as.numeric(t(Y - X %*% beta) %*% (Y - X %*% beta))\n  sigma2 <- 1 / rgamma(1, shape = a + n / 2, rate = b + quadratic / 2)\n  \n  ###Save samples after a burn-in\n  samples <- rbind(samples, c(beta, sigma2))\n}\n```\n:::\n\n\n\n# Insepction of Gibbs sampler\n\nWe can begin by inspecting the posterior density and traceplots.\n\n\n\n::: {.cell layout-nrow=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\ndat.fig <- data.frame(\n  parameter = rep(c(\"beta[0]\", \"beta[1]\", \"sigma^2\"), each = 5000),\n  index = rep(1:5000, 3),\n  value = as.numeric(samples)\n)\nggplot(dat.fig, aes(x = value)) +\n  geom_density(lwd = 1.5) +\n  facet_grid(. ~ parameter, labeller = label_parsed, scales = \"free_x\") +\n  ylab(\"Density\") +\n  xlab(\"Parameter value\")\n```\n\n::: {.cell-output-display}\n![](ae-01-linear-regression_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=672}\n:::\n\n```{.r .cell-code}\nggplot(dat.fig, aes(x = index, y = value)) + \n  geom_line(lwd = 0.5) + \n  facet_grid(. ~ parameter, labeller = label_parsed, scales = \"free_x\") + \n  ylab(\"Parameter value\") +\n  xlab(\"Sample index\")\n```\n\n::: {.cell-output-display}\n![](ae-01-linear-regression_files/figure-html/unnamed-chunk-8-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n\nThe traceplots do not exhibit much autocorrelation, indicating we are looking at samples from the posterior.\n\nTo recover the regression parameters on their original scale, we can use the following transformation, where $\\mu_Y$, $\\sigma_Y$ are the mean and standard deviation for our outcome, *price*, $\\mu_X$, $\\sigma_X$ are the mean and standard deviation for the predictor, *area*, and $\\beta_0^*$, $\\beta_1^*$ are the regression parameters obtained from the Gibbs sampler above (i.e., on the transformed data).\n\n\\begin{align*}\n\\beta_0 &= \\mu_Y + \\sigma_Y \\beta_0^* - \\frac{\\sigma_Y}{\\sigma_X} \\mu_X \\beta_1^*\\\\\n\\beta_1 &= \\frac{\\sigma_Y}{\\sigma_X} \\beta_1^*\n\\end{align*}\n\nUsing this transformation, $\\beta_0$ and $\\beta_1$ are on the original scale.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_y <- mean(duke_forest$price)\nsd_y <- sd(duke_forest$price)\nmean_x <- mean(duke_forest$area)\nsd_x <- sd(duke_forest$area)\nintercept <- mean_y + sd_y * samples[, 1] - (sd_y / sd_x) * mean_x * samples[, 2]\nslope <- (sd_y / sd_x) * samples[, 2]\n```\n:::\n\n\n\nA histogram of the posterior parameters can be examined as follows. \n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](ae-01-linear-regression_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n\n::: {.cell-output-display}\n![](ae-01-linear-regression_files/figure-html/unnamed-chunk-10-2.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n# Exercises\n\n## Exercise 1\n\nCompute the posterior mean for the intercept and slope of each of the regression coefficients on the scale of the original data. Provide an interpretation for each of these parameter estimates.\n\n**Answer:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n## Exercise 2\n\nCompute a 95% confidence interval for the regression slope. Provide an interpretation for this confidence interval.\n\n**Answer:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n\n## Exercise 3\n\nIn real estate, the price per square foot is an indicator of how expensive it is to buy living space in that area, with a higher price per square foot generally signifying a more expensive city due to factors like high demand for limited land, desirable location, and often, a high cost of living.\n\nLet's assume that a city is considered to have a high living cost if the price per square foot is higher than 150. Using the slope as an estimate for price per square foot, estimate the probability that the Duke Forest area has a price per square foot greater than 150, $P(\\beta_1 > 150)$. Interpret the results in plain English. \n\n**Answer:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add code here\n```\n:::\n\n\n\n::: callout-important\nTo submit the AE:\n\n-   Render the document to produce the PDF with all of your work from today's class.\n-   Push all your work to your AE repo on GitHub. You're done! 🎉\n:::\n",
    "supporting": [
      "ae-01-linear-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}