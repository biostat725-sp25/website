---
title: "Probabilistic Programming (Intro to Stan!)"
author: "Prof. Sam Berchuck"
date: "2025-01-21"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    html-math-method: mathjax
filters:
  - parse-latex
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r, echo=FALSE}
library(ggplot2)
library(gridExtra)
library(knitr)
library(mvtnorm)
library(coda)
```

## Review of last lecture

On Thursday, we performed posterior inference for Bayesian linear regression using Gibbs and Metropolis sampling

-   We obtained correlated samples from the posterior using MCMC

-   Gibbs required a lot math!

-   Metropolis required tuning!

Today we will introduce Stan, a probabilistic programming language that uses Hamiltonian Monte Carlo to perform general Bayesian inference

## Learning objectives

By the end of this lecture you should:

-   Know how to start coding up a model in Stan

-   Appreciate how easy Stan makes things for us compared to coding up the algorithm ourselves

-   Know what to do when coding goes wrong

-   Know what to do when sampling goes wrong

## What is Stan and how do we use it?

-   Stan is an intuitive yet sophisticated programming language that does the hard work for us.

-   Programming language like R, Python, Matlab, C++...

-   Works like most other languages: can use loops, conditional statements, and functions.

-   Code up a model in Stan and then it implements HMC (actually something called NUTS) for us.

## Why should we use Stan?

-   Stan is the brainchild of Andrew Gelman at Colombia.

-   Stanâ€™s uses an extension of HMC called NUTS that automatically tunes. It is fast.

-   Stan is simple to learn.

-   Stan has excellent documentation (a manual full of extensive examples).

-   **Most important:** Stan has a very active and helpful user forum and development team; for example, typical question answered in less than a couple of hours.

## How do we use it?

Code up model in Stan code in a text editor and save as `.stan` file.

-   Call Stan to run the model from:

    -   R, python, the command line, Matlab, Stata, Julia

-   Use one of the above to analyse the data (of course you can export to another one).

## A straightforward example {.midi}

Suppose:

-   We record the height, $Y_i$, of 10 people.

-   We want a model to explain the variation, and choose a normal likelihood: $$Y_i \sim N(\mu, \sigma^2)$$

-   We choose the following (independent) priors on each parameter:

    -   $\mu \sim N(0, 1)$
    -   $\sigma^2 \sim IG(1, 1)$

-   **Question:** how do we code this up in Stan?

## An example Stan program

```{stan output.var = "straightforward", eval=FALSE}
data {
  real Y[10]; // height for 10 people
}
parameters {
  real mu;
  real<lower = 0> sigma;
}
model {
  Y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 1); // prior for mu
  sigma ~ inv_gamma(1, 1); // prior for sigma
}
```

## An example Stan program: data block

```{stan output.var = "straightforward", eval=FALSE}
data {
  real Y[10]; // height for 10 people
}
```

-   Declare all data that you will pass to Stan to estimate your model.

-   Terminate all statements with a semi-colon `;`.

-   Use `##` or `//` for comments.

## An example Stan program: data block

```{stan output.var = "straightforward", eval=FALSE}
data {
  real Y[10]; // height for 10 people
}
```

-   We need to tell Stan the type of data variable. For example:

    -   `real` for continuous data.

    -   `int` for discrete data.

    -   Arrays: above we specified `Y` as an array of continuous data of length 10.

## An example Stan program: data block

```{stan output.var = "straightforward", eval=FALSE}
data {
  real Y[10]; // height for 10 people
}
```

Can place limits on data, for example:

-   `real<lower = 0, upper = 1> X;`

-   `real<lower = 0> Z;`

Vectors and matrices; only contain reals and can be used for matrix operations.

```{stan output.var = "straightforward", eval=FALSE}
real Y[10]; // array representation
vector[10] Y; // vector representation
```

## An example Stan program: parameter block {.midi}

```{stan output.var = "straightforward", eval=FALSE}
parameters {
  real mu;
  real<lower = 0> sigma;
}
```

-   Declare all parameters that you use in your model.

-   Place limits on variables, for example:

    -   `real<lower = 0> sigma`

A multitude of parameter types including some of the aforementioned:

-   `real` for continuous parameters.

-   Arrays of types, for example `real beta[10]`

## An example Stan program: parameter block

```{stan output.var = "straightforward", eval=FALSE}
parameters {
  real mu;
  real<lower = 0> sigma;
}
```

-   `vector` or `matrix`, specified by:

    -   `vector[5] beta`

    -   `matrix[5, 3] gamma`

-   `simplex` for a parameter vector that must sum to 1.

-   More exotic types like `corr_matrix`, or `ordered`.

## An example Stan program: parameter block

```{stan output.var = "straightforward", eval=FALSE}
parameters {
  real mu;
  real<lower = 0> sigma;
}
```

**Important:** Stan is not developed yet to work with discrete parameters. Options for discrete parameters in Stan:

-   Marginalize out the parameter. For example, suppose we have $f(\boldsymbol{\beta}, \theta)$, where $\boldsymbol{\beta}$ is continuous and $\theta$ is discrete:

\begin{center}$f(\boldsymbol{\beta}) = \sum_{i = 1}^K f(\boldsymbol{\beta}, \theta_i)$\end{center}

-   Some models can be reformulated without discrete parameters.

## An example Stan program: model block

```{stan output.var = "straightforward", eval=FALSE}
model {
  Y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 1); // prior for mu
  sigma ~ inv_gamma(1, 1); // prior for sigma
}
```

-   Used to define:

    -   Likelihood.

    -   Priors on parameters.

If donâ€™t specify priors on parameters Stan assumes you are using flat priors (which can be improper).

## An example Stan program: model block

```{stan output.var = "straightforward", eval=FALSE}
model {
  Y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 1); // prior for mu
  sigma ~ inv_gamma(1, 1); // prior for sigma
}
```

Huge range of probability distributions covered, across a range of parameterizations. For example:

-   **Discrete:** Bernoulli, binomial, normal, Poisson, beta-binomial, negative-binomial, categorical, multinomial.

-   **Continuous unbounded:** normal, skew-normal, student-t, Cauchy, logistic.

## An example Stan program: model block

```{stan output.var = "straightforward", eval=FALSE}
model {
  Y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 1); // prior for mu
  sigma ~ inv_gamma(1, 1); // prior for sigma
}
```

-   **Continuous bounded:** uniform, beta, log-normal, exponential, gamma, chi-squared, inverse-chi-squared, Weibull, Wiener diffusion, Pareto.

-   **Multivariate continuous:** normal, student-t, Gaussian process.

-   **Exotics:** Dirichlet, LKJ correlation distribution, Wishart and its inverse, Von-Mises.

## Running Stan

Write model in a text editing program and save as a `.stan` file.

-   To create a `.stan` file from RStudio, `File -> New File -> Stan File`.

```{r, eval=FALSE}
###Load packages
library(rstan)

###Generate fake data
Y <- rnorm(10, mean = 0, sd = 1)

###Compile and run model, and save in fit
fit <- stan(file = 'straightforward.stan', data = list(Y= Y), 
            iter = 1000, chains = 4, seed = 1)
```

```{r, echo=FALSE}
# ## Load packages
# library(rstan)
# 
# ## Generate fake data
# Y <- rnorm(10, mean = 0, sd = 1)
# 
# ## Compile and run model, and save in fit
# fit <- stan(file = '/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/straightforward.stan', data = list(Y= Y), 
#             iter = 1000, chains = 4)
# saveRDS(fit, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/straightforward_fit.rds")
library(rstan)
fit <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/straightforward_fit.rds")
```

## Running Stan on example model

```{r, eval=FALSE}
###Compile and run model, and save in fit
fit <- stan(file = 'straightforward.stan', data = list(Y = Y), 
            iter = 1000, chains = 4, seed = 1)
```

The above R code runs NUTS for our model with the following options:

-   $S=1,000$ MCMC samples of which 500 are discarded as warm-up.

-   Across 4 chains.

-   Using a random number seed of 1 (good to ensure you can reproduce results).

## Example model: results

```{r}
###Print summary statistics
print(fit, probs = c(0.25, 0.5, 0.75))
```

## Example model: results

```{r}
###Extract posterior samples
pars <- extract(fit)
class(pars)
names(pars)

###Extract samples for particular parameters
pars <- extract(fit, pars = "mu")
class(pars$mu)
dim(pars$mu)
```

## Visualize posterior

```{r}
#| echo: true
#| fig-align: "center"
#| fig-width: 4
#| fig-height: 4
#| layout-nrow: 1
###Extract samples for particular parameters
library(ggplot2)
data.frame(mu = pars$mu) |>
  ggplot(aes(x = mu)) +
  geom_histogram() +
  labs(x = expression(mu), y = "Count", 
       subtitle = bquote("Posterior distribution for " ~ mu))
```

## Quick note: what does $\sim$ mean? {.midi}

```{stan output.var = "straightforward", eval=FALSE}
model {
  Y ~ normal(mu, sigma); // likelihood
  mu ~ normal(0, 1); // prior for mu
  sigma ~ inv_gamma(1, 1); // prior for sigma
}
```

-   $\sim$ doesn't mean *sampling*, although often times it can be thought of as sampling

-   MCMC/HMC makes use of the log-posterior

$$\log f(\boldsymbol{\theta} | \mathbf{Y}) \propto \log f(\boldsymbol{\theta}) + \sum_{i=1}^n \log f(\mathbf{Y} | \boldsymbol{\theta})$$

-   As such $\sim$ really means *increment log probability*

-   All we have to do in Stan is specify the log-posterior!

## Alternate way of specifying Stan models {.midi}

```{stan output.var = "straightforward", eval=FALSE}
model {
  target += normal_lpdf(Y | mu, sigma); // likelihood
  target += normal_lpdf(mu | 0, 1); // prior for mu
  target += inv_gamma_lpdf(sigma | 1, 1); // prior for sigma
}
```

-   `target` is a not a variable, but a special object that represents incremental log probability.

-   `target` is initialized to zero.

-   `normal_lpdf` is the log of the normal density of `y` given location `mu` and scale `sigma`:

-   [Stan documentation for normal distribution](https://mc-stan.org/docs/functions-reference/unbounded_continuous_distributions.html#normal-distribution)

```{stan output.var = "std_normal", eval=FALSE}
target += std_normal_lpdf(mu) // prior for mu using standard normal
```

## Linear regression using Stan: data and parameter chunks

```{stan output.var = "linear_regression", eval=FALSE}
data {
  int<lower = 1> n; // number of observations
  int<lower = 1> p; // number of covariates
  vector[n] Y; // outcome vector
  matrix[, p + 1] X; // covariate vector
  real beta0; // location hyperparameter for beta
  real<lower = 0> sigma_beta; // scale hyperparameter for beta
  real<lower = 0> a; // shape hyperparameter for sigma
  real<lower = 0> b; // scale hyperparameter for sigma
}
parameters {
  vector[p + 1] beta;
  real<lower = 0> sigma;
}
```

## Linear regression using Stan: model chunk

```{stan output.var = "linear_regression", eval=FALSE}
model {
  for (i in 1:n) {
    target += normal_lpdf(Y[i] | X[i, ] * beta, sigma); // likelihood
  }
  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta
  target += inv_gamma_lpdf(sigma | a, b); // prior for sigma
}
```

## Linear regression using Stan: vectorization

It is always a good idea to vectorize Stan code for faster and more efficient inference

```{stan output.var = "linear_regression", eval=FALSE}
model {
  target += normal_lpdf(Y | X * beta, sigma); // likelihood
  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta
  target += inv_gamma_lpdf(sigma | a, b); // prior for sigma
}
```

## Linear regression using Stan

```{stan output.var = "linear_regression", eval=FALSE}
// saved in linear_regression.stan
data {
  int<lower = 1> n; // number of observations
  int<lower = 1> p; // number of covariates
  vector[n] Y; // outcome vector
  matrix[n, p + 1] X; // covariate vector
  real beta0; // location hyperparameter for beta
  real<lower = 0> sigma_beta; // scale hyperparameter for beta
  real<lower = 0> a; // shape hyperparameter for sigma
  real<lower = 0> b; // scale hyperparameter for sigma
}
parameters {
  vector[p + 1] beta;
  real<lower = 0> sigma;
}
model {
  target += normal_lpdf(Y | X * beta, sigma); // likelihood
  target += normal_lpdf(beta | beta0, sigma_beta); // prior for beta
  target += inv_gamma_lpdf(sigma | a, b); // prior for sigma
}
```

## Let's simulate some data again

```{r}
###True parameters
sigma <- 1.5 # true measurement error
beta <- matrix(c(-1.5, 3), ncol = 1) # true beta

###Simulation settings
n <- 100 # number of observations
p <- length(beta) - 1 # number of covariates

###Simulate data
set.seed(54) # set seed
X <- cbind(1, matrix(rnorm(n * p), ncol = p))
Y <- as.numeric(X %*% beta + rnorm(n, 0, sigma))
```

## Fit linear regression using Stan

```{r, eval=FALSE}
###Load packages
library(rstan)

###Create stan data object
stan_data <- list(n = n,
                  p = p,
                  Y = Y,
                  X = X,
                  beta0 = 0,
                  sigma_beta = 10,
                  a = 3, 
                  b = 1)
  
###Compile model separately
stan_model <- stan_model(file = "linear_regression.stan")

###Run model and save
fit <- sampling(stan_model, data = stan_data, 
                chains = 4, iter = 1000)
saveRDS(fit, file = "linear_regression_fit.rds")
```

```{r, echo=FALSE}
# ###Create stan data object
# stan_data <- list(n = n,
#                   p = p,
#                   Y = Y,
#                   X = X,
#                   beta0 = 0,
#                   sigma_beta = 10,
#                   a = 3, 
#                   b = 1)
#   
# ###Compile model separately
# stan_model <- stan_model(file = "robjects/linear_regression.stan")
# 
# ###Run model and save
# fit <- sampling(stan_model, data = stan_data, chains = 4, iter = 1000)
# saveRDS(fit, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/linear_regression_fit.rds")
fit <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/linear_regression_fit.rds")
```

## Example model: results

```{r}
###Print summary statistics
print(fit, probs = c(0.25, 0.5, 0.75))
```

## Stan plots: point estimate and intervals

```{r}
stan_plot(fit, pars = c("beta", "sigma"), include_warmup = FALSE,
          point_est = "median", ci_level = 0.8, outer_level = 0.95)
```

## Stan plots: histogram

```{r}
stan_hist(fit)
```

## Stan plots: density

```{r}
stan_dens(fit)
```

## Stan: a few of the loops and conditions

Stan has pretty much the full range of language constructs to allow pretty much any model to be coded.

`for (i in 1:10) {something;}`\
\

`while (i > 1) {something;}`\
\

`if (i > 1) {something 1;}`\
`else if (i == 0) {something2;}`\
`else {something 3;}`

## Stan speed concerns

Whilst Stan is fast it pays to know the importance of each code block for efficiency.

-   **data:** called once at beginning of execution.

-   **transformed data:** called once at beginning of execution.

-   **parameters:** every log probability evaluation!

-   **transformed parameters:** every log probability evaluation!

-   **model:** every log probability evaluation!

-   **generated quantities:** once per sample.

-   **functions:** how many times it is called depends on the function's nature.

## Stan in parallel

In R can run chains in parallel easily using:

```{r}
library(rstan)
options(mc.cores = 8)
```

## Stan summary

-   Stan works by default with a HMC-like algorithm called NUTS.

-   The Stan language is similar in nature to other common languages with loops, conditional statements and user-definable functions (didnâ€™t cover here).

-   Stan makes life easier for us than coding up the MCMC algorithms ourselves.

## R packages that interface with Stan {.midi}

-   `rstan`, `brms`, `cmdstanr`, `rstanarm`

-   `rstan` and `cmdstanr` you write the Stan code, which gives you the most options.

    -   `rstan` has a more intuitive user interface.

    -   `cmdstanr` is more memory efficient and a lightweight interface to Stan.

-   `rstanarm` and `brms` you don't need to write the Stan code yourself, which makes it easier to use Stan, but is limiting.

    -   `rstanarm`'s biggest advantage is that the models are pre-compiled, but this is also it's biggest limitation.

    -   `brms` writes Stan code on the fly, so has many more models, some that are pretty advanced.

## Prepare for next class

-   Work on [HW 01](https://biostat725-sp25.netlify.app/hw/hw-01) which is due January 30

-   Complete reading to prepare for next Thursday's lecture

-   Thursday's lecture: Priors, Posteriors, and PPDs!
