---
title: "Disease Mapping"
author: "Prof. Sam Berchuck"
date: "2025-03-25"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    html-math-method: mathjax
filters:
  - parse-latex
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r, echo=FALSE, message=FALSE, warning=FALSE, }
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(knitr)
library(bayesplot)
library(rstan)
library(igraph)
library(tidycensus)
library(sf)
library(rnaturalearth)
library(tidyverse)
library(tigris)
library(scales)
library(spdep)
library(reshape2)
covid_nc_2020 <- st_read("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/data/covid/covid_nc_2020.shp", quiet = TRUE)
```

## Review of last week

-   Last week, we learned about Gaussian processes.

-   We learned how to apply Gaussian processes to longitudinal (or time-series) and geospatial data.

-   Focused on making predictions at new locations across the spatial surface.

-   Today we will focus on areal spatial data, which has different goals associated with it than point-referenced spatial data.

## Lattice Data (Areal Data)

-   Data observed at the level of an areal unit

    -   County Level Sudden Infant Death Syndrome Counts

![](./images/18/lattice_data.png){fig-align="center" height="450"}

## Lattice Data (Areal Data)

-   Birmingham Tract Level Poverty Levels

![](./images/18/Birmingham_Poverty.png){fig-align="center" height="500"}

## Goals of Areal Spatial Data Analysis

The goal of **areal spatial data analysis** is to understand how spatial patterns (e.g., mortality rates, disease incidence) vary across different geographic areas (e.g., counties, neighborhoods).

It helps us identify:

-   **Clusters**: Areas with similar characteristics (e.g., high mortality, disease prevalence).

-   **Outliers**: Areas that deviate significantly from the overall pattern (e.g., unexpectedly high mortality rates).

-   **Spatial Dependence**: Whether values in one area are correlated with values in nearby areas (e.g., neighboring counties with similar health outcomes).

## Why We Care About Spatial Patterns

-   **Local Insights**: Spatial analysis helps identify **local variations** in health outcomes that may not be apparent when analyzing data at a higher (e.g., state or national) level.

-   **Targeted Interventions**: Understanding spatial patterns allows for **targeted public health interventions** tailored to regions that need attention (e.g., areas with unusually high mortality rates).

-   **Identifying Spatial Clusters**: By recognizing **clusters of high or low rates**, we can investigate potential **common causes** (e.g., environmental factors, access to healthcare, socioeconomic conditions).

## Motivating Data {.midi}

Today, we will motivate areal spatial data analysis and disease mapping by studying 2020 COVID mortality at the county-level in North Carolina. The data object `covid_nc_2020` is an `sf` object.

-   Variables are:

    -   `name`: county name.

    -   `population`: 2020 population.

    -   `obs_deaths`: observed number of COVID-related deaths in 2020.

    -   `est_deaths`: estimated number of COVID-related deaths in 2020.

    -   `smr`: standardized mortality ratio.

    -   `age`: precentage of residents over 60 years of age.

    -   `poverty`: percentage of residents below the poverty line.

    -   `geometry`: contains centroid and boundary information for each county.

## COVID Mortality

<!-- - Account for noise due to spatial variability in order to provide smoothed estimates across space -->

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 10
#| fig-height: 5
#| layout-ncol: 1
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = obs_deaths), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = "Observed 2020 COVID Deaths by County",
    fill = "Deaths"
  ) +
  scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
```

## Introduction to Disease Mapping

-   Disease mapping is a way of visualizing and analyzing geographic variations in health outcomes, such as mortality or disease incidence, across different regions (e.g., counties or neighborhoods).

-   It helps us identify regions with unusually high or low health outcomes, which could be indicative of underlying health disparities.

## The Challenge with Observed Data

Imagine you want to compare the number of deaths across counties in a state, like North Carolina. If we simply look at **observed death counts**, we might be misled:

-   Larger counties with more people may have more deaths simply due to their larger population.

-   Smaller counties may appear "healthier" simply because they have fewer people, not because they have lower mortality rates.

Thus, observed death counts are **not enough** to draw meaningful comparisons.

## The Challenge with Observed Data

-   To make fair comparisons between regions of different sizes, we need to **adjust for population size** (and sometimes demographics).

-   Without these adjustments, it's hard to determine if a county's high death count is due to its population size or if there's something unique about the county (e.g., healthcare access, environmental factors) that increases the risk of mortality.

-   This is where we need more **nuanced measures** to adjust for population size and allow for better comparisons.

-   Today we will talk about the standardized mortality ratio (SMR).

## Standardized Mortality Ratio

-   SMR is a way of comparing the observed number of deaths in a population to the number of deaths we would expect, given the population's characteristics (such as population size).

-   It adjusts for differences in population, allowing us to identify areas where deaths are higher or lower than we would expect.

$$\text{SMR} = \frac{\text{Observed Deaths}}{\text{Expected Deaths}}$$

-   **Expected Deaths** is calculated by multiplying the total deaths across the state by the proportion of the population in that county.

## Example Data {.midi}

| County   | Observed Deaths | Population | Population Proportion |
|----------|-----------------|------------|-----------------------|
| County A | 10              | 30,000     | 0.3                   |
| County B | 15              | 50,000     | 0.5                   |
| County C | 5               | 20,000     | 0.2                   |
| Total    | 30              | 100,000    | 1.0                   |

## Step 1 - Calculate Expected Deaths

The **Expected Deaths** for each county are calculated by multiplying the **total deaths** by the **population proportion** for that county:

\begin{align*}
\text{Expected Deaths for County A} = 30 \times 0.3 &= 9\\
\text{Expected Deaths for County B} = 30 \times 0.5 &= 15\\
\text{Expected Deaths for County C} = 30 \times 0.2 &= 6
\end{align*}

## Step 2 - Compute SMR

Now, we calculate the **SMR** by dividing the **observed deaths** by the **expected deaths**:

\begin{align*}
\text{SMR for County A} &= \frac{10}{9} = 1.11\\
\text{SMR for County B} &= \frac{15}{15} = 1\\
\text{SMR for County C} &= \frac{5}{6} = 0.83
\end{align*}

What do these numbers mean?

## Interpreting SMR

-   **SMR = 1**: The observed number of deaths matches the expected number of deaths.

-   **SMR \> 1**: More deaths than expected (excess mortality).

-   **SMR \< 1**: Fewer deaths than expected (lower mortality).

In our example:

-   **County A** has excess mortality, with SMR of **1.11**.

-   **County B** has as many deaths as expected, with SMR of **1**.

-   **County C** has fewer deaths than expected, with SMR of **0.83**.

## Why Use SMR in Disease Mapping?

**SMR** allows us to:

-   Make meaningful comparisons across counties of different sizes.

-   Identify areas with **excess mortality** (SMR \> 1) and areas with **lower-than-expected mortality** (SMR \< 1).

In disease mapping, **SMR** helps us better understand **spatial health disparities** and identify regions that may need targeted public health interventions.

## Standardized Mortality Ratios

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 10
#| fig-height: 5
#| layout-ncol: 1
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = smr), shape = 16, size = 2) +
  theme_minimal() +
  scale_fill_gradient2(
    low = "green",        # Color for O/E < 1
    mid = "gray",        # Neutral color for O/E = 1
    high = "red",        # Color for O/E > 1
    midpoint = 1,        # Center the color scale at 1
    name = "SMR"
  ) +
  labs(
    title = "Standardized Mortality Ratios (SMRs) across NC Counties",
    fill = "SMR"
  ) +
  # scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
```

## Writing down a model for SMR

Define $Y_i$ and $E_i$ as the observed and expected mortality counts at county $i$ ($i = 1\ldots,n$). We can model the observed counts as follows:

$$Y_i | \lambda_i \stackrel{ind}{\sim} \text{Poisson}(E_i \lambda_i).$$

-   Recall that for a random variable $Y \sim \text{Poisson}(\lambda)$, $\mathbb{E}[Y] = \lambda$ and $\mathbb{V}(Y) = \lambda$.

-   We have: $\mathbb{E}[Y_i | \lambda_i] = E_i \lambda_i \implies \mathbb{E}\left[(Y_i / E_i) | \lambda_i\right] = \lambda_i.$

    -   Under this parameterization $\lambda_i$ is the SMR.

## Disease Mapping Model

The parameter $\lambda_i$, sometimes also called **relative risk**, is modeled as follows:

\begin{align*}
Y_i | \lambda_i &\stackrel{ind}{\sim} \text{Poisson}(E_i \lambda_i)\\
\log \lambda_i &= \alpha + \mathbf{x}_i \boldsymbol{\beta} + \theta_i + \epsilon_i, \quad \epsilon_i \stackrel{iid}{\sim} N(0,\sigma^2)
\end{align*}

where $\mathbf{x}_i \in \mathbb{R}^{p \times 1}$ contains county-level predictors.

**Population parameters**:

-   $\alpha \in \mathbb{R}$ is a population intercept.

-   $\boldsymbol{\beta} \in \mathbb{R}^p$ is a vector of population coefficients.

-   $\sigma \in \mathbb{R}^+$ is a residual error term.

## Disease Mapping Model

The parameter $\lambda_i$, sometimes also called **relative risk**, is modeled as follows:

\begin{align*}
Y_i | \lambda_i &\stackrel{ind}{\sim} \text{Poisson}(E_i \lambda_i)\\
\log \lambda_i &= \alpha + \mathbf{x}_i \boldsymbol{\beta} + \theta_i + \epsilon_i,\quad \epsilon_i \stackrel{iid}{\sim} N(0,\sigma^2)
\end{align*}

**Spatial Error Term**:

-   $\theta_i \in \mathbb{R}$ is a location-specific parameter that smooths data according to a neighborhood structure.

-   $\theta_i$ induces spatial correlation, such that $\lambda_i$ in neighboring areas will be more similar.

## Spatial Correlation: Areal Data

-   How to induce spatial correlation between areal units?

    -   Distances between centroids (possibly population weighted); may be inappropriate for oddly shaped regions of varying sizes (great for equal sized grid though).

    -   Neighborhood structure of your spatial region; are two regions neighbors?

-   Correlation introduced through spatial random effects.

-   The default model for areal data in the Bayesian setting is called the conditionally autoregressive (CAR) model.

## Adjacency Matrix

-   We will define the matrix $\mathbf{W} \in \mathbb{R}^{n \times n}$ as the **adjacency matrix**.

    -   This is sometimes called a **proximity matrix** or **neighborhood matrix**.

-   Each entry ($w_{ij} = [\mathbf{W}]_{ij}$) is given by: $$w_{ij} = 1(i \sim j) = \left\{ \begin{array}{ll}
           1 & \mbox{if $i$ and $j$ share a border};\\
           0 & \mbox{otherwise}.\end{array} \right.$$

-   In some cases, $w_{ij}$ can be generalized to be non-binary.

## Compute Adjacency Matrix

To compute the adjacency matrix of an `sf` data object we can use the `spdep` library.

```{r}
neighbors <- spdep::poly2nb(covid_nc_2020) # computes the neighborhood structure
W <- spdep::nb2mat(neighbors, style = "B", zero.policy = TRUE) # converts to an n x n matrix
```

-   `style = "B"` specifies binary encoding (1 if neighbors, 0 if not).

-   `zero.policy = TRUE` ensures the function works even if some counties do not have neighbors.

## Visualzing the Adjacency Matrix

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 6
#| fig-height: 6
#| layout-ncol: 1
W_long <- melt(W)
ggplot(W_long, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_classic() + 
  theme(legend.position = "none") + 
  coord_fixed() + 
  labs(title = "Adjacency Matrix Heatmap", x = "County", y = "County")
```

## Visualzing the Adjacency Matrix

```{r, echo = FALSE}
# Get the centroids of each county
centroids <- st_centroid(covid_nc_2020)
centroids <- centroids %>% mutate(id = 1:nrow(centroids))
edges <- which(W == 1, arr.ind = TRUE)

# Create a data frame with the indices of the neighboring counties
neighbor_pairs <- data.frame(
  from = edges[, 1],
  to = edges[, 2]
)
```

```{r, echo = FALSE}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 10
#| fig-height: 5
#| layout-ncol: 1
ggplot(data = covid_nc_2020) +
  geom_sf(fill = NA, color = "black") +
  # Add lines connecting neighboring counties
  geom_segment(data = neighbor_pairs,
               aes(x = st_coordinates(centroids)[from, 1], y = st_coordinates(centroids)[from, 2],
                   xend = st_coordinates(centroids)[to, 1], yend = st_coordinates(centroids)[to, 2]),
               color = "blue", size = 1.5) +
  geom_sf(data = centroids, aes(geometry = geometry), color = "red", size = 3) +
  theme_minimal() +
  coord_sf(expand = FALSE) +  # Use coord_sf to control map projection
  labs(x = "Longitude", y = "Latitude") +
  ggtitle("County Adjacency Map") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Optional: Rotate x-axis labels for better readability
```

## ICAR Model

Today, we will look at the intrinsic CAR (ICAR) process for a vector $\boldsymbol{\theta} = (\theta_1, \ldots, \theta_n)^\top$, $\boldsymbol{\theta} | \tau^2 \sim \text{ICAR}\left(\tau^2\right)$. Under this specification, the following joint distribution is given:

$$f(\boldsymbol{\theta} | \tau^2) \propto \exp\left\{-\frac{1}{2\tau^2}\boldsymbol{\theta}^\top \left(\mathbf{D}_w - \mathbf{W}\right) \boldsymbol{\theta}\right\},$$

where $\mathbf{D}_w$ is diagonal with $[\mathbf{D}_w]_{ii} = w_{i+}$ and $w_{i+} = \sum_{j=1}^n w_{ij}$ (i.e., $w_{i+}$ is the number of neighbors for locations $i$).

-   $\left(\mathbf{D}_w - \mathbf{W}\right)$ is singular, so $\left(\mathbf{D}_w - \mathbf{W}\right)^{-1}$ does not exist and this distribution is improper.

-   We can still use this as a prior for $\boldsymbol{\theta}$ and get a proper posterior!

## ICAR Model: Conditional Distributinos

The joint distribution on the previous slide can be written as a $n$ conditional distributions:

$$\theta_{i} | \boldsymbol{\theta}_{-i}, \tau^2 \sim  N \left({\frac{\sum_{j=1}^n w_{ij}\theta_{j}}{w_{i+}}},\frac{\tau^2}{w_{i+}}\right)$$

-   $\boldsymbol\theta_{-j}$: Vector of $\theta_{i}$ parameters with $\theta_{j}$ removed.

-   The mean is an average of the neighbors values.

-   The variance shrinks as a function of the number of neighbors.

## Another Equivalent Specification

Pairwise difference specification:

$$f(\boldsymbol{\theta} | \tau^2) \propto \exp\left\{-\frac{1}{2\tau^2}\sum_{i \sim j} w_{ij} (\theta_i - \theta_j)^2\right\},$$

-   The impropriety of the distribution can also be seen here, because we can add any constant to all $\theta_i$ and the distribution is unaffected.

-   A constraint such as $\sum_{i=1}^n \theta_i = 0$ would provide the needed centering.

-   We will use this specification in Stan.

## Full Disease Mapping Model

The full model can be written as:

\begin{align*}
Y_i | \lambda_i &\stackrel{ind}{\sim} \text{Poisson}(E_i \lambda_i)\\
\log \lambda_i &= \alpha + \mathbf{x}_i \boldsymbol{\beta} + \theta_i + \epsilon_i,\quad \epsilon_i \stackrel{iid}{\sim} N(0,\sigma^2)\\
\boldsymbol{\theta} | \tau &\sim \text{ICAR}\left(\tau^2\right)\\
\boldsymbol{\Omega} &\sim f(\boldsymbol{\Omega}),\\
\end{align*}

where $\boldsymbol{\Omega} = (\alpha, \boldsymbol{\beta}, \sigma, \tau)$.

-   $\mu_i = \exp\{\log E_i + \alpha + \mathbf{x}_i\boldsymbol{\beta} + \theta_i + \epsilon_i\}$.

## Posterior Distribution

Define $\mathbf{Y} = (Y_1,\ldots,Y_n)$. The posterior can be written as:

\begin{align*}
f(\boldsymbol{\Omega}, \boldsymbol{\theta} | \mathbf{Y}) &\propto f(\mathbf{Y}, \boldsymbol{\Omega},\boldsymbol{\theta})\\
&\propto f(\mathbf{Y} | \boldsymbol{\Omega},\boldsymbol{\theta}) f(\boldsymbol{\theta} | \boldsymbol{\Omega}) f(\boldsymbol{\Omega})\\
&\propto f(\boldsymbol{\Omega}) \prod_{i=1}^n f({Y}_i | \lambda_i) f(\theta_i | \tau^2) .
\end{align*}

## Adding the ICAR prior to Stan

We will use the pairwise differences specification, so we need the unique pairs of neighbors. We will define $n_{edges}$ as the number of non-zero edges. The following is added to the Stan data code chunk.

```{stan output.var = "icar", eval = FALSE}
data {
  int<lower=0> n;
  int<lower=0> n_edges;
  array[n_edges] int<lower = 1, upper = n> node1; // node1[i] adjacent to node2[i]
  array[n_edges] int<lower = 1, upper = n> node2; // and node1[i] < node2[i]
  ...
}
```

## Extracting non-zero edges for Stan

Our goal is to get the row-column pairs from $\mathbf{W}$ where the $w_{ij} = 1$. This will return all non-zero indices in the adjacency matrix.

```{r}
neighbor_pairs <- which(W == 1, arr.ind = TRUE)
```

Since $\mathbf{W}$ is symmetric, we only need to keep the edges from above the diagonal to avoid repeating edges.

```{r}
neighbor_pairs_lower <- neighbor_pairs[neighbor_pairs[, 1] < neighbor_pairs[, 2], ]
n_edges <- nrow(neighbor_pairs_lower)
node1 <- neighbor_pairs_lower[, 1]
node2 <- neighbor_pairs_lower[, 2]
```

## Adding the ICAR prior to Stan

We can then add the following to the parameters and model Stan code chunks, where we leverage Stan's ability to perform multi-indexing and vectorization!

```{stan output.var = "icar", eval = FALSE}
parameters {
  vector[n] z;
}
transformed parameters {
  vector[n] theta = tau * z;
}
model {
  target += -0.5 * dot_self(z[node1] - z[node2]);
  // soft sum-to-zero constraint on z,
  // equivalent to mean(z) ~ normal(0,0.01)
  sum(z) ~ normal(0, 0.01 * n);
}
```

## Non-centered parameterization

In Stan it is more computationally efficient to use a non-centered parameterization. We define, $\mathbf{z} \in \mathbb{R}^n$ and give it the following prior:

$$\mathbf{z} \sim \text{ICAR}(\tau^2 = 1), \quad \sum_{i=1}^n z_i = 0.$$

We can then recover $\boldsymbol{\theta}$ by computing $\boldsymbol{\theta} = \tau \mathbf{z}.$

## Modeling {.midi}

We specify the following model:

\begin{align*}
Y_i | \lambda_i &\stackrel{ind}{\sim} \text{Poisson}(E_i \lambda_i)\\
\log \lambda_i &= \alpha + \mathbf{x}_i \boldsymbol{\beta} + \theta_i + \epsilon_i,\quad \epsilon_i \stackrel{iid}{\sim} N(0,\sigma^2)\\
\boldsymbol{\theta} | \tau &\sim \text{ICAR}\left(\tau^2\right)\\
\alpha^* &\sim N(0,3^2)\\
\beta_j &\sim N(0,3^2), \quad j = 1,\ldots,p\\
\sigma &\sim \text{Half-Normal}(0, 3^2)\\
\tau &\sim \text{Half-Normal}(0, 3^2)\\
\end{align*}

Where $n = 100$, $\mathbf{x}_i = (\text{age}_{i}, \text{poverty}_i)$.

## Full Stan Model for ICAR

```{stan output.var = "full_icar", eval = FALSE}
// saved in icar.stan
data {
  int<lower = 1> n;
  int<lower = 1> p;
  int<lower = 0> n_edges;
  array[n_edges] int<lower = 1, upper = n> node1; // node1[i] adjacent to node2[i]
  array[n_edges] int<lower = 1, upper = n> node2; // and node1[i] < node2[i]
  array[n] int<lower = 0> Y;
  vector<lower = 0>[n] E;
  matrix[n, p] X;
}
transformed data {
  matrix[n, p] X_centered;
  row_vector[p] X_bar;
  for (i in 1:p) {
    X_bar[i] = mean(X[, i]);
    X_centered[, i] = X[, i] - X_bar[i];
  }
  vector[n] logE = log(E);
}
parameters {
  real alpha_star;
  vector[p] beta;
  real<lower = 0> sigma; // precision of heterogeneous effects
  real<lower = 0> tau; // precision of spatial effects
  vector[n] z1; // spatial effects
  vector[n] z2; // heterogeneous effects
}
transformed parameters {
  vector[n] theta = tau * z1;     // spatial effects
  vector[n] epsilon = sigma * z2; // heterogeneous effects
}
model {
  Y ~ poisson_log(logE + alpha_star + X_centered * beta + theta + epsilon);
  // the following computes the ICAR prior on theta (through the standardized version z1)
  target += -0.5 * dot_self(z1[node1] - z1[node2]);
  // soft sum-to-zero constraint on theta)
  sum(z1) ~ normal(0, 0.001 * n); // equivalent to mean(z1) ~ normal(0, 0.001)
  // heterogeneous effects
  z2 ~ std_normal();
  // population parameters
  alpha_star ~ normal(0, 3);
  beta ~ normal(0, 3);
  sigma ~ normal(0, 3);
  tau ~ normal(0, 3);
}
generated quantities {
  real alpha = alpha_star - X_bar * beta;
  vector[n] log_mu = logE + alpha_star + X_centered * beta + theta + epsilon;
  vector[n] lambda = exp(log_mu - logE);
  vector[n] mu = exp(log_mu);
  vector[n] Y_pred;
  vector[n] log_lik;
  for (i in 1:n) {
    Y_pred[i] = poisson_log_rng(log_mu[i]);
    log_lik[i] = poisson_log_lpmf(Y[i] | log_mu[i]);
  }
}
```

## Fit the Stan Model

```{r, eval = FALSE, echo = FALSE}
icar <- stan_model("/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/data/covid/icar.stan")
X <- model.matrix(~ age + poverty, data = covid_nc_2020)[, -1]
stan_data <- list(
  n = nrow(covid_nc_2020),
  p = ncol(X),
  n_edges = nrow(neighbor_pairs_lower),
  node1 = neighbor_pairs_lower[, 1],
  node2 = neighbor_pairs_lower[, 2],
  Y = covid_nc_2020$obs_deaths,
  E = covid_nc_2020$est_deaths,
  X = X
)
fit_icar <- sampling(icar, stan_data, pars = c("z1", "z2", "epsilon", "log_mu", "lp__"), include = FALSE, iter = 10000)
print(fit_icar, pars = c("alpha", "alpha_star", "beta", "sigma", "tau"))
rstan::traceplot(fit_icar, pars = c("alpha", "alpha_star", "beta", "sigma", "tau"))
rstan::traceplot(fit_icar, pars = "theta[1]")
saveRDS(fit_icar, file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/19-fit-icar.rds")
```

```{r, eval = FALSE}
X <- model.matrix(~ age + poverty, data = covid_nc_2020)[, -1]
stan_data <- list(
  n = nrow(covid_nc_2020),
  p = ncol(X),
  n_edges = nrow(neighbor_pairs_lower),
  node1 = neighbor_pairs_lower[, 1],
  node2 = neighbor_pairs_lower[, 2],
  Y = covid_nc_2020$obs_deaths,
  E = covid_nc_2020$est_deaths,
  X = X
)
icar <- stan_model("icar.stan")
fit_icar <- sampling(icar, stan_data, pars = c("z1", "z2", "epsilon", "log_mu", "lp__"), include = FALSE, iter = 10000)
```

## Examine model summaries

```{r, eval = FALSE}
print(fit_icar, pars = c("alpha", "alpha_star", "beta", "sigma", "tau"))
```

```{r, echo = FALSE}
fit_icar <- readRDS(file = "/Users/sib2/Box Sync/Faculty/Education/biostat725-sp25/course-material/r-objects/19-fit-icar.rds")
print(fit_icar, pars = c("alpha", "alpha_star", "beta", "sigma", "tau"))
```

## Examine traceplots

```{r}
rstan::traceplot(fit_icar, pars = c("alpha", "alpha_star", "beta", "sigma", "tau"))
```

## Looking at SMR observed versus $\lambda_i$

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 5
#| fig-height: 5
#| layout-ncol: 1
lambda <- rstan::extract(fit_icar, pars = "lambda")$lambda
lambda_mean <- apply(lambda, 2, mean)
lambda_sd <- apply(lambda, 2, sd)
covid_nc_2020$lambda_mean <- lambda_mean
covid_nc_2020$lambda_sd <- lambda_sd
data.frame(Observed = covid_nc_2020$smr, Bayesian = covid_nc_2020$lambda_mean) |>
  ggplot(aes(x = Observed, y = Bayesian)) + 
    geom_point() + 
    geom_vline(aes(xintercept = 1)) + 
    geom_hline(aes(yintercept = 1)) +
    geom_abline(aes(intercept = 0, slope = 1))
```

## Posterior SMR Across North Carolina

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 7
#| fig-height: 3.5
#| layout-ncol: 2
#| layout-nrow: 2
###Map the PPD
min_value <- min(c(covid_nc_2020$smr, covid_nc_2020$lambda_mean))
max_value <- max(c(covid_nc_2020$smr, covid_nc_2020$lambda_mean))
min_value <- 0
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = smr), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = "Observed SMR by NC County",
    fill = "SMR"
  ) +
  scale_fill_gradient2(
    low = "green",        # Color for O/E < 1
    mid = "gray",        # Neutral color for O/E = 1
    high = "red",        # Color for O/E > 1
    midpoint = 1,        # Center the color scale at 1
    name = "SMR",
    limits = c(min_value, max_value)
  ) +
  # scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = lambda_mean), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = " Posterior Mean SMR by NC County",
    fill = "SMR"
  ) +
  scale_fill_gradient2(
    low = "green",        # Color for O/E < 1
    mid = "gray",        # Neutral color for O/E = 1
    high = "red",        # Color for O/E > 1
    midpoint = 1,        # Center the color scale at 1
    name = "SMR",
    limits = c(min_value, max_value)
  ) +
  # scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = lambda_sd), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = " Posterior Standard Deviation SMR by NC County",
    fill = "SD"
  ) +
  scale_fill_gradient2(
    low = "green",        # Color for O/E < 1
    mid = "gray",        # Neutral color for O/E = 1
    high = "red",        # Color for O/E > 1
    midpoint = 0,        # Center the color scale at 1
    name = "SD",
    limits = c(0, max(covid_nc_2020$lambda_sd))
  ) +
  # scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = smr - lambda_mean), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = " Difference in Observed Minus Bayesian SMR by County",
    fill = "Difference"
  ) +
  scale_fill_gradient2(
    low = "green",        # Color for O/E < 1
    mid = "gray",        # Neutral color for O/E = 1
    high = "red",        # Color for O/E > 1
    midpoint = 0,        # Center the color scale at 1
    name = "Difference",
    limits = c(-0.5, 0.5)
  ) +
  # scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
```

## Mapping $P(\lambda_i > 1 | \mathbf{Y})$

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 11
#| fig-height: 5.5
#| layout-ncol: 1
#| layout-nrow: 1
covid_nc_2020$lambda_prob <- apply(lambda, 2, function(x) mean(x > 1))
covid_nc_2020$lambda_prob_binary <- 1 * (covid_nc_2020$lambda_prob > 0.95)
covid_nc_2020$lambda_prob_binary <- as.factor(covid_nc_2020$lambda_prob_binary)
levels(covid_nc_2020$lambda_prob_binary) <- c("No", "Yes")
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = lambda_prob), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = "Posterior Probability that SMR is greater than 1",
    fill = "Probability"
  ) +
  scale_fill_viridis_c() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
```

## Mapping $P(\lambda_i > 1 | \mathbf{Y})$

Binary indicator of $P(\lambda_i > 1 | \mathbf{Y}) > 0.95$:

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-align: "center"
#| fig-width: 11
#| fig-height: 5.5
#| layout-ncol: 1
#| layout-nrow: 1
ggplot(data = covid_nc_2020) +
  geom_sf(fill = "lightblue", color = "black") +
  geom_sf(aes(fill = as.factor(lambda_prob_binary)), shape = 16, size = 2) +
  theme_minimal() +
  labs(
    title = "Posterior Indicator that SMR > 1",
    fill = "SMR > 1"
  ) +
  # scale_fill_viridis_b() +  # Custom labels for the breaks
  coord_sf()  # Ensures the map is properly projected
```

## Prepare for next class

-   Work on HW 05, which is due April 8.

-   Complete reading to prepare for next Thursday's lecture

-   Thursday's lecture: Guest lecture by Prof. Hwanhee Hong on Bayesian Meta-Analysis
