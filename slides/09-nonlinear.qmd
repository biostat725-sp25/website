---
title: "Nonlinear Regression"
author: "Prof. Sam Berchuck"
date: "2025-02-06"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— BIOSTAT 725 - Spring 2025](https://biostat725-sp25.netlify.app/)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    html-math-method: mathjax
filters:
  - parse-latex
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(knitr)
library(mvtnorm)
library(coda)
library(lars)
library(LaplacesDemon)
library(nimble)
library(splines)
```

## Review of last lecture

-   On Tuesday, we put all of our skills together and learned about the Bayesian workflow.

-   We have now learned all the skills needed to perform Bayesian inference.

-   The rest of the course we will introduce new models and data types that are useful for performing biomedical data science.

## Learning objectives today

-   Thus far, we have focused on linear regression models.

-   Today we will focus on two common approaches that use linear regression to build nonlinear associations: polynomial regression and b-splines.

-   Both approaches work by transforming a single predictor variable into several synthetic variables.

-   We will also look at a change point model, that encodes clinical context into a nonlinear framework.

## Linear regression

-   Consider the classic parametric model:

$$Y_i = \alpha + X_i \beta + \epsilon_i, \quad \epsilon_i \sim N(0, \sigma^2).$$

-   Assumptions:

    1.  $\epsilon_i$ are independent.

    2.  $\epsilon_i$ are Gaussian.

    3.  The mean of $Y_i$ is linear in $X_i$.

    4.  The residual distribution does not depend on $X_i$.

**Today we will generalize the linearity assumption.**

## Nonlinear regression

-   Define: $\mu_i = \mathbb{E}[Y_i] = \alpha + x_i\beta.$

-   The mean process can modeled flexibly, $\mu_i = g(X_i)$, where $g$ is some function that relates $X_i$ to $\mathbb{E}[Y_i | X_i].$

-   A form of nonlinear regression approximates the function $g$ using a finite basis expansion, 
$$g(X_i) = \alpha + \sum_{j=1}^J B_j(X_i)\beta_j,$$
where $B_j(X)$ are known basis functions and $\beta_j$ are unknown parameters that determine the shape of $g$.

## Nonlinear regression

-   Example: Polynomial regression takes $B_j(X_i) = X_i^j$.

-   Example: Gaussian radial basis functions: $$B_j(X_i) = \exp\left\{-\frac{|X_i - \nu_j|^2}{l^2}\right\},$$ where $\nu_j$ are centers of the basis functions and $l$ is a common width parameter.

- The number of of basis functions and the width parameter $l$ controls the scale at which the model can vary as a function of $X_i$.

## Nonlinear regression {.smaller}

- Example: The cubic B-spline basis function is the following piecewise cubic polynomial:

$$B_j(X_i) = \left\{
\begin{matrix*}[l]
\frac{1}{6}u^3 & \text{for }X_i \in (\nu_j,\nu_{j+1}), & u = (X_i - \nu_j) / \delta\\
\frac{1}{6}(1 + 3u + 3u^2 - 3u^3) & \text{for }X_i \in (\nu_{j+1},\nu_{j+2}), & u = (X_i - \nu_{j+1}) / \delta\\
\frac{1}{6}(4 - 6u^2 + 3u^3) & \text{for }X_i \in (\nu_{j+2},\nu_{j+3}), & u = (X_i - \nu_{j+2}) / \delta\\
\frac{1}{6}(1 - 3u + 3u^2 - u^3) & \text{for }X_i \in (\nu_{j+3},\nu_{j+4}), & u = (X_i - \nu_{j+3}) / \delta\\
0 & \text{otherwise.}
\end{matrix*}
\right.$$

- B-splines are a piecewise continuous function defined conditional on some set of knots. 

- Here we assume a uniform knot locations $\nu_{j + k} = \nu_j + \delta k$.

- B-splines have compact support, so the design matrix is sparse. 

## Nonlinear regression

- Conditionally on the selected baseis $B$, the model is linear in the parameters. Hence we can write, 
$$Y_i = \mu(X_i) + \epsilon_i = \mathbf{w}_i \boldsymbol{\beta} + \epsilon_i,$$ 
with $\mathbf{w}_i = (B_1(X_i),\ldots,B_J(X_i))$.

- Model fitting can proceed as in linear regression models, since the resulting model is linear in $\boldsymbol{\beta}$.

- It is often useful to center the basis function model around the linear model, $\mu(X_i) = \alpha + X_i \beta + \mathbf{w}_i\boldsymbol{\beta}$.

## Glaucoma disease progression {.midi}

-   Today we will use data from the [Rotterdam Ophthalmic Data Repository](http://www.rodrep.com/longitudinal-glaucomatous-vf-data---description.html).

-   Glaucoma is the leading cause of irreversible blindness world wide with over 60 million glaucoma patients as of 2012. Since impairment caused by glaucoma is irreversible, early detection of disease progression is crucial for effective treatment.

-   Patients with glaucoma are routinely followed up and administered visual fields, a functional assessment of their vision.

-   After each visual field test their current disease status is reported as a mean deviation (MD) value, measured in decibels (dB). A lower mean deviation indicates worse vision.

-   Central clinical challenges are i) identifying disease progression of MD, and ii) predicting future MD.

## Glaucoma data

```{r, eval = FALSE}
### Load and process data to obtain data for an example patient
dat <- read.csv(file = "LongGlaucVF_20150216/VisualFields.csv")
dat <- dat[order(dat$STUDY_ID, dat$SITE), ]
dat$EYE_ID <- cumsum(!duplicated(dat[, c("STUDY_ID", "SITE")]))
dat_pat <- dat[dat$EYE_ID == "4", ] # 4
dat_pat$time <- (dat_pat$AGE - dat_pat$AGE[1]) / 365
dat_pat <- dat_pat[, c("time", "MD")]
colnames(dat_pat) <- c("X", "Y")
glimpse(dat_pat)
```

```{r, echo = FALSE}
dat <- read.csv(file = "/Users/sib2/Box Sync/Postdoc/Education/STA440/case3/data/LongGlaucVF_20150216/VisualFields.csv")
dat <- dat[order(dat$STUDY_ID, dat$SITE), ]
dat$EYE_ID <- cumsum(!duplicated(dat[, c("STUDY_ID", "SITE")]))
dat_pat <- dat[dat$EYE_ID == "4", ] # 4
dat_pat$time <- (dat_pat$AGE - dat_pat$AGE[1]) / 365
dat_pat <- dat_pat[, c("time", "MD")]
colnames(dat_pat) <- c("X", "Y")
glimpse(dat_pat)
```

## An example patient

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
ggplot(dat_pat, aes(x = X, y = Y)) + 
  geom_point() + 
  scale_x_continuous(name = "Years from baseline visual field") + 
  scale_y_continuous(name = "Mean deviation (dB)")
```

## Linear regression

```{r, eval = FALSE, echo = FALSE}
stan_data <- list(
  n = nrow(dat_pat),
  p = 1,
  Y = dat_pat$Y,
  X = matrix(dat_pat$X, ncol = 1)
)
compile_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/nonlinear_linear.stan")
fit_linear <- sampling(compile_model, data = stan_data)
saveRDS(fit_linear, file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_linear.rds")
```

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
fit_linear <- readRDS("/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_linear.rds")
mu <- rstan::extract(fit_linear, pars = "mu")$mu
mu_mean <- apply(mu, 2, mean)
mu_lower <- apply(mu, 2, function(x) quantile(x, probs = 0.025))
mu_upper <- apply(mu, 2, function(x) quantile(x, probs = 0.975))
dat_fig_linear <- data.frame(x = dat_pat$X, mean = mu_mean, lower = mu_lower, upper = mu_upper)
dat_fig_linear |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Posterior regression line with 95% credible interval")
```

## Linear regression

-   Linear regression is simple.

-   Linear regression is highly interpretable. It encodes disease progression into a slope, which is the amount of MD loss (dB) per year.

    -   Interpretability is important!

-   A linear relationship may be an oversimplification.

-   Often in prediction contexts, a nonlinear approach is preferred.

## Polynomials

-   Model for the mean process becomes nonlinear:

$$\mathbb{E}[MD_i] = \alpha + \beta_1 Time_i + \cdots + \beta_p Time_i^p$$

-   $p$ is chosen depending on the degree of non-linearity.

-   When fitting non-linear regression in Bayesian context it is useful to standardize the data.

## Polynomial regression in Stan

```{r, eval = FALSE}
dat_poly <- data.frame(
  Y = scale(dat_pat$Y),
  X = scale(dat_pat$X)
)
dat_poly$X2 <- dat_poly$X^2
stan_data <- list(
  n = nrow(dat_pat),
  p = 2,
  Y = dat_poly$Y,
  X = cbind(dat_poly$X, dat_poly$X2),
)
compile_model <- stan_model(file = "nonlinear_linear.stan")
fit_quadratic <- sampling(compile_model, data = stan_data)
```

## Polynomial regression in Stan

```{stan output.var = "test", eval = FALSE}
// saved in nonlinear_linear.stan
data {
  int<lower = 1> n; // number of observations
  int<lower = 1> p; // number of covariates
  vector[n] Y; // outcome vector
  matrix[n, p] X; // covariate vector
}
parameters {
  real alpha;
  vector[p] beta;
  real<lower = 0> sigma;
}
model {
  target += normal_lpdf(Y | X * beta, sigma); // likelihood
  target += normal_lpdf(alpha | 0, 1); // prior for beta
  target += normal_lpdf(beta | 0, 1); // prior for beta
  target += inv_gamma_lpdf(sigma | 3, 1); // prior for sigma
}
generated quantities {
  vector[n] in_sample;
  vector[n] log_lik;
  vector[n] mu;
  for (i in 1:n) {
    mu[i] = alpha + X[i, ] * beta;
    in_sample[i] = normal_rng(mu[i], sigma);
    log_lik[i] = normal_lpdf(Y[i] |  mu[i], sigma);
  }
}
```

## Quadratic regression

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
fit_quadratic <- readRDS("/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_quadratic.rds")
rstan::traceplot(fit_quadratic, pars = c("alpha", "beta"))
```

## Extract posterior mean for $\mu$

```{r, eval = FALSE}
mu <- rstan::extract(fit_quadratic, pars = "mu")$mu
mu <- mu * sd(dat_pat$Y) + mean(dat_pat$Y) # transform to original unstandardized Y_i
mu_mean <- apply(mu, 2, mean)
mu_lower <- apply(mu, 2, function(x) quantile(x, probs = 0.025))
mu_upper <- apply(mu, 2, function(x) quantile(x, probs = 0.975))
```

```{r, eval = FALSE, echo = FALSE}
dat_poly <- data.frame(
  Y = scale(dat_pat$Y),
  X = scale(dat_pat$X)
)
dat_poly$X2 <- dat_poly$X^2
dat_poly$X3 <- dat_poly$X^3
stan_data <- list(
  n = nrow(dat_pat),
  p = 2,
  Y = dat_poly$Y,
  X = cbind(dat_poly$X, dat_poly$X2)
)
# compile_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/nonlinear_linear.stan")
fit_quadratic <- sampling(compile_model, data = stan_data)
saveRDS(fit_quadratic, file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_quadratic.rds")
```

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 9
#| fig-height: 4
#| layout-ncol: 1
mu <- rstan::extract(fit_quadratic, pars = "mu")$mu
mu <- mu * sd(dat_pat$Y) + mean(dat_pat$Y)
mu_mean <- apply(mu, 2, mean)
mu_lower <- apply(mu, 2, function(x) quantile(x, probs = 0.025))
mu_upper <- apply(mu, 2, function(x) quantile(x, probs = 0.975))
dat_fig_quadratic <- data.frame(x = dat_pat$X, mean = mu_mean, lower = mu_lower, upper = mu_upper)
dat_fig_quadratic |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Quadratic polynomial regression")
```

## Cubic regression

```{r, eval = FALSE, echo = FALSE}
stan_data <- list(
  n = nrow(dat_pat),
  p = 3,
  Y = dat_poly$Y,
  X = cbind(dat_poly$X, dat_poly$X2, dat_poly$X3)
)
# compile_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/nonlinear_linear.stan")
fit_cubic <- sampling(compile_model, data = stan_data)
saveRDS(fit_cubic, file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_cubic.rds")
```

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
fit_cubic <- readRDS("/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_cubic.rds")
mu <- rstan::extract(fit_cubic, pars = "mu")$mu
mu <- mu * sd(dat_pat$Y) + mean(dat_pat$Y)
mu_mean <- apply(mu, 2, mean)
mu_lower <- apply(mu, 2, function(x) quantile(x, probs = 0.025))
mu_upper <- apply(mu, 2, function(x) quantile(x, probs = 0.975))
dat_fig_cubic <- data.frame(x = dat_pat$X, mean = mu_mean, lower = mu_lower, upper = mu_upper)
dat_fig_cubic |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Cubic polynomial regression")
```

## B-spline regression with 5 knots

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 5
#| fig-height: 5
#| layout-ncol: 2
num_knots <- 5
X_viz <- seq(min(dat_pat$X), max(dat_pat$X), length.out = 1001)
knot_list <- quantile(X_viz, probs = seq(from = 0, to = 1, length.out = num_knots))
B <- bs(X_viz,
        knots = knot_list[-c(1, num_knots)], 
        degree = 3, 
        intercept = TRUE)
plot(1, 1, type = "n", xlim = c(0, max(dat_pat$X)), ylim = c(0, 1), xlab = "X", ylab = "", xaxs = "i")
for (i in 1:ncol(B)) lines(X_viz, B[, i])
MU <- matrix(nrow = nrow(B), ncol = 5)
for (i in 1:5) {
  beta <- rnorm(ncol(B))
  alpha <- rnorm(1)
  MU[, i] <- alpha + B %*% beta
}
plot(1, 1, type = "n", xlab = "X", ylab = expression(paste(mu, "(X)")), xlim = c(min(dat_pat$X), max(dat_pat$X)), ylim = c(min(MU), max(MU)), , xaxs = "i")
for (i in 1:5) lines(X_viz, MU[, i], col = i + 1)
```

## B-spline regression with 10 knots

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 5
#| fig-height: 5
#| layout-ncol: 2
num_knots <- 10
X_viz <- seq(min(dat_pat$X), max(dat_pat$X), length.out = 1001)
knot_list <- quantile(X_viz, probs = seq(from = 0, to = 1, length.out = num_knots))
B <- bs(X_viz,
        knots = knot_list[-c(1, num_knots)], 
        degree = 3, 
        intercept = TRUE)
plot(1, 1, type = "n", xlim = c(0, max(dat_pat$X)), ylim = c(0, 1), xlab = "X", ylab = "", xaxs = "i")
for (i in 1:ncol(B)) lines(X_viz, B[, i])
MU <- matrix(nrow = nrow(B), ncol = 5)
for (i in 1:5) {
  beta <- rnorm(ncol(B))
  alpha <- rnorm(1)
  MU[, i] <- alpha + B %*% beta
}
plot(1, 1, type = "n", xlab = "X", ylab = expression(paste(mu, "(X)")), xlim = c(min(dat_pat$X), max(dat_pat$X)), ylim = c(min(MU), max(MU)), , xaxs = "i")
for (i in 1:5) lines(X_viz, MU[, i], col = i + 1)
```

## B-spline regression {.smaller}

```{r}
library(splines)
num_knots <- 5
knot_list <- quantile(dat_pat$X, probs = seq(from = 0, to = 1, length.out = num_knots))
B <- bs(dat_pat$X,
        knots = knot_list[-c(1, num_knots)], 
        degree = 3, 
        intercept = TRUE)
B
```

## B-spline regression {.smaller}

```{r, eval = FALSE, echo = FALSE}
stan_data <- list(
  n = nrow(dat_pat),
  p = ncol(B),
  Y = dat_poly$Y,
  X = B
)
# compile_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/nonlinear_linear.stan")
fit_bspline <- sampling(compile_model, data = stan_data)
saveRDS(fit_bspline, file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_bspline.rds")
```

```{r, eval = FALSE}
stan_data <- list(
  n = nrow(dat_pat),
  p = ncol(B),
  Y = dat_poly$Y,
  X = B
)
fit_bspline <- sampling(compile_model, data = stan_data)
```

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4
#| layout-ncol: 1
fit_bspline <- readRDS("/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_bspline.rds")
mu <- rstan::extract(fit_bspline, pars = "mu")$mu
mu <- mu * sd(dat_pat$Y) + mean(dat_pat$Y)
mu_mean <- apply(mu, 2, mean)
mu_lower <- apply(mu, 2, function(x) quantile(x, probs = 0.025))
mu_upper <- apply(mu, 2, function(x) quantile(x, probs = 0.975))
dat_fig_bspline <- data.frame(x = dat_pat$X, mean = mu_mean, lower = mu_lower, upper = mu_upper)
dat_fig_bspline |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "B-spline regression")
```


## Model comparison

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 4
#| fig-height: 2.5
#| layout-ncol: 2
#| layout-nrow: 2
dat_fig_linear |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Linear")
dat_fig_quadratic |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Quadratic")
dat_fig_cubic |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "Cubic")
dat_fig_bspline |> ggplot(aes(x = x, y = mean)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3) + 
  geom_point(data = dat_pat, aes(x = X, y = Y)) + 
  labs(x = "Years from baseline visual field", y = "Mean deviation (dB)", subtitle = "B-spline")
```

## What is the point?

-   Choice of model is highly dependent on the context.

-   As we learned in the model comparison lecture, a better fit to the sample might not actually be a better model.

-   These basis models are difficult to interpret and are not particularly useful for a clinical setting (they may be useful for prediction!).

## Change point motivation

:::::: columns
::: {.column width="40%"}
```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 4
#| fig-height: 4
#| layout-ncol: 1
ggplot(dat_pat, aes(x = X, y = Y)) + 
  geom_point() + 
  scale_x_continuous(name = "Years from baseline visual field") + 
  scale_y_continuous(name = "Mean deviation (dB)")
```
:::

::: {.column width="60%"}
- Progression is defined by slow (or stable) deterioration, followed by a rapid decrease.

- Flexible modeling of MD across time.

- Biological representation of progression through the change point.

- Change points are a framework for inherently parameterizing progression.
:::
::::::

## Writing down a model

- Model for the observed data:

$$Y_i = \mu(X_i) + \epsilon_i, \quad \epsilon_i \sim N(0,\sigma^2).$$

. . .

- Model for the mean process:

$$\mu(X_i) =\left\{ \begin{array}{ll}
        {\beta}_0 + \beta_1 X_i & \text{ } \mbox{$X_i \leq \theta$},\\
        {\beta}_0 + \beta_1 \theta + {\beta}_2\{X_i - \theta\}& \text{ } \mbox{$X_i > \theta.$}\end{array} \right.$$

- $\theta \in (\min X_i, \max X_i)$ represents a change point.

## Change point model in Stan

```{stan output.var = "cp", eval = FALSE}
// saved in change_points.stan
functions {
  vector compute_mean(vector X, real beta0, real beta1, real beta2, real theta) {
    int n = size(X);
    vector[n] mu;
    for (t in 1:n) {
      if (X[t] <= theta) mu[t] = beta0 + beta1 * X[t];
      if (X[t] > theta) mu[t] = beta0 + beta1 * theta + beta2 * (X[t] - theta);
  }
  return mu;
  }
}
data {
  int<lower=1> n;
  vector[n] Y;
  vector[n] X;
  int n_pred;
  vector[n_pred] X_pred;
}
transformed data {
  real min_X = min(X);
  real max_X = max(X);
}
parameters {
  real beta0;
  real beta1;
  real beta2;
  real<lower = 0> sigma;
  real<lower = min_X, upper = max_X> theta;
}
model {
  vector[n] mu = compute_mean(X, beta0, beta1, beta2, theta);
  target += normal_lpdf(Y | mu, sigma);
  target += normal_lpdf(sigma | 0, 1);
  target += normal_lpdf(beta0 | 0, 1);
  target += normal_lpdf(beta1 | 0, 1);
  target += normal_lpdf(beta2 | 0, 1);
}
generated quantities {
  vector[n_pred] mu_pred = compute_mean(X_pred, beta0, beta1, beta2, theta);
  array[n_pred] real Y_pred_out = normal_rng(mu_pred, sigma);
  vector[n] mu = compute_mean(X, beta0, beta1, beta2, theta);
  array[n] real Y_pred_in = normal_rng(mu, sigma);
}
```

## Change point regression {.smaller}

```{r, eval = FALSE, echo = FALSE}
stan_model <- stan_model(file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/Material/ChangePoints/change_points.stan")
n_pred <- 1000
stan_data <- list(Y = dat_pat$Y, 
                  X = dat_pat$X,
                  n = nrow(dat_pat),
                  n_pred = n_pred,
                  X_pred = seq(0, max(dat_pat$X) + 2, length.out = n_pred))
fit_cp <- sampling(stan_model, data = stan_data)
saveRDS(fit_cp, file = "/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_cp.rds")
```

```{r, eval = FALSE}
stan_model <- stan_model(file = "change_points.stan")
n_pred <- 1000
stan_data <- list(Y = dat_pat$Y, 
                  X = dat_pat$X,
                  n = nrow(dat_pat),
                  n_pred = n_pred,
                  X_pred = seq(0, max(dat_pat$X) + 2, length.out = n_pred))
fit_cp <- sampling(stan_model, data = stan_data)
print(fit_cp, probs = c(0.025, 0.5, 0.0975))
```

```{r, echo = FALSE}
n_pred <- 1000
stan_data <- list(Y = dat_pat$Y, 
                  X = dat_pat$X,
                  n = nrow(dat_pat),
                  n_pred = n_pred,
                  X_pred = seq(0, max(dat_pat$X) + 2, length.out = n_pred))
fit_cp <- readRDS("/Users/sib2/Box Sync/Faculty/Education/BIOSTAT725/robjects/fit_cp.rds")
print(fit_cp, probs = c(0.25, 0.5, 0.75), pars = c("beta0", "beta1", "beta2", "sigma", "theta"))
```

## Diagnostics

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4
#| layout-ncol: 1
rstan::traceplot(fit_cp, pars = c("beta0", "beta1", "beta2", "sigma", "theta"))
```

## Posterior fit

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
pars <- rstan::extract(fit_cp)
beta0 <- mean(pars$beta0)
beta1 <- mean(pars$beta1)
beta2 <- mean(pars$beta2)
theta <- mean(pars$theta)
X <- stan_data$X
n <- stan_data$n
mu <- numeric(length = n)
for (t in 1:n) {
  if (X[t] <= theta) mu[t] = beta0 + beta1 * X[t]
  if (X[t] > theta) mu[t] = beta0 + beta1 * theta + beta2 * (X[t] - theta)
}
reg.line <- data.frame(
  X = X,
  Y = mu
)
dat.fig <- data.frame(
  X = stan_data$X,
  Y = apply(pars$mu, 2, mean),
  Lower = apply(pars$mu, 2, function(x) quantile(x, probs = 0.025)),
  Upper = apply(pars$mu, 2, function(x) quantile(x, probs = 0.975))
)
ggplot(dat_pat, aes(x = X, y = Y)) + 
  geom_point() +
  geom_line(data = reg.line, aes(x = X, y = Y), color = "blue", size = 1.5) + 
  scale_x_continuous(name = "Years from baseline visual field") + 
  scale_y_continuous(name = "Mean deviation") +
  geom_vline(xintercept = theta, linetype = "dotted", color = "red", size = 1.5) + 
  ggtitle("Blue line is the mean function evaluated at the posterior means\nDashed red line indicates the posterior mean change point")
```

## Posterior fit

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
ggplot(dat_pat, aes(x = X, y = Y)) + 
  geom_point() +
  geom_line(data = reg.line, aes(x = X, y = Y), color = "blue", size = 1.5) + 
  geom_line(data = dat.fig, aes(x = X, y = Y), size = 1.5) + 
  geom_ribbon(data = dat.fig, aes(ymin = Lower, ymax = Upper), alpha = 0.3) + 
  geom_vline(xintercept = median(pars$theta), linetype = "dotted", color = "red", size = 1.5) + 
  geom_vline(xintercept = quantile(pars$theta, probs = 0.25), linetype = "solid", color = "red", size = 1) + 
  geom_vline(xintercept = quantile(pars$theta, probs = 0.75), linetype = "solid", color = "red", size = 1) + 
  scale_x_continuous(name = "Years from baseline visual field") + 
  scale_y_continuous(name = "Mean deviation") +
  ggtitle("Dashed red line indicates the posterior median change point (with IQR)\nBlack curve represents the posterior mean process with 95% credible band")

```

## Prediction

```{r}
#| echo: false
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 6
#| layout-ncol: 1
dat.fig_pred <- data.frame(
  X = stan_data$X_pred,
  Y = apply(pars$mu_pred, 2, mean),
  Lower = apply(pars$mu_pred, 2, function(x) quantile(x, probs = 0.025)),
  Upper = apply(pars$mu_pred, 2, function(x) quantile(x, probs = 0.975))
)
dat.fig_pred <- dat.fig_pred[dat.fig_pred$X > max(dat_pat$X), ]
ggplot(dat_pat, aes(x = X, y = Y)) + 
  geom_point() +
  geom_line(data = dat.fig, aes(x = X, y = Y)) + 
  geom_ribbon(data = dat.fig, aes(ymin = Lower, ymax = Upper), alpha = 0.3) + 
  geom_line(data = dat.fig_pred, aes(x = X, y = Y), color = "green") + 
  geom_ribbon(data = dat.fig_pred, aes(ymin = Lower, ymax = Upper), fill = "green", color = "green", alpha = 0.3) + 
  geom_vline(xintercept = median(pars$Theta), linetype = "dotted", color = "red", size = 1.5) + 
  geom_vline(xintercept = quantile(pars$Theta, probs = 0.25), linetype = "solid", color = "red", size = 1) + 
  geom_vline(xintercept = quantile(pars$Theta, probs = 0.75), linetype = "solid", color = "red", size = 1) + 
  scale_x_continuous(name = "Years from baseline visual field") + 
  scale_y_continuous(name = "Mean deviation") +
  ggtitle("The figure has been updated to show extrapolation of two years")
```

## Prepare for next class

-   Work on [HW 02](https://biostat725-sp25.netlify.app/hw/hw-02).

-   Complete reading to prepare for next Tuesday's lecture

-   Tuesday's lecture: Robust regression
